[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Biométrie et expérimentation végétale",
    "section": "",
    "text": "Bienvenue\nCe cours présente les notions de bases en biométrie et expérimentation aux ingénieur agronomes 3e année de l’Institut National Polytechnique Félix Houphouët-Boigny.\nCe manuel est et sera toujours gratuit, sous licence CC BY-NC-ND 3.0."
  },
  {
    "objectID": "intro.html#rappels-sur-les-notions-de-base",
    "href": "intro.html#rappels-sur-les-notions-de-base",
    "title": "\n1  Importance et notions de base\n",
    "section": "\n1.1 Rappels sur les notions de base",
    "text": "1.1 Rappels sur les notions de base\n\n1.1.1 Types de statistiques\n\n\nDescriptives: le but est d’illustrer les données;\n\n\nParamétriques: on suppose que la/les variables(s) suivent une distribution particulière;\n\n\nNon paramétriques: on ne fait aucune supposition concernant la distribution de la/les variables(s).\n\n1.1.2 Variables\n\nUne variable est un attribut mesuré pour chaque individu/observation.\n\nTypes d’échelle de mesure:\n\nRatio: le 0 est clairement défini; ne peut pas être &lt; 0.\n\nIntervalle: le 0 est arbitraire; peut être &lt; 0.\n\nOrdinale: l’ordre est défini; les rangs n’indiquent pas nécessairement des différentes constantes.\n\nNominale/Catégorique: l’ordre est non défini.\n\nContinue: présente une infinité de valeurs possibles.\n\nDiscrète: nombre limité de valeurs possibles.\n\n\n\n1.1.3 Qu’est-ce qu’une distribution?\nUne fonction qui exprime la fréquence (densité de probabilité) des différentes valeurs pouvant être prise par une variable.\nRappelons ici quelques distributions usuelles.\n\n1.1.3.1 Distribution uniforme (continue)\nBien que les origines historiques de la conception de la distribution uniforme ne soient pas concluantes, on suppose que le terme “uniforme” est né du concept d’équiprobabilité dans les jeux de dés (notez que les jeux de dés auraient un espace d’échantillonnage uniforme discret et non continu).\nLes paramètres de la distribution uniforme sont:\n\nMoyenne: \\(\\frac{1}{2}(a + b)\\).\n\nVariance: \\(\\frac{1}{12}(b - a)^2\\).\n\nLa fonction de densité de la loi uniforme est:\n\\[\nf(x) = \\left\\{\\begin{array}{ll}\\frac{1}{b - a} & \\mbox{for } a \\leq x \\leq b, \\\\ 0 & \\mbox{otherwise}\\end{array}\\right.\n\\]\n\n\n\n\n\n\n1.1.3.2 Distribution binomiale\nLa distribution binomiale est fréquemment utilisée pour modéliser le nombre de succès dans un échantillon de taille \\(n\\) tiré avec remplacement d’une population de taille \\(N\\).\nLes paramètres de la distribution binomiale sont:\n\nMoyenne: \\(\\mu = np\\).\nVariance: \\(\\sigma^2 = npq\\).\n\nLa fonction de densité de la loi binomiale est:\n\\[\nf(k, n, p) = \\binom{n}{k}p^k (1-p)^{n-k}\n\\]\n\n\n\n\n\n\n1.1.3.3 Distribution de Poisson\nLa distribution de Poisson est une distribution de probabilité discrète qui exprime la probabilité qu’un nombre donné d’événements se produisent dans un intervalle de temps fixe si ces événements se produisent avec un taux moyen constant connu et indépendamment du temps écoulé depuis le dernier événement.\nLes paramètres de la distribution de Poisson sont:\n\nMoyenne: \\(\\mu = \\lambda\\)\nVariance: \\(\\sigma^2 = \\lambda\\)\n\nLa fonction de densité de probabilité de la distribution de Poisson est:\n\\[\nf(k; \\lambda) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\n\\]\n\n\n\n\n\n\n1.1.3.4 Distribution normale\nLes distributions normales sont importantes en statistique et sont souvent utilisées dans les sciences naturelles et sociales pour représenter des variables aléatoires à valeur réelle dont la distribution n’est pas connue. Leur importance est en partie due au théorème de la limite centrale. Ce théorème stipule que, sous certaines conditions, la moyenne de nombreux échantillons (observations) d’une variable aléatoire de moyenne et de variance finies est elle-même une variable aléatoire, dont la distribution converge vers une distribution normale à mesure que le nombre d’échantillons augmente. Par conséquent, les quantités physiques qui sont censées être la somme de nombreux processus indépendants, tels que les erreurs de mesure, ont souvent des distributions qui sont presque normales.\nLes paramètres de la distribution normale sont:\n\nMoyenne: \\(\\mu = \\frac{\\sum_{i=1}^{N} X_i}{N}\\).\nVariance: \\(\\sigma^2 = \\frac{\\sum (X_i - \\mu)^2}{N}\\).\n\nLa fonction de densité de la loi normale est:\n\\[ f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}\\]\n\n\n\n\n\n\n\n\n\n\n\nPoints clés à retenir\n\n\n\n\nLa distribution normale est le terme approprié pour désigner une courbe de probabilité en cloche.\nDans une distribution normale, la moyenne est égale à zéro et l’écart-type est de 1. L’asymétrie est nulle et l’aplatissement est de 3.\nLes distributions normales sont symétriques, mais toutes les distributions symétriques ne sont pas normales.\n\n\n\n\n1.1.3.5 Distribution \\(t\\) de Student\nEn probabilité et en statistique, la distribution \\(t\\) de Student (ou simplement la distribution \\(t\\)) \\(t_\\nu\\) est une distribution de probabilité continue qui généralise la distribution normale standard. Comme cette dernière, elle est symétrique autour de zéro et en forme de cloche.\nLes paramètres de la distribution \\(t\\) de Student sont:\n\nMoyenne: 0 pour \\(\\nu &gt; 1\\) et indéfini dans le cas contraire.\nVariance: \\(\\frac{\\nu}{\\nu - 2}\\) pour \\(\\nu &gt; 2\\), \\(\\infty\\) pour \\(1 &lt; \\nu \\leq 2\\), indéfini dans les cas contraires.\n\nLa fonction de densité de probabilité de la distribution de \\(t\\) est:\n\\[\nf(t) = \\frac{\\Gamma(\\frac{\\nu + 1}{2})}{\\sqrt{\\pi \\nu} \\Gamma(\\frac{\\nu}{2})} (1 + \\frac{t^2}{\\nu}) ^ {-(\\nu + 1)/2}\n\\]\nou \\(\\nu\\) est le nombre de dégrés de libertés et \\(\\Gamma\\) est la fonction Gamma.\n\n\n\n\n\nLa distribution t de Student avec \\(\\nu\\) degrés de liberté peut être définie comme la distribution de la variable aléatoire \\(T\\) avec \\[T = \\frac{Z}{\\sqrt{V/\\nu}} = Z\\sqrt{\\frac{\\nu}{V}}\\]\navec\n\n\\(Z\\) est une normale standard avec une valeur attendue de 0 et une variance de 1 ;\n\\(V\\) suit une distribution de khi-deux (\\(\\chi^2\\)) avec \\(\\nu\\) dégrés de liberté;\n\\(Z\\) et \\(V\\) sont indépendants.\n\n\n\n\n\n\n\nPoints clés à retenir\n\n\n\n\nLa distribution \\(t\\) est une distribution de probabilité continue du score z lorsque l’écart-type estimé est utilisé au dénominateur plutôt que l’écart-type réel.\nLa distribution \\(t\\), comme la distribution normale, est en forme de cloche et symétrique, mais ses queues sont plus lourdes, ce qui signifie qu’elle a tendance à produire des valeurs très éloignées de sa moyenne.\nLes tests T sont utilisés en statistique pour estimer l’importance des résultats."
  },
  {
    "objectID": "intro.html#pourquoi-a-t-on-besoin-de-méthodes-statistiques",
    "href": "intro.html#pourquoi-a-t-on-besoin-de-méthodes-statistiques",
    "title": "\n1  Importance et notions de base\n",
    "section": "\n1.2 Pourquoi a-t-on besoin de méthodes statistiques ?",
    "text": "1.2 Pourquoi a-t-on besoin de méthodes statistiques ?\nLa plupart des sciences sont comparatives. Les chercheurs ont souvent besoin de savoir si un traitement expérimental particulier a eu un effet, ou s’il existe des différences entre une variable particulière mesurée à plusieurs endroits différents. Par exemple, un nouveau médicament a-t-il un effet sur la tension artérielle, un régime riche en vitamine C réduit-il le risque de cancer du foie chez l’homme, ou existe-t-il une relation entre la couverture végétale et la densité de la population de lapins ? Mais lorsque vous faites ce genre de comparaisons, les différences entre les traitements ou entre les zones échantillonnées peuvent être réelles ou peuvent simplement être le type de variation qui se produit par hasard entre les échantillons d’une même population.\nPrenons 2 situations concrètes:\n\nDans la première, nous jouons à pile ou face avec 10 pièces. On obtient après un lancer unique de chacune des pièces 3 faces et 7 piles. Pouvons-nous dire si ce lot de pièces est truqué?\n\nDans la seconde, on échantillone une population de singes, et on observe 32 femelles et 54 mâles. Y a-t-il réellement plus de mâles dans la population?\n\nLes probabilités vous aident à prendre une décision concernant vos résultats.\n\n1.2.1 Tests statistiques et niveaux de signification\nUn test statistique est une aide à la décision concernant une hypothèse (alternative vs nulle).\nL’idée maîtresse à la base de tout test d’hypothèse statistique:\n\nJe suppose que \\(H_0\\) (hypothèse nulle) est vraie (pas de différence/relation);\n\nJe calcule la p-valeur, c’est à dire la probabilité d’obtenir une différence/relation au moins aussi forte que celle que j’ai observée dans mon échantillon (qui est un fait établi);\n\nSi cette p-valeur est faible, alors il est probable que \\(H_0\\) soit fausse: la différence mesurée est simplement une mauvaise estimation d’une différence nulle.\n\nLe statisticien Sir Ronald Fisher a proposé que, si la probabilité d’obtenir cette différence ou une différence plus extrême entre le résultat attendu et le résultat réel est inférieure à 5 %, il convient de conclure que la différence est statistiquement significative (Fisher, 1954). Le choix de 5% (qui correspond à 1/20 ou 0,05) n’a pas de raison biologique. C’est la probabilité que de nombreux chercheurs utilisent comme « niveau de signification statistique » standard.\n\n\n\n\n\n\nAttention: ce seuil n’est pas une valeur magique, les statistiques ce n’est pas blanc vs noir, vrai vs faux, significatif vs non significatif…\n\n\n\n\n1.2.2 Exemple de calcul direct de la p-valeur\nPrenons un exemple de sac contenant 1000 boules blanches et noires. On en tire 6 au hasard (McKillup 2011). On veut tester l’hypothèse qu’il y a 500 blanches et 500 noires: \\(H_0\\): \\(\\mathbb{P}(blanche) = 0,5\\) vs \\(H_A\\): \\(\\mathbb{P}(blanche) ≠ 0,5\\).\n\n\n\n\n\n\nConcepts basiques de probabilité\n\n\n\nLa probabilité d’un événement ne peut varier qu’entre 0 et 1 (qui correspondent à 0 et 100%). Si un événement est certain de se produire, il a une probabilité de 1 ; alors que s’il est certain que l’événement ne se produira pas, il a une probabilité de 0.\nLa probabilité d’un événement particulier est le nombre de résultats donnant cet événement, divisé par le nombre total de résultats possibles. Par exemple, lorsque vous jouez à pile ou face, il n’y a que deux résultats possibles : pile ou face. Ces deux événements s’excluent mutuellement : il est impossible d’obtenir les deux.\nPar conséquent, la probabilité d’obtenir un résultat positif est de 1 divisé par 2 = ½ (et donc la probabilité d’obtenir un résultat négatif est également de ½).\nLa règle de l’addition\nLa probabilité d’obtenir une tête ou une queue est de ½ + ½ = 1. Il s’agit d’un exemple de la règle de l’addition : lorsque plusieurs résultats s’excluent mutuellement, la probabilité d’obtenir l’un d’entre eux est la somme de leurs probabilités respectives. (Par conséquent, la probabilité d’obtenir un 1, un 2, un 3 ou un 4 en lançant un dé à six faces est de 4/6).\nLa règle de multiplication\nÉvénements indépendants. Pour calculer la probabilité conjointe de deux ou plusieurs événements indépendants (par exemple, un face suivi d’un autre face lors de deux lancers indépendants d’une pièce de monnaie), il suffit de multiplier les probabilités indépendantes entre elles. Par conséquent, la probabilité d’obtenir deux têtes lors de deux lancers d’une pièce est de ½ ½ = ¼. La probabilité d’obtenir un pile ou un face avec deux lancers est de ½, parce qu’il y a deux façons d’obtenir ce résultat : HT ou TH.\nÉvénements connexes. Si les événements ne sont pas indépendants (par exemple, le premier événement est un nombre compris entre 1 et 3 inclus lors du lancer d’un dé à six faces et le second événement est un nombre pair), la règle de multiplication s’applique également, mais vous devez multiplier la probabilité d’un événement par la probabilité conditionnelle du second.\nLorsqu’on lance un dé, la probabilité indépendante d’un nombre compris entre 1 et 3 est de \\(3/6 = 1/2\\), et la probabilité indépendante de tout nombre pair est également de \\(1/2\\) (les nombres pairs sont 2, 4 ou 6 divisés par les six résultats possibles).\nCependant, si vous avez déjà lancé un nombre de 1 à 3, la probabilité que cet ensemble restreint de résultats soit un nombre pair est de \\(1/3\\) (parce que “2” est le seul nombre pair possible dans cet ensemble de trois résultats). Par conséquent, la probabilité des deux événements liés est de \\(1/2 \\times 1/3 = 1/6\\). Vous pouvez examiner la situation dans l’autre sens : la probabilité d’obtenir un nombre pair en lançant un dé est de \\(1/2\\) (vous obtiendriez les nombres 2, 4 ou 6) et la probabilité que l’un de ces nombres soit compris entre 1 et 3 est de \\(1/3\\) (le nombre 2 parmi ces trois résultats). Par conséquent, la probabilité des deux résultats est à nouveau \\(1/2 \\times 1/3 = 1/6\\).\n\n\n\n\n\n\n\n\n\n\nNombre de boules noires\nNombre de boules blanches\nProbabilité\nPourcentage de cas pouvant donner ce resultat\n\n\n\n6\n0\n1/64\n1,56\n\n\n5\n1\n6/64\n9,38\n\n\n4\n2\n15/64\n23,44\n\n\n3\n3\n20/64\n31,25\n\n\n2\n4\n15/64\n23,44\n\n\n1\n5\n6/64\n9,38\n\n\n0\n6\n1/64\n1,56\n\n\nTotal\n\n64/64\n100\n\n\n\n\n\nLes nombres attendus de chaque mélange possible de couleurs lors du tirage indépendant de six perles avec remplacement à 64 occasions différentes à partir d’une grande population contenant 50 % de noires et 50 % de blanches.\n\nLa probabilité de n’obtenir aucune boule blanche sur 6 boules tirées est de 1,56%. On rejette l’hypothèse nulle \\(H_0\\) puisque \\(p &lt; 2,5\\%\\) (test bidirectionnel).\n\n1.2.3 Passage intermédiaire par une statistique\nDans la majorité des cas, on ne peut pas calculer directement la p-valeur. L’alternative est de calculer une statistique qui quantifie la différence entre les données observées et les données attendues sous \\(H_0\\). On calcule ensuite la p-valeur en comparant la valeur de la statistique à sa distribution théorique sous \\(H_0\\).\n\n1.2.3.1 Inférence à une moyenne\nOn peut par exemple être amené à comparer la moyenne d’un échantillon à la moyenne d’une population dont la variance est connue. Pour un tel test on a:\n\n\n\\(H_0\\): \\(\\mu = \\mu_0\\); \\(H_A\\): \\(\\mu ≠ \\mu_0\\).\n\nStatistique de test: \\(Z_{obs} = \\frac{\\bar{Y} - \\mu_0}{ESM} = \\frac{\\bar{Y} - \\mu_0}{\\frac{\\sigma}{\\sqrt{n}}} \\sim N(0, 1)\\)\n\n\n\n\n\n\n\n\nScore Z (Z-score)\nLe score Z est une mesure statistique qui quantifie la distance entre un point de données et la moyenne d’un ensemble de données. Il est exprimé en termes d’écarts types. Il indique le nombre d’écarts types d’un point de données par rapport à la moyenne de la distribution.\nSi un score Z est égal à 0, cela signifie que le score du point de données est identique au score moyen. Un score Z de 1,0 indique une valeur qui se situe à un écart-type de la moyenne. Les scores Z peuvent être positifs ou négatifs, une valeur positive indiquant que le score est supérieur à la moyenne et une valeur négative indiquant qu’il est inférieur à la moyenne.\n\\[ Z = \\frac{x - \\mu}{\\sigma}\\]\nErreur standard à la moyenne (ESM)\nLe terme “erreur” remplace celui de “déviation” quand on parle de la variation de moyennes plutôt que de la variation de mesures individuelles.\n\n\n\n\n1.2.3.2 Et si les paramètres sont inconnus ?\nSi on ne connaît pas la variance réelle de la population, il faut tenir compte des biais possibles dus à la taille de l’échantillon (n).\nOn a alors:\n\nStatistique de test (\\(S^2\\) est la variance de l’échantillon): \\(t_{obs} = \\frac{\\bar{X} - \\mu_0}{ESM} = \\frac{\\bar{X} - \\mu_0}{\\frac{S}{\\sqrt{n -1 }}} \\sim St(n-1)\\).\n\nDegrés de liberté: nombre d’observations dans l’échantillon libres de varier quand on estime la variance.\n\nPlus n est petit, plus la distribution est large car S sous-estime σ. Quand n = ∞, Student = Normale.\n\n1.2.4 Effet de la taille de l’échantillon (n)\nPlus l’échantillon est grand, plus la précision avec laquelle est connue la moyenne est importante. Intervalle de confiance à la moyenne réelle \\(\\mu\\): \\[ \\bar{Y} \\pm t_{1-\\alpha/2; n-1} . \\frac{S}{\\sqrt{n-1}}\\]\n\n\nL’effet de la taille de l’échantillon sur la précision et l’exactitude des valeurs de \\(\\bar{X}\\) en tant qu’estimations de \\(\\mu\\) (McKillup 2011)."
  },
  {
    "objectID": "intro.html#test-uni--vs-bidirectionnel",
    "href": "intro.html#test-uni--vs-bidirectionnel",
    "title": "\n1  Importance et notions de base\n",
    "section": "\n1.3 Test uni- vs bidirectionnel",
    "text": "1.3 Test uni- vs bidirectionnel\nL’hypothèse nulle est toujours “il n’existe pas de” différence/relation… Cela revient à dire qu’une certaine quantité est égale à 0. L’hypothèse alternative est soit:\n\nCette quantité est différente de 0 (test bidirectionnel);\n\nCette quantité est supérieure/inférieure à 0 (test unidirectionnel).\n\nAinsi on a:\n\nTest bidirectionnel:\n\n\n\\(H_0\\) : \\(\\mu = \\mu_0\\) ou \\(t = 0\\)\n\n\n\\(H_A\\) : \\(\\mu ≠ \\mu_0\\) ou \\(t ≠ 0\\)\n\n\n\nTest unidirectionnel:\n\n\n\\(H_0\\): \\(\\mu = \\mu_0\\) ou \\(t = 0\\)\n\n\n\\(H_{A1}\\): \\(\\mu &gt; \\mu_0\\) ou \\(t &gt; 0\\)\n\n\n\\(H_{A2}\\): \\(\\mu &lt; \\mu_0\\) ou \\(t &lt; 0\\)"
  },
  {
    "objectID": "intro.html#types-derreurs",
    "href": "intro.html#types-derreurs",
    "title": "\n1  Importance et notions de base\n",
    "section": "\n1.4 Types d’erreurs",
    "text": "1.4 Types d’erreurs\nQuand on prend une décision concernqnt une hypothèse sur la base d’un échantillon donné, on n’est jamais sûr de prendre la bonne décision!!.\n\n\nDécisions et erreurs statistiques lors des tests d’hypothèses nulles (“Hypothesis Testing” 2002).\n\nOn peut se tromper de 2 manières:\n\n\n\\(\\alpha\\) (probabilité d’erreur de type I: rejeter \\(H_0\\) à tort) est traditionnellement fixé à 5%. Rien n’empêche de choisir un \\(\\alpha\\) plus petit ou plus grand;\n\n\n\\(1 - \\beta\\) (probabilité d’erreur de type II: accepter \\(H_0\\) à tort) est la puissance du test. Elle dépend notamment de:\n\nLa taille de l’effet: plus l’effet est grand, plus la probabilité de le détecter est grande;\nLa variance: plus le paramètre est connu avec précision, plus la probabilité d’en détecter une différence est grande. La précision augmente avec le nombre d’observation."
  },
  {
    "objectID": "intro.html#compromis-entre-alpha-et-beta",
    "href": "intro.html#compromis-entre-alpha-et-beta",
    "title": "\n1  Importance et notions de base\n",
    "section": "\n1.5 Compromis entre \\(\\alpha\\) et \\(\\beta\\)\n",
    "text": "1.5 Compromis entre \\(\\alpha\\) et \\(\\beta\\)\n\nIl existe un compromis entre les probabilités d’erreur de type I (\\(\\alpha\\)) et de type II (\\(\\alpha\\)). Pour un même jeu de données, si on choisit de diminuer \\(\\alpha\\), on augmentera automatiquement \\(\\beta\\), et inversement.\n\n\nLe compromis entre l’erreur de type 1 et l’erreur de type 2. (a) fixé à 10 %. (b) L’abaissement à 5 % réduira le risque d’erreur de type 1, mais augmentera le risque d’erreur de type 2. (c) Une réduction à 1 % diminuera encore le risque d’erreur de type 1, mais augmentera fortement le risque d’erreur de type 2. (McKillup 2011)."
  },
  {
    "objectID": "intro.html#les-deux-grands-types-de-questions",
    "href": "intro.html#les-deux-grands-types-de-questions",
    "title": "\n1  Importance et notions de base\n",
    "section": "\n1.6 Les deux grands types de questions",
    "text": "1.6 Les deux grands types de questions\nOn peut différencier en général 3 types de jeux de données en fonction du nombre de variables mesurées sur chaque individu:\n\nUnivarié: une seule variable;\n\nBivarié: 2 variables;\n\nMultivarié: plus de 2 variables;\n\nOn peut différencier 2 grandes classes de questions:\n\nL’hypothèse porte sur l’existence de différence(s);\n\nL’hypothèse porte sur l’existence d’une relation entre variables."
  },
  {
    "objectID": "intro.html#les-grandes-classes-de-méthodes-danalyse",
    "href": "intro.html#les-grandes-classes-de-méthodes-danalyse",
    "title": "\n1  Importance et notions de base\n",
    "section": "\n1.7 Les grandes classes de méthodes d’analyse",
    "text": "1.7 Les grandes classes de méthodes d’analyse\n\n\n\n\n\n“Hypothesis Testing.” 2002. In, 32–57. Cambridge University Press. https://doi.org/10.1017/cbo9780511806384.004.\n\n\nMcKillup, Steve. 2011. “Statistics Explained,” November. https://doi.org/10.1017/cbo9781139047500."
  },
  {
    "objectID": "chapter1.html#architecture-de-von-neuman",
    "href": "chapter1.html#architecture-de-von-neuman",
    "title": "2  Partie matérielle de l’ordinateur",
    "section": "2.1 Architecture de Von Neuman",
    "text": "2.1 Architecture de Von Neuman\nL’architecture de von Neumann est un modèle structurel d’ordinateur dans lequel une unité de stockage (mémoire) unique sert à conserver à la fois les instructions et les données demandées ou produites par le calcul. Les ordinateurs actuels sont tous basés sur des versions améliorées de cette architecture.\n\n\n\nFigure 2.1: Architecture de Von Neuman\n\n\nL’architecture de von Neumann décompose l’ordinateur en 4 parties distinctes:\n- l’unité arithmétique et logique (UAL ou ALU en anglais) ou unité de traitement: son rôle est d’effectuer les opérations de base;\n- l’unité de contrôle ou de commande (control unit), chargée du « séquençage » des opérations;\n- la mémoire qui contient à la fois les données et le programme qui indiquera à l’unité de contrôle quels sont les calculs à faire sur ces données;\n- les dispositifs d’entrée-sortie, qui permettent de communiquer avec le monde extérieur."
  },
  {
    "objectID": "chapter1.html#composantes-dun-ordinateur",
    "href": "chapter1.html#composantes-dun-ordinateur",
    "title": "2  Partie matérielle de l’ordinateur",
    "section": "2.2 Composantes d’un ordinateur",
    "text": "2.2 Composantes d’un ordinateur\n\n2.2.1 L’unité centrale\nL’unité centrale, c’est l’organe principal de l’ordinateur, elle renferme plusieurs composants destinés au traitement et à la circulation de l’information. Dans l’unité centrale, on trouve:\n- le bloc d’alimentation;\n- la carte mère (microprocesseur, mémoire centrale, mémoire morte, l’horloge…);\n- les mémoires de masses (disque dur, lecteurs de CD-ROM…);\n- les cartes additionnelles (carte réseau, carte son, carte vidéo, …).\n\n2.2.1.1 Le bloc d’alimentation\nLe boîtier héberge un bloc d’alimentation électrique, chargé de fournir un courant électrique stable et continu à l’ensemble des éléments de l’ordinateur.\n\n\n\n\n\n\n\nExemple 1\n\n\n\n\n\n\n\nExemple 2\n\n\n\n\nFigure 2.2: Bloc d’alimentation\n\n\n\n\n2.2.1.2 Carte mère\nLa carte mère (motherboard en anglais) est le circuit imprimé principal de l’ordinateur. Sur cette carte, tous les composants du PC sont connectés. La carte mère contient entre autres : le socket (connecteur) pour le processeur, des supports mémoire vive, des ports pour les cartes d’extension.\n\n\n\nFigure 2.3: Carte mère\n\n\n\n\n2.2.1.3 Microprocesseur\nLe microprocesseur (CPU : Central Processing Unit ou Unité Centrale de Traitement) est le cerveau de l’ordinateur. Il permet de manipuler, de circuler les informations et d’exécuter les instructions stockées en mémoire. Toute l’activité de l’ordinateur est cadencée par une horloge unique.\n\n\n\nFigure 2.4: Microprocesseur\n\n\nLe microprocesseur est caractérisé par la cadence maximale à laquelle il est capable de travailler, par la taille et le nombre de données qu’il peut manipuler. Plus la circulation des données est rapide, plus l’ordinateur sera jugé performant.\nOn emploie généralement les termes suivants:\n- Fréquence de l’horloge: la fréquence de l’horloge de la carte mère qui cadence le microprocesseur;\n- Largeur des données: Le premier nombre indique le nombre de bits sur lequel une opération est faite. Le second nombre indique le nombre de bits transférés à la fois entre la mémoire et le microprocesseur;\n- MIPS: le nombre de millions d’instructions complétées par le microprocesseur en une seconde.\n\n\n\nDate\nProcesseur / Système\nFrquence de l’horloge\nMIPS\nSource\n\n\n\n\n1951\nUNIVAC I\n2,25 MHz\n0,002\n\n\n\n1981\nMotorola 6802\n3,58 MHz\n0,5\nsource\n\n\n1991\nIntel i860\n50 MHz\n50\nsource\n\n\n1994\nIntel DX4\n100 MHz\n70\n\n\n\n1994\nIntel Pentium\n100 MHz\n188\n\n\n\n1996\nIntel Pentium Pro\n200 MHz\n541\n\n\n\n1999\nIntel Pentium III\n600 MHz\n2054\n\n\n\n2003\nIntel Pentium 4 Extreme Edition\n3,2 GHz\n9726\n\n\n\n2008\nIntel Core i7 920 (4-core)\n2,93 GHz\n82300\n\n\n\n2011\nIntel Core i7 875K\n2,93 GHz\n92100\n\n\n\n2016\nIntel Core i7 6950X (10-core)\n3,5 GHz\n320440\n\n\n\n2021\nIntel Core i5-11600K (6-core)\n4,92 GHz\n346350\n\n\n\n\nLe microprocesseur Figure 2.4 est constitué:\n- d’une unité de commande qui est responsable de la lecture en mémoire et du décodage des instructions;\n- d’une unité de traitement (Unité Arithmétique et Logique (U.A.L.)) qui exécute les instructions.\n\n2.2.1.3.1 L’unité de commande\nL’unité de commande est constituée de plusieurs organes qui permettent la recherche en mémoire et le décodage d’une instruction. L’unité de commande est constituée des éléments suivants:\n- Le compteur ordinal: c’est un registre contenant l’adresse de l’instruction en cours;\n- Le registre d’instruction: il contient l’instruction suivante;\n- Le décodeur d’instructions: c’est un dispositif qui traduit le code de l’instruction reçu en signaux qui sont transmis au séquenceur;\n- Le séquenceur: il est chargé de synchroniser l’exécution des instructions à la cadence de l’horloge. Il est ainsi chargé de l’envoi des signaux de commande.\n\n\n2.2.1.3.2 L’unité de traitement\nCette unité utilise les données stockées en mémoire, effectue des calculs dont les résultats sont eux aussi stockées en mémoire ou acheminés vers un périphérique de sortie.\n\n\n\n2.2.1.4 La mémoire\nLa mémoire est un composant de base de l’ordinateur, son rôle est de stocker les données avant et pendant leur traitement par le processeur. Ces données sont d’apparence binaire et mémorisées sous forme d’impulsions électriques (une impulsion est égale à 1, aucune impulsion est égale à 0 ou l’inverse).\n\n2.2.1.4.1 Mémoire vive\nLa mémoire vive appelée également mémoire centrale ou RAM (Random Access Memory) permet de stocker temporairement les données et programmes en cours de traitement. Les données contenues dans la mémoire vive sont perdues lorsque le courant électrique est coupé. La mémoire vive se présente sous la forme de barrettes qu’on insère dans un connecteur de la carte mère. On peut souvent augmenter la taille mémoire en ajoutant des barrettes de RAM.\nLes caractéristiques de la mémoire vive sont:\n- sa rapidité d’accès : cette rapidité est essentielle pour fournir rapidement les données au processeur;\n- sa volatilité : cette volatilité implique que les données sont perdues dès que l’alimentation électrique est coupée.\nPour mesurer la taille mémoire, on utilise l’Octet:\n- Un octet = 8 bits;\n- Un kilo-octet (Ko) = 1024 octets ≈ 103 octets;\n- Un méga-octet (Mo) = (1024)2 octets ≈ 106 octets;\n- Un giga-octet (Go) = (1024)3 octets ≈ 109 octets;\n- Un tera-octet (To) = (1024)4 octets ≈ 1012 octets;\nOn peut aussi parler de Kbits, Mbits, Gbits. 1Kbits = 103 bits, 1Mbits= 103 kbits, 1 Gbits= 103 Mbits.\n\n\n2.2.1.4.2 Mémoire morte\nLa mémoire morte (en anglais ROM = Read Only Memory) est une mémoire en lecture seule, appelée aussi mémoire non volatile, c’est-à-dire une mémoire qui ne s’efface pas à l’extinction de l’ordinateur. Elle stocke le programme de base pour démarrer et utiliser un ordinateur (le BIOS : Basic Input Output System).\n\n\n2.2.1.4.3 Mémoire cache\nLa mémoire cache est une petite mémoire à accès rapide qui sert de tampon entre la mémoire vive et le processeur. Elle stocke les informations les plus souvent utilisées, permettant ainsi de réduire les états d’attente du microprocesseur. Lorsque le microprocesseur veut traiter des données, il accède d’abord au cache interne, s’il ne trouve pas les données, il accède au cache externe, puis à la RAM. On distingue deux types de caches:\n- Cache interne: c’est une mémoire ultra rapide intégrée au microprocesseur. Elle stocke les données les plus utilisées;\n- Cache externe: si le microprocesseur ne trouve pas les données dans la cache interne, il les cherche dans la cache externe. La cache externe est moins rapide que la cache interne mais plus rapide que la RAM.\nLe processeur est plus rapide que la mémoire RAM, celle-ci est beaucoup plus rapide que le disque dur. Une cache disque est utilisée entre le disque dur et la mémoire, lorsque l’ordinateur écrit sur le disque, les données sont placées dans la cache disque, elles sont alors écrites lentement (à la vitesse maximale du disque dur) alors que l’ordinateur peut s’occuper à faire autre chose. Lorsque l’ordinateur désire lire sur le disque, le cache disque peut avoir lu d’avance ou posséder des données lues auparavant, celles-ci sont alors tirées directement de la cache disque sans avoir à passer par le disque dur. Non seulement l’ordinateur peut-il lui même utiliser une partie de sa mémoire RAM comme cache entre lui et le disque dur (cache logicielle), mais les concepteurs de disques durs ont également ajouté une petite quantité de mémoire directement sur les contrôleurs de disques durs comme cache (cache matérielle) et c’est la norme actuellement dans la fabrication des disques dur.\n\n\n\n2.2.1.5 Les bus\nLes bus constituent le système de communication central de l’ordinateur. Ils relient le processeur à la mémoire centrale et aux cartes d’extensions, c’est par leur intermédiaire que transitent toutes les informations entre les différents composants d’un ordinateur. On distingue trois types de bus :\n- Le bus de données transférant les données entre le processeur et les autres parties. C’est un bus bidirectionnel;\n- Le bus d’adresses par lequel le processeur indique l’adresse mémoire à laquelle sont écrites ou lues les données;\n- Le bus de commande (ou contrôle) par lequel le processeur envoie des codes de commande aux différents organes.\nOn a par exemple:\n- Le bus système: appelé aussi FSB (Front Side Bus). C’est le bus qui assure le transport de données entre le processeur et la mémoire vive;\n- Le bus série : c’est le bus que tous les PC possèdent, celui qui débouche sur le port servant à brancher une souris ou un modem, ou encore certains périphériques de jeux. Ses défauts sont sa lenteur extrême car les données ne sont envoyées que bit par bit (0 ou 1); - Le bus parallèle: c’est le bus qui communique avec le port parallèle, qui sert à brancher l’imprimante, le scanner, des graveurs externes, etc. Il est 8 fois plus rapide que le port série (les informations sont transmises par tranche de 8 bits en parallèle, soit 1 octet à la fois), mais toujours lent si on le compare aux bus USB;\n- Le bus USB (Universal Serial Bus) : il est largement plus rapide que le bus parallèle et peut aller à la vitesse de 1.5 Mo par seconde pour l’USB 1.1. L’USB 2.0 peut quant à lui monter à 60 Mo par seconde et l’USB 3.0 jusqu’à 500 MB par seconde. Il est relié au port USB qui sert à brancher presque tous les périphériques du marché : webcams, modems, imprimantes, scanners, etc.\n- Le bus AGP (accelerated graphic port) : Il est apparu avec le Pentium II en 1997. Il permet de traiter 32 bits à la fois et à une fréquence de bus de 66 MHz. Ses qualités sont sa rapidité (500 Mo par seconde pour le 2 X et 1 Go pour le 4 X, et maintenant 2 Go par seconde pour le 8x). Il communique avec le port AGP;\n\n\n2.2.1.6 Connecteurs d’extension\nLes connecteurs d’extension sont des emplacements disponibles sur la carte mère destinés à recevoir des cartes d’extension, c’est-à-dire des cartes offrant de nouvelles fonctionnalités à l’ordinateur. Il existe plusieurs sortes de connecteurs:\n- Connecteur d’extension AGP : (Accelerated Graphics Port) est l’emplacement réservé à la carte graphique;\n- Connecteurs d’extension PCI : (Peripheral Component Interconnect) est l’emplacement où sont connectées les différentes cartes de votre ordinateur (carte son, carte réseau, etc.).\nParmi les cartes d’extension les plus courantes, on peut citer:\n- Carte graphique : est une carte d’extension dont le rôle est de produire une image affichable sur un moniteur d’ordinateur;\n- Carte son : est une carte d’extension permettant d’écouter de la musique et des sons sur votre ordinateur. Elle s’implante dans un connecteur PCI;\n- Carte réseau : est une carte d’extension permettant de connecter un ordinateur à un réseau.\n\n\n2.2.1.7 Ports de communication\nLes ports d’entrée-sortie sont des éléments matériels de l’ordinateur, permettant au système de communiquer avec des éléments extérieurs, c’est-à-dire d’échanger des données, d’où l’appellation d’interface d’entrée-sortie.\n\n2.2.1.7.1 Ports série\nLe port série est un port sur lequel on ne peut envoyer les données que bit par bit, les uns après les autres. Ce port peut se présenter sous la forme d’un connecteur 9 ou 25 broches (le nom du connecteur est DB-9 ou DB-25 suivant le nombre de broches). Sur un port série on peut brancher un modem, un scanner, une souris ou un appareil photo numérique.\n\n\n\nPort série\n\n\n\n\n2.2.1.7.2 Port parallèle\nLe port parallèle est basé sur un transfert de type parallèle. C’est-à-dire que les 8 bits d’un octet sont envoyés simultanément. Ce type de communication est nettement plus rapide que celui d’un port série. Un port parallèle permet de connecter une imprimante.\n\n\n\nPort parallèle\n\n\n\n\n2.2.1.7.3 Port USB\nLe port USB (Universal Serial Bus) est basé sur une architecture série pour deux raisons principales:\n- L’interface série permet d’utiliser une cadence d’horloge beaucoup plus élevée qu’une interface parallèle (dans une architecture parallèle à haut débit, les bits circulant sur chaque fil arrivent avec des décalages, provoquant des erreurs);\n- Le câble série est plus économique que le câble parallèle.\nLes ports USB supportent le Hot Plug & Play, c’est-à-dire qu’un périphérique peut être connecté et reconnu, sans redémarrage de l’ordinateur. Les périphériques qui disposent actuellement de ce type de port sont les imprimantes, scanners, Webcams, etc.\n\n\n\n\n2.2.2 Les unités de stockage\nUne mémoire de masse est une mémoire de grande capacité, non volatile. Elle conserve les données de manière permanente. Les mémoires de masse les plus utilisées sont :\n- le disque dur pour les informations qui devront être traitées ultérieurement;\n- le CD-ROM et le DVD pour les copies de sauvegarde;\n- la clé USB et disquette pour le transfert d’information entre micro-ordinateurs.\n\n2.2.2.1 Le disque dur\nLe disque dur est un support composé de disques magnétiques sur lesquels on peut stocker de très grandes quantités d’informations (20 Go, 40 Go, 80 Go, 120 Go, …). Un disque dur est formé de plusieurs plateaux circulaires superposés entre lesquels flottent des têtes de lecture et écriture et d’un moteur central permettant la rotation de tous les plateaux en même temps.\n\n\n\nDisque dur\n\n\nChaque plateau est composé de pistes concentriques. Les pistes situées à un même rayon forment un cylindre. Les pistes sont ensuite découpées en secteurs qui sont l’unité élémentaire de stockage et dont la taille est de 512 octets. Les caractéristiques principales d’un disque dur sont les suivantes:\n- Capacité: volume de données pouvant être stockées sur le disque;\n- Taux de transfert (ou débit): quantité de données pouvant être lues ou écrites sur le disque par unité de temps. Il s’exprime en bits par seconde;\n- Vitesse de rotation: vitesse à laquelle les plateaux tournent, exprimée en nombre de tours par minute. La vitesse des disques durs est de l’ordre de 7200 à 15000 rpm (rpm : Rotation Par Minute).\nCalcul de la taille (capacité) d’un disque dur:\n\\[Capacité = Nt \\times Nc \\times Ns \\times 512 o\\]\nOu:\n- Nt: nombre de têtes (ou de faces)\n- Nc: nombre de cylindres\n- Ns: nombre de secteurs\n- o: octets\n\n\n2.2.2.2 Le lecteur CD-ROM\nLe lecteur CD-ROM permet de lire les informations se trouvant sur les disques CD-ROM. Le CD-ROM (Compact Disc - Read Only Memory) est une mémoire de masse à lecture seule, les données y ont été inscrites une fois pour toute. On ne peut plus effacer leur contenu. Le CD-ROM est un disque optique de 12 cm de diamètre et de 1mm d’épaisseur, permettant de stocker des informations numériques correspondant à 650 Mo de données informatiques. Un trou circulaire en son milieu permet de le centrer sur la platine de lecture. Un lecteur CD-ROM est caractérisé par les éléments suivants:\n- Vitesse : la vitesse d’un lecteur de CD-ROM est calculée par rapport à la vitesse d’un lecteur de CD audio. Un CD audio lit 150 Ko/s par seconde (1x). Un lecteur de CD-ROM capable de lire 30000 Ko/s sera appelé un lecteur 20x. Remarque : Le X représente une vitesse de 150 Ko/s, ce qui signifie qu’un lecteur de CD 2X à un débit de 2150= 300 Ko/s alors qu’un lecteur de CD Rom 40X a un débit de 40 150 = 6 000 Ko/s.\n- Temps d’accès : est le temps moyen pour aller d’une partie du CD à une autre.\n\n\n2.2.2.3 Le graveur\nLe graveur de CD-ROM est un outil qui permet de réaliser des sauvegardes sur des CD-ROM. Il utilise deux sortes de disques : CD-R et CD-RW. Un graveur CD/DVD permet de lire ou graver des DVD, des CD audio et des CD de données.\n\n\n2.2.2.4 Clé USB\nCe sont des lecteurs amovibles. Branchés sur un port USB, elles peuvent s’ajouter à tout moment sur un ordinateur allumé. Très pratique pour transférer des informations d’un ordinateur à l’autre.\n\n\n\n2.2.3 Les périphériques d’entrées/sorties\n\n2.2.3.1 Clavier\nLe clavier est un périphérique d’entrée (figure suivante). Il vous permet d’entrer du texte, des chiffres ou des commandes dans votre ordinateur. Il peut être AZERTY, QWERTY ou autre. On désigne par ces noms les “langues” des claviers dont les français ou anglais dont les premières touches sont A,Z,E,R,T,Y et Q,W,E,R,T,Y.\n\n\n\nClavier\n\n\nUn clavier comporte 4 grandes zones:\n- Le pavé numérique, rendu actif par la touche Verr num (contrôlée par un voyant), composé des 10 chiffres et des 4 opérations, ainsi que d’une touche entrée spécifique;\n- Le bloc alphanumérique comporte toutes les lettres de l’alphabet, les 10 chiffres, les signes de ponctuation, la barre d’espace et divers autres symboles d’usage courant;\n- Le pavé de flèches qui servent à déplacer le curseur en tous sens (gauche, droite, haut, bas), à sauter de page en page, à se positionner au début ou à la fin, à insérer ou supprimer;\n- Les touches de fonction de F1 à F12 sont associées à des commandes. Ces touches spéciales permettent d’exécuter plus efficacement des tâches particulières. Les opérations réalisées par ces touches dépendent du logiciel utilisé. Par exemple, la touche F1 sert généralement à afficher l’aide sur l’utilisation du logiciel en cours.\n\n\n2.2.3.2 Souris\nLa souris (périphérique d’entrée) est un périphérique de pointage servant à déplacer un curseur sur l’écran et permettant de sélectionner, déplacer, manipuler des objets grâce à des boutons:\n\nLe bouton gauche:\n\nCliquer (clic) est l’action consistant à appuyer une seule fois sur le bouton gauche de la souris, il permet de sélectionner une icône sur le bureau, sélectionner une commande à l’intérieur d’un menu, etc.\n\nDouble cliquer est l’action de cliquer deux fois brièvement sur le bouton gauche de la souris. Cela provoque, sur une icône, l’ouverture d’une fenêtre ou le lancement d’un programme.\n\nGlisser déplacer : indique le déplacement d’un objet en maintenant le bouton gauche enfoncé et en déplaçant la souris.\n\nLe bouton droit : Permet d’ouvrir un “menu contextuel” en rapport avec la situation du pointeur ou l’objet sélectionné.\n\n\nLe bouton droit: Permet d’ouvrir un “menu contextuel” en rapport avec la situation du pointeur ou l’objet sélectionné.\n\nMolette: Elle permet de monter et de descendre rapidement dans l’affichage d’un document.\n\n\n\n2.2.3.3 L’ecran\nL’écran est un périphérique de sortie qui permet d’afficher du texte et des images traités par l’ordinateur. Il se caractérise par les paramètres suivants:\n\nLa taille de l’écran : Elle se mesure en “pouces” (1 pouce = 2,54 cm) et correspond à la mesure de la diagonale de l’écran.\n\nLa résolution de l’écran : Elle représente le nombre de points que l’écran peut afficher. Elle indique le nombre de pixels (points) affichable à l’écran. Elle est donnée en fonction du nombre de points sur la largeur, suivi de celle en hauteur. Ce nombre de points est actuellement généralement compris entre 640x480 (640 points en longueur, 480 points en largeur) et 1600x1200."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "“Hypothesis Testing.” 2002. In, 32–57. Cambridge University\nPress. https://doi.org/10.1017/cbo9780511806384.004.\n\n\nMcKillup, Steve. 2011. “Statistics Explained,” November. https://doi.org/10.1017/cbo9781139047500."
  },
  {
    "objectID": "intro1.html#test-uni--vs-bidirectionnel",
    "href": "intro1.html#test-uni--vs-bidirectionnel",
    "title": "1  Pourquoi a-t-on besoin de méthodes statistiques ?",
    "section": "1.4 Test uni- vs bidirectionnel",
    "text": "1.4 Test uni- vs bidirectionnel\nL’hypothèse nulle est toujours “il n’existe pas de” différence/relation… Cela revient à dire qu’une certaine quantité est égale à 0. L’hypothèse alternative est soit:\n\nCette quantité est différente de 0 (test bidirectionnel);\n\nCette quantité est supérieure/inférieure à 0 (test unidirectionnel).\n\nAinsi on a:\n\nTest bidirectionnel:\n\n\\(H_0\\) : \\(\\mu = \\mu_0\\) ou \\(t = 0\\)\n\\(H_A\\) : \\(\\mu ≠ \\mu_0\\) ou \\(t ≠ 0\\)\n\nTest unidirectionnel:\n\n\\(H_0\\): \\(\\mu = \\mu_0\\) ou \\(t = 0\\)\n\\(H_{A1}\\): \\(\\mu &gt; \\mu_0\\) ou \\(t &gt; 0\\)\n\\(H_{A2}\\): \\(\\mu &lt; \\mu_0\\) ou \\(t &lt; 0\\)"
  },
  {
    "objectID": "intro1.html#types-derreurs",
    "href": "intro1.html#types-derreurs",
    "title": "1  Pourquoi a-t-on besoin de méthodes statistiques ?",
    "section": "1.5 Types d’erreurs",
    "text": "1.5 Types d’erreurs\nQuand on prend une décision concernqnt une hypothèse sur la base d’un échantillon donné, on n’est jamais sûr de prendre la bonne décision!!.\n\n\n\nDécisions et erreurs statistiques lors des tests d’hypothèses nulles (“Hypothesis Testing” 2002).\n\n\nOn peut se tromper de 2 manières:\n\n\\(\\alpha\\) (probabilité d’erreur de type I: rejeter \\(H_0\\) à tort) est traditionnellement fixé à 5%. Rien n’empêche de choisir un \\(\\alpha\\) plus petit ou plus grand;\n\n\\(1 - \\beta\\) (probabilité d’erreur de type II: accepter \\(H_0\\) à tort) est la puissance du test. Elle dépend notamment de:\n\nLa taille de l’effet: plus l’effet est grand, plus la probabilité de le détecter est grande;\nLa variance: plus le paramètre est connu avec précision, plus la probabilité d’en détecter une différence est grande. La précision augmente avec le nombre d’observation."
  },
  {
    "objectID": "intro1.html#compromis-entre-alpha-et-beta",
    "href": "intro1.html#compromis-entre-alpha-et-beta",
    "title": "1  Pourquoi a-t-on besoin de méthodes statistiques ?",
    "section": "1.6 Compromis entre \\(\\alpha\\) et \\(\\beta\\)",
    "text": "1.6 Compromis entre \\(\\alpha\\) et \\(\\beta\\)\nIl existe un compromis entre les probabilités d’erreur de type I (\\(\\alpha\\)) et de type II (\\(\\alpha\\)). Pour un même jeu de données, si on choisit de diminuer \\(\\alpha\\), on augmentera automatiquement \\(\\beta\\), et inversement.\n\n\n\nLe compromis entre l’erreur de type 1 et l’erreur de type 2. (a) fixé à 10 %. (b) L’abaissement à 5 % réduira le risque d’erreur de type 1, mais augmentera le risque d’erreur de type 2. (c) Une réduction à 1 % diminuera encore le risque d’erreur de type 1, mais augmentera fortement le risque d’erreur de type 2. (McKillup 2011)."
  },
  {
    "objectID": "intro1.html#les-deux-grands-types-de-questions",
    "href": "intro1.html#les-deux-grands-types-de-questions",
    "title": "1  Pourquoi a-t-on besoin de méthodes statistiques ?",
    "section": "1.7 Les deux grands types de questions",
    "text": "1.7 Les deux grands types de questions\nOn peut différencier en général 3 types de jeux de données en fonction du nombre de variables mesurées sur chaque individu:\n\nUnivarié: une seule variable;\n\nBivarié: 2 variables;\n\nMultivarié: plus de 2 variables;\n\nOn peut différencier 2 grandes classes de questions:\n\nL’hypothèse porte sur l’existence de différence(s);\n\nL’hypothèse porte sur l’existence d’une relation entre variables."
  },
  {
    "objectID": "intro1.html#les-grandes-classes-de-méthodes-danalyse",
    "href": "intro1.html#les-grandes-classes-de-méthodes-danalyse",
    "title": "1  Pourquoi a-t-on besoin de méthodes statistiques ?",
    "section": "1.8 Les grandes classes de méthodes d’analyse",
    "text": "1.8 Les grandes classes de méthodes d’analyse\n\n\n\n\n\n“Hypothesis Testing.” 2002. In, 32–57. Cambridge University Press. https://doi.org/10.1017/cbo9780511806384.004.\n\n\nMcKillup, Steve. 2011. “Statistics Explained,” November. https://doi.org/10.1017/cbo9781139047500.\n\n\nPopper, Karl. 2005. The Logic of Scientific Discovery. Routledge. https://doi.org/10.4324/9780203994627."
  },
  {
    "objectID": "intro2.html#rappels-sur-les-notions-de-base",
    "href": "intro2.html#rappels-sur-les-notions-de-base",
    "title": "\n2  Importance et notions de base\n",
    "section": "\n2.1 Rappels sur les notions de base",
    "text": "2.1 Rappels sur les notions de base\n\n2.1.1 Types de statistiques\n\n\nDescriptives: le but est d’illustrer les données;\n\n\nParamétriques: on suppose que la/les variables(s) suivent une distribution particulière;\n\n\nNon paramétriques: on ne fait aucune supposition concernant la distribution de la/les variables(s).\n\n2.1.2 Variables\n\nUne variable est un attribut mesuré pour chaque individu/observation.\n\nTypes d’échelle de mesure:\n\nRatio: le 0 est clairement défini; ne peut pas être &lt; 0.\n\nIntervalle: le 0 est arbitraire; peut être &lt; 0.\n\nOrdinale: l’ordre est défini; les rangs n’indiquent pas nécessairement des différentes constantes.\n\nNominale/Catégorique: l’ordre est non défini.\n\nContinue: présente une infinité de valeurs possibles.\n\nDiscrète: nombre limité de valeurs possibles.\n\n\n\n2.1.3 Qu’est-ce qu’une distribution?\nUne fonction qui exprime la fréquence (densité de probabilité) des différentes valeurs pouvant être prise par une variable.\nRappelons ici quelques distributions usuelles.\n\n2.1.3.1 Distribution uniforme (continue)\nBien que les origines historiques de la conception de la distribution uniforme ne soient pas concluantes, on suppose que le terme “uniforme” est né du concept d’équiprobabilité dans les jeux de dés (notez que les jeux de dés auraient un espace d’échantillonnage uniforme discret et non continu).\nLes paramètres de la distribution uniforme sont:\n\nMoyenne: \\(\\frac{1}{2}(a + b)\\).\n\nVariance: \\(\\frac{1}{12}(b - a)^2\\).\n\nLa fonction de densité de la loi uniforme est:\n\\[\nf(x) = \\left\\{\\begin{array}{ll}\\frac{1}{b - a} & \\mbox{for } a \\leq x \\leq b, \\\\ 0 & \\mbox{otherwise}\\end{array}\\right.\n\\]\n\n\n\n\n\n\n2.1.3.2 Distribution binomiale\nLa distribution binomiale est fréquemment utilisée pour modéliser le nombre de succès dans un échantillon de taille \\(n\\) tiré avec remplacement d’une population de taille \\(N\\).\nLes paramètres de la distribution binomiale sont:\n\nMoyenne: \\(\\mu = np\\).\nVariance: \\(\\sigma^2 = npq\\).\n\nLa fonction de densité de la loi binomiale est:\n\\[\nf(k, n, p) = \\binom{n}{k}p^k (1-p)^{n-k}\n\\]\n\n\n\n\n\n\n2.1.3.3 Distribution de Poisson\nLa distribution de Poisson est une distribution de probabilité discrète qui exprime la probabilité qu’un nombre donné d’événements se produisent dans un intervalle de temps fixe si ces événements se produisent avec un taux moyen constant connu et indépendamment du temps écoulé depuis le dernier événement.\nLes paramètres de la distribution de Poisson sont:\n\nMoyenne: \\(\\mu = \\lambda\\)\nVariance: \\(\\sigma^2 = \\lambda\\)\n\nLa fonction de densité de probabilité de la distribution de Poisson est:\n\\[\nf(k; \\lambda) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\n\\]\n\n\n\n\n\n\n2.1.3.4 Distribution normale\nLes distributions normales sont importantes en statistique et sont souvent utilisées dans les sciences naturelles et sociales pour représenter des variables aléatoires à valeur réelle dont la distribution n’est pas connue. Leur importance est en partie due au théorème de la limite centrale. Ce théorème stipule que, sous certaines conditions, la moyenne de nombreux échantillons (observations) d’une variable aléatoire de moyenne et de variance finies est elle-même une variable aléatoire, dont la distribution converge vers une distribution normale à mesure que le nombre d’échantillons augmente. Par conséquent, les quantités physiques qui sont censées être la somme de nombreux processus indépendants, tels que les erreurs de mesure, ont souvent des distributions qui sont presque normales.\nLes paramètres de la distribution normale sont:\n\nMoyenne: \\(\\mu = \\frac{\\sum_{i=1}^{N} X_i}{N}\\).\nVariance: \\(\\sigma^2 = \\frac{\\sum (X_i - \\mu)^2}{N}\\).\n\nLa fonction de densité de la loi normale est:\n\\[ f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}\\]\n\n\n\n\n\n\n\n\n\n\n\nPoints clés à retenir\n\n\n\n\nLa distribution normale est le terme approprié pour désigner une courbe de probabilité en cloche.\nDans une distribution normale, la moyenne est égale à zéro et l’écart-type est de 1. L’asymétrie est nulle et l’aplatissement est de 3.\nLes distributions normales sont symétriques, mais toutes les distributions symétriques ne sont pas normales.\n\n\n\n\n2.1.3.5 Distribution \\(t\\) de Student\nEn probabilité et en statistique, la distribution \\(t\\) de Student (ou simplement la distribution \\(t\\)) \\(t_\\nu\\) est une distribution de probabilité continue qui généralise la distribution normale standard. Comme cette dernière, elle est symétrique autour de zéro et en forme de cloche.\nLes paramètres de la distribution \\(t\\) de Student sont:\n\nMoyenne: 0 pour \\(\\nu &gt; 1\\) et indéfini dans le cas contraire.\nVariance: \\(\\frac{\\nu}{\\nu - 2}\\) pour \\(\\nu &gt; 2\\), \\(\\infty\\) pour \\(1 &lt; \\nu \\leq 2\\), indéfini dans les cas contraires.\n\nLa fonction de densité de probabilité de la distribution de \\(t\\) est:\n\\[\nf(t) = \\frac{\\Gamma(\\frac{\\nu + 1}{2})}{\\sqrt{\\pi \\nu} \\Gamma(\\frac{\\nu}{2})} (1 + \\frac{t^2}{\\nu}) ^ {-(\\nu + 1)/2}\n\\]\nou \\(\\nu\\) est le nombre de dégrés de libertés et \\(\\Gamma\\) est la fonction Gamma.\n\n\n\n\n\nLa distribution t de Student avec \\(\\nu\\) degrés de liberté peut être définie comme la distribution de la variable aléatoire \\(T\\) avec \\[T = \\frac{Z}{\\sqrt{V/\\nu}} = Z\\sqrt{\\frac{\\nu}{V}}\\]\navec\n\n\\(Z\\) est une normale standard avec une valeur attendue de 0 et une variance de 1 ;\n\\(V\\) suit une distribution de khi-deux (\\(\\chi^2\\)) avec \\(\\nu\\) dégrés de liberté;\n\\(Z\\) et \\(V\\) sont indépendants.\n\n\n\n\n\n\n\nPoints clés à retenir\n\n\n\n\nLa distribution \\(t\\) est une distribution de probabilité continue du score z lorsque l’écart-type estimé est utilisé au dénominateur plutôt que l’écart-type réel.\nLa distribution \\(t\\), comme la distribution normale, est en forme de cloche et symétrique, mais ses queues sont plus lourdes, ce qui signifie qu’elle a tendance à produire des valeurs très éloignées de sa moyenne.\nLes tests T sont utilisés en statistique pour estimer l’importance des résultats."
  },
  {
    "objectID": "intro2.html#pourquoi-a-t-on-besoin-de-méthodes-statistiques",
    "href": "intro2.html#pourquoi-a-t-on-besoin-de-méthodes-statistiques",
    "title": "\n2  Importance et notions de base\n",
    "section": "\n2.2 Pourquoi a-t-on besoin de méthodes statistiques ?",
    "text": "2.2 Pourquoi a-t-on besoin de méthodes statistiques ?\nLa plupart des sciences sont comparatives. Les chercheurs ont souvent besoin de savoir si un traitement expérimental particulier a eu un effet, ou s’il existe des différences entre une variable particulière mesurée à plusieurs endroits différents. Par exemple, un nouveau médicament a-t-il un effet sur la tension artérielle, un régime riche en vitamine C réduit-il le risque de cancer du foie chez l’homme, ou existe-t-il une relation entre la couverture végétale et la densité de la population de lapins ? Mais lorsque vous faites ce genre de comparaisons, les différences entre les traitements ou entre les zones échantillonnées peuvent être réelles ou peuvent simplement être le type de variation qui se produit par hasard entre les échantillons d’une même population.\nPrenons 2 situations concrètes:\n\nDans la première, nous jouons à pile ou face avec 10 pièces. On obtient après un lancer unique de chacune des pièces 3 faces et 7 piles. Pouvons-nous dire si ce lot de pièces est truqué?\n\nDans la seconde, on échantillone une population de singes, et on observe 32 femelles et 54 mâles. Y a-t-il réellement plus de mâles dans la population?\n\nLes probabilités vous aident à prendre une décision concernant vos résultats.\n\n2.2.1 Tests statistiques et niveaux de signification\nUn test statistique est une aide à la décision concernant une hypothèse (alternative vs nulle).\nL’idée maîtresse à la base de tout test d’hypothèse statistique:\n\nJe suppose que \\(H_0\\) (hypothèse nulle) est vraie (pas de différence/relation);\n\nJe calcule la p-valeur, c’est à dire la probabilité d’obtenir une différence/relation au moins aussi forte que celle que j’ai observée dans mon échantillon (qui est un fait établi);\n\nSi cette p-valeur est faible, alors il est probable que \\(H_0\\) soit fausse: la différence mesurée est simplement une mauvaise estimation d’une différence nulle.\n\nLe statisticien Sir Ronald Fisher a proposé que, si la probabilité d’obtenir cette différence ou une différence plus extrême entre le résultat attendu et le résultat réel est inférieure à 5 %, il convient de conclure que la différence est statistiquement significative (Fisher, 1954). Le choix de 5% (qui correspond à 1/20 ou 0,05) n’a pas de raison biologique. C’est la probabilité que de nombreux chercheurs utilisent comme « niveau de signification statistique » standard.\n\n\n\n\n\n\nAttention: ce seuil n’est pas une valeur magique, les statistiques ce n’est pas blanc vs noir, vrai vs faux, significatif vs non significatif…\n\n\n\n\n2.2.2 Exemple de calcul direct de la p-valeur\nPrenons un exemple de sac contenant 1000 boules blanches et noires. On en tire 6 au hasard (McKillup 2011). On veut tester l’hypothèse qu’il y a 500 blanches et 500 noires: \\(H_0\\): \\(\\mathbb{P}(blanche) = 0,5\\) vs \\(H_A\\): \\(\\mathbb{P}(blanche) ≠ 0,5\\).\n\n\n\n\n\n\nConcepts basiques de probabilité\n\n\n\nLa probabilité d’un événement ne peut varier qu’entre 0 et 1 (qui correspondent à 0 et 100%). Si un événement est certain de se produire, il a une probabilité de 1 ; alors que s’il est certain que l’événement ne se produira pas, il a une probabilité de 0.\nLa probabilité d’un événement particulier est le nombre de résultats donnant cet événement, divisé par le nombre total de résultats possibles. Par exemple, lorsque vous jouez à pile ou face, il n’y a que deux résultats possibles : pile ou face. Ces deux événements s’excluent mutuellement : il est impossible d’obtenir les deux.\nPar conséquent, la probabilité d’obtenir un résultat positif est de 1 divisé par 2 = ½ (et donc la probabilité d’obtenir un résultat négatif est également de ½).\nLa règle de l’addition\nLa probabilité d’obtenir une tête ou une queue est de ½ + ½ = 1. Il s’agit d’un exemple de la règle de l’addition : lorsque plusieurs résultats s’excluent mutuellement, la probabilité d’obtenir l’un d’entre eux est la somme de leurs probabilités respectives. (Par conséquent, la probabilité d’obtenir un 1, un 2, un 3 ou un 4 en lançant un dé à six faces est de 4/6).\nLa règle de multiplication\nÉvénements indépendants. Pour calculer la probabilité conjointe de deux ou plusieurs événements indépendants (par exemple, un face suivi d’un autre face lors de deux lancers indépendants d’une pièce de monnaie), il suffit de multiplier les probabilités indépendantes entre elles. Par conséquent, la probabilité d’obtenir deux têtes lors de deux lancers d’une pièce est de ½ ½ = ¼. La probabilité d’obtenir un pile ou un face avec deux lancers est de ½, parce qu’il y a deux façons d’obtenir ce résultat : HT ou TH.\nÉvénements connexes. Si les événements ne sont pas indépendants (par exemple, le premier événement est un nombre compris entre 1 et 3 inclus lors du lancer d’un dé à six faces et le second événement est un nombre pair), la règle de multiplication s’applique également, mais vous devez multiplier la probabilité d’un événement par la probabilité conditionnelle du second.\nLorsqu’on lance un dé, la probabilité indépendante d’un nombre compris entre 1 et 3 est de \\(3/6 = 1/2\\), et la probabilité indépendante de tout nombre pair est également de \\(1/2\\) (les nombres pairs sont 2, 4 ou 6 divisés par les six résultats possibles).\nCependant, si vous avez déjà lancé un nombre de 1 à 3, la probabilité que cet ensemble restreint de résultats soit un nombre pair est de \\(1/3\\) (parce que “2” est le seul nombre pair possible dans cet ensemble de trois résultats). Par conséquent, la probabilité des deux événements liés est de \\(1/2 \\times 1/3 = 1/6\\). Vous pouvez examiner la situation dans l’autre sens : la probabilité d’obtenir un nombre pair en lançant un dé est de \\(1/2\\) (vous obtiendriez les nombres 2, 4 ou 6) et la probabilité que l’un de ces nombres soit compris entre 1 et 3 est de \\(1/3\\) (le nombre 2 parmi ces trois résultats). Par conséquent, la probabilité des deux résultats est à nouveau \\(1/2 \\times 1/3 = 1/6\\).\n\n\n\n\n\n\n\n\n\n\nNombre de boules noires\nNombre de boules blanches\nProbabilité\nPourcentage de cas pouvant donner ce resultat\n\n\n\n6\n0\n1/64\n1,56\n\n\n5\n1\n6/64\n9,38\n\n\n4\n2\n15/64\n23,44\n\n\n3\n3\n20/64\n31,25\n\n\n2\n4\n15/64\n23,44\n\n\n1\n5\n6/64\n9,38\n\n\n0\n6\n1/64\n1,56\n\n\nTotal\n\n64/64\n100\n\n\n\n\n\nLes nombres attendus de chaque mélange possible de couleurs lors du tirage indépendant de six perles avec remplacement à 64 occasions différentes à partir d’une grande population contenant 50 % de noires et 50 % de blanches.\n\nLa probabilité de n’obtenir aucune boule blanche sur 6 boules tirées est de 1,56%. On rejette l’hypothèse nulle \\(H_0\\) puisque \\(p &lt; 2,5\\%\\) (test bidirectionnel).\n\n2.2.3 Passage intermédiaire par une statistique\nDans la majorité des cas, on ne peut pas calculer directement la p-valeur. L’alternative est de calculer une statistique qui quantifie la différence entre les données observées et les données attendues sous \\(H_0\\). On calcule ensuite la p-valeur en comparant la valeur de la statistique à sa distribution théorique sous \\(H_0\\).\n\n2.2.3.1 Inférence à une moyenne\nOn peut par exemple être amené à comparer la moyenne d’un échantillon à la moyenne d’une population dont la variance est connue. Pour un tel test on a:\n\n\n\\(H_0\\): \\(\\mu = \\mu_0\\); \\(H_A\\): \\(\\mu ≠ \\mu_0\\).\n\nStatistique de test: \\(Z_{obs} = \\frac{\\bar{Y} - \\mu_0}{ESM} = \\frac{\\bar{Y} - \\mu_0}{\\frac{\\sigma}{\\sqrt{n}}} \\sim N(0, 1)\\)\n\n\n\n\n\n\n\n\nScore Z (Z-score)\nLe score Z est une mesure statistique qui quantifie la distance entre un point de données et la moyenne d’un ensemble de données. Il est exprimé en termes d’écarts types. Il indique le nombre d’écarts types d’un point de données par rapport à la moyenne de la distribution.\nSi un score Z est égal à 0, cela signifie que le score du point de données est identique au score moyen. Un score Z de 1,0 indique une valeur qui se situe à un écart-type de la moyenne. Les scores Z peuvent être positifs ou négatifs, une valeur positive indiquant que le score est supérieur à la moyenne et une valeur négative indiquant qu’il est inférieur à la moyenne.\n\\[ Z = \\frac{x - \\mu}{\\sigma}\\]\nErreur standard à la moyenne (ESM)\nLe terme “erreur” remplace celui de “déviation” quand on parle de la variation de moyennes plutôt que de la variation de mesures individuelles.\n\n\n\n\n2.2.3.2 Et si les paramètres sont inconnus ?\nSi on ne connaît pas la variance réelle de la population, il faut tenir compte des biais possibles dus à la taille de l’échantillon (n).\nOn a alors:\n\nStatistique de test (\\(S^2\\) est la variance de l’échantillon): \\(t_{obs} = \\frac{\\bar{X} - \\mu_0}{ESM} = \\frac{\\bar{X} - \\mu_0}{\\frac{S}{\\sqrt{n -1 }}} \\sim St(n-1)\\).\n\nDegrés de liberté: nombre d’observations dans l’échantillon libres de varier quand on estime la variance.\n\nPlus n est petit, plus la distribution est large car S sous-estime σ. Quand n = ∞, Student = Normale.\n\n2.2.4 Effet de la taille de l’échantillon (n)\nPlus l’échantillon est grand, plus la précision avec laquelle est connue la moyenne est importante. Intervalle de confiance à la moyenne réelle \\(\\mu\\): \\[ \\bar{Y} \\pm t_{1-\\alpha/2; n-1} . \\frac{S}{\\sqrt{n-1}}\\]\n\n\nL’effet de la taille de l’échantillon sur la précision et l’exactitude des valeurs de \\(\\bar{X}\\) en tant qu’estimations de \\(\\mu\\) (McKillup 2011)."
  },
  {
    "objectID": "intro2.html#test-uni--vs-bidirectionnel",
    "href": "intro2.html#test-uni--vs-bidirectionnel",
    "title": "\n2  Importance et notions de base\n",
    "section": "\n2.3 Test uni- vs bidirectionnel",
    "text": "2.3 Test uni- vs bidirectionnel\nL’hypothèse nulle est toujours “il n’existe pas de” différence/relation… Cela revient à dire qu’une certaine quantité est égale à 0. L’hypothèse alternative est soit:\n\nCette quantité est différente de 0 (test bidirectionnel);\n\nCette quantité est supérieure/inférieure à 0 (test unidirectionnel).\n\nAinsi on a:\n\nTest bidirectionnel:\n\n\n\\(H_0\\) : \\(\\mu = \\mu_0\\) ou \\(t = 0\\)\n\n\n\\(H_A\\) : \\(\\mu ≠ \\mu_0\\) ou \\(t ≠ 0\\)\n\n\n\nTest unidirectionnel:\n\n\n\\(H_0\\): \\(\\mu = \\mu_0\\) ou \\(t = 0\\)\n\n\n\\(H_{A1}\\): \\(\\mu &gt; \\mu_0\\) ou \\(t &gt; 0\\)\n\n\n\\(H_{A2}\\): \\(\\mu &lt; \\mu_0\\) ou \\(t &lt; 0\\)"
  },
  {
    "objectID": "intro2.html#types-derreurs",
    "href": "intro2.html#types-derreurs",
    "title": "\n2  Importance et notions de base\n",
    "section": "\n2.4 Types d’erreurs",
    "text": "2.4 Types d’erreurs\nQuand on prend une décision concernqnt une hypothèse sur la base d’un échantillon donné, on n’est jamais sûr de prendre la bonne décision!!.\n\n\nDécisions et erreurs statistiques lors des tests d’hypothèses nulles (“Hypothesis Testing” 2002).\n\nOn peut se tromper de 2 manières:\n\n\n\\(\\alpha\\) (probabilité d’erreur de type I: rejeter \\(H_0\\) à tort) est traditionnellement fixé à 5%. Rien n’empêche de choisir un \\(\\alpha\\) plus petit ou plus grand;\n\n\n\\(1 - \\beta\\) (probabilité d’erreur de type II: accepter \\(H_0\\) à tort) est la puissance du test. Elle dépend notamment de:\n\nLa taille de l’effet: plus l’effet est grand, plus la probabilité de le détecter est grande;\nLa variance: plus le paramètre est connu avec précision, plus la probabilité d’en détecter une différence est grande. La précision augmente avec le nombre d’observation."
  },
  {
    "objectID": "intro2.html#compromis-entre-alpha-et-beta",
    "href": "intro2.html#compromis-entre-alpha-et-beta",
    "title": "\n2  Importance et notions de base\n",
    "section": "\n2.5 Compromis entre \\(\\alpha\\) et \\(\\beta\\)\n",
    "text": "2.5 Compromis entre \\(\\alpha\\) et \\(\\beta\\)\n\nIl existe un compromis entre les probabilités d’erreur de type I (\\(\\alpha\\)) et de type II (\\(\\alpha\\)). Pour un même jeu de données, si on choisit de diminuer \\(\\alpha\\), on augmentera automatiquement \\(\\beta\\), et inversement.\n\n\nLe compromis entre l’erreur de type 1 et l’erreur de type 2. (a) fixé à 10 %. (b) L’abaissement à 5 % réduira le risque d’erreur de type 1, mais augmentera le risque d’erreur de type 2. (c) Une réduction à 1 % diminuera encore le risque d’erreur de type 1, mais augmentera fortement le risque d’erreur de type 2. (McKillup 2011)."
  },
  {
    "objectID": "intro2.html#les-deux-grands-types-de-questions",
    "href": "intro2.html#les-deux-grands-types-de-questions",
    "title": "\n2  Importance et notions de base\n",
    "section": "\n2.6 Les deux grands types de questions",
    "text": "2.6 Les deux grands types de questions\nOn peut différencier en général 3 types de jeux de données en fonction du nombre de variables mesurées sur chaque individu:\n\nUnivarié: une seule variable;\n\nBivarié: 2 variables;\n\nMultivarié: plus de 2 variables;\n\nOn peut différencier 2 grandes classes de questions:\n\nL’hypothèse porte sur l’existence de différence(s);\n\nL’hypothèse porte sur l’existence d’une relation entre variables."
  },
  {
    "objectID": "intro2.html#les-grandes-classes-de-méthodes-danalyse",
    "href": "intro2.html#les-grandes-classes-de-méthodes-danalyse",
    "title": "\n2  Importance et notions de base\n",
    "section": "\n2.7 Les grandes classes de méthodes d’analyse",
    "text": "2.7 Les grandes classes de méthodes d’analyse\n\n\n\n\n\n“Hypothesis Testing.” 2002. In, 32–57. Cambridge University Press. https://doi.org/10.1017/cbo9780511806384.004.\n\n\nMcKillup, Steve. 2011. “Statistics Explained,” November. https://doi.org/10.1017/cbo9781139047500."
  },
  {
    "objectID": "intro1.html#la-méthode-scientifique",
    "href": "intro1.html#la-méthode-scientifique",
    "title": "1  Pourquoi a-t-on besoin de méthodes statistiques ?",
    "section": "1.1 La méthode scientifique",
    "text": "1.1 La méthode scientifique\n\n1.1.1 Approche hypothético-déductive\nLes caractéristiques essentielles de la vision “hypothético-déductive” de la méthode scientifique (Popper 2005) sont les suivantes : une personne observe ou prélève des échantillons du monde naturel et utilise toutes les informations disponibles pour faire une supposition intuitive et logique, appelée hypothèse, sur la manière dont le système fonctionne. La personne n’a aucun moyen de savoir si son hypothèse est correcte - elle peut s’appliquer ou non. Les prédictions faites à partir de l’hypothèse sont testées, soit par un échantillonnage supplémentaire, soit par des expériences. Si les résultats sont cohérents avec les prédictions, l’hypothèse est retenue. Dans le cas contraire, elle est rejetée et une nouvelle hypothèse est formulée Figure 1.1.\n\n\n\nFigure 1.1: Le processus de formulation et de vérification des hypothèses (McKillup 2011).\n\n\n\n\n1.1.2 Exemple d’application\nLe mille-pattes portugais Ommatioulus moreleti Figure 1.2 a été introduit accidentellement dans le sud de l’Australie depuis le Portugal dans les années 1950.\n\n\n\nFigure 1.2: Ommatoiulus moreleti\n\n\nCe mille-pattes vit dans la litière de feuilles et atteint environ quatre centimètres de long. En l’absence d’ennemis naturels dans son pays d’origine (en particulier les hérissons européens, qui mangent beaucoup de mille-pattes), son nombre a rapidement augmenté pour atteindre les proportions d’un fléau en Australie-Méridionale. Bien qu’il ne cause que très peu de dégâts aux cultures agricoles, O. moreleti est un ravageur “nuisible” sérieux car il envahit les maisons.\nEn travaillant sur les moyens de réduire les nuisances causées par le mille-pattes portugais, McKillup (McKillup 2011) a remarqué que les propriétaires de maisons qui signalaient de graves problèmes avaient des maisons bien éclairées avec de grandes fenêtres sans rideaux. En revanche, les voisins dont les maisons n’étaient pas aussi bien éclairées et qui fermaient leurs rideaux la nuit signalaient beaucoup moins de mille-pattes à l’intérieur. Le nombre d’O. moreleti par mètre carré était similaire dans la litière de feuilles autour des deux types de maisons.\n\n1.1.2.1 De l’observation à l’hypothèse\nA partir de l’exemple précédent, on peut donc en suivant l’approche hypothético-déductive les éléments suivants:\n\nEtape 1: Observation: Cette espèce peste envahit les maisons, particulièrement celles fort éclairées.\nEtape 2: Hypothèse: Les millepates sont attirés par la lumière. Hypothèse alternative (\\(H_A\\)): Les mille-pates sont attirés par la lumière. Hypothèse nulle (\\(H_0\\)): Les mille-pates ne sont pas attirés par la lumière.\nEtape 3: Prédiction à partir de l’hypothèse: Il devrait y avoir plus de millepattes sur des plaques éclairées que sur des plaques non éclairées.\n\n\n\n1.1.2.2 Prendre une décision à propos d’une hypothèse\nUne fois que l’on dispose du résultat du test expérimental d’une hypothèse, deux choses peuvent se produire :\n\nsoit les résultats de l’expérience sont cohérents avec l’hypothèse, donc l’hypothèse est retenu;\nou les résultats ne sont pas cohérents avec l’hypothèse, on peut donc rejeter l’hypothèse.\n\nSi l’hypothèse est rejetée, il est probable qu’elle soit erronée et qu’il faille en proposer une autre.\nSi l’hypothèse est retenue, qu’elle résiste à d’autres tests et qu’elle présente une très grande généralité, elle peut devenir une théorie. Mais une théorie n’est jamais qu’une hypothèse très générale qui a résisté à des tests répétés. Il est toujours possible qu’elle soit réfutée à l’avenir.\n\n\n1.1.2.3 Pourquoi une hypothèse ou une théorie ne peut-elle jamais être prouvée ?\nAucune hypothèse ou théorie ne peut jamais être prouvée - un jour, il peut y avoir des preuves qui la rejettent et conduisent à une explication différente (qui peut inclure toutes les prédictions réussies de l’hypothèse précédente). Par conséquent, nous ne pouvons que falsifier ou réfuter des hypothèses et des théories - nous ne pouvons jamais les prouver.\nLes cas de réfutation suivie d’un changement de pensée sont fréquents. En voici deux exemples.\nLes chercheurs en médecine pensaient que l’excès d’acidité de l’estomac était responsable de la majorité des ulcères gastriques chez l’homme. Un changement radical s’est opéré lorsque de nombreux ulcères ont guéri à la suite d’une antibiothérapie visant à réduire le nombre de bactéries Helicobacter pylori dans la paroi de l’estomac.\nIl existe au moins trois théories sur la manière dont le rein humain produit une solution concentrée d’urine, et la dernière en date n’est pas nécessairement correcte."
  },
  {
    "objectID": "intro1.html#tests-statistiques-et-niveaux-de-signification",
    "href": "intro1.html#tests-statistiques-et-niveaux-de-signification",
    "title": "1  Pourquoi a-t-on besoin de méthodes statistiques ?",
    "section": "1.3 Tests statistiques et niveaux de signification",
    "text": "1.3 Tests statistiques et niveaux de signification\nUn test statistique est une aide à la décision concernant une hypothèse (alternative vs nulle).\nL’idée maîtresse à la base de tout test d’hypothèse statistique:\n\nJe suppose que \\(H_0\\) (hypothèse nulle) est vraie (pas de différence/relation);\n\nJe calcule la p-valeur, c’est à dire la probabilité d’obtenir une différence/relation au moins aussi forte que celle que j’ai observée dans mon échantillon (qui est un fait établi);\n\nSi cette p-valeur est faible, alors il est probable que \\(H_0\\) soit fausse: la différence mesurée est simplement une mauvaise estimation d’une différence nulle.\n\nLe statisticien Sir Ronald Fisher a proposé que, si la probabilité d’obtenir cette différence ou une différence plus extrême entre le résultat attendu et le résultat réel est inférieure à 5 %, il convient de conclure que la différence est statistiquement significative (Fisher, 1954). Le choix de 5% (qui correspond à 1/20 ou 0,05) n’a pas de raison biologique. C’est la probabilité que de nombreux chercheurs utilisent comme « niveau de signification statistique » standard.\n\n\n\n\n\n\nAttention: ce seuil n’est pas une valeur magique, les statistiques ce n’est pas blanc vs noir, vrai vs faux, significatif vs non significatif…\n\n\n\n\n1.3.1 Exemple de calcul direct de la p-valeur\nPrenons un exemple de sac contenant 1000 boules blanches et noires. On en tire 6 au hasard (McKillup 2011). On veut tester l’hypothèse qu’il y a 500 blanches et 500 noires: \\(H_0\\): \\(\\mathbb{P}(blanche) = 0,5\\) vs \\(H_A\\): \\(\\mathbb{P}(blanche) ≠ 0,5\\).\n\n\n\n\n\n\nConcepts basiques de probabilité\n\n\n\nLa probabilité d’un événement ne peut varier qu’entre 0 et 1 (qui correspondent à 0 et 100%). Si un événement est certain de se produire, il a une probabilité de 1 ; alors que s’il est certain que l’événement ne se produira pas, il a une probabilité de 0.\nLa probabilité d’un événement particulier est le nombre de résultats donnant cet événement, divisé par le nombre total de résultats possibles. Par exemple, lorsque vous jouez à pile ou face, il n’y a que deux résultats possibles : pile ou face. Ces deux événements s’excluent mutuellement : il est impossible d’obtenir les deux.\nPar conséquent, la probabilité d’obtenir un résultat positif est de 1 divisé par 2 = ½ (et donc la probabilité d’obtenir un résultat négatif est également de ½).\nLa règle de l’addition\nLa probabilité d’obtenir une tête ou une queue est de ½ + ½ = 1. Il s’agit d’un exemple de la règle de l’addition : lorsque plusieurs résultats s’excluent mutuellement, la probabilité d’obtenir l’un d’entre eux est la somme de leurs probabilités respectives. (Par conséquent, la probabilité d’obtenir un 1, un 2, un 3 ou un 4 en lançant un dé à six faces est de 4/6).\nLa règle de multiplication\nÉvénements indépendants. Pour calculer la probabilité conjointe de deux ou plusieurs événements indépendants (par exemple, un face suivi d’un autre face lors de deux lancers indépendants d’une pièce de monnaie), il suffit de multiplier les probabilités indépendantes entre elles. Par conséquent, la probabilité d’obtenir deux têtes lors de deux lancers d’une pièce est de ½ ½ = ¼. La probabilité d’obtenir un pile ou un face avec deux lancers est de ½, parce qu’il y a deux façons d’obtenir ce résultat : HT ou TH.\nÉvénements connexes. Si les événements ne sont pas indépendants (par exemple, le premier événement est un nombre compris entre 1 et 3 inclus lors du lancer d’un dé à six faces et le second événement est un nombre pair), la règle de multiplication s’applique également, mais vous devez multiplier la probabilité d’un événement par la probabilité conditionnelle du second.\nLorsqu’on lance un dé, la probabilité indépendante d’un nombre compris entre 1 et 3 est de \\(3/6 = 1/2\\), et la probabilité indépendante de tout nombre pair est également de \\(1/2\\) (les nombres pairs sont 2, 4 ou 6 divisés par les six résultats possibles).\nCependant, si vous avez déjà lancé un nombre de 1 à 3, la probabilité que cet ensemble restreint de résultats soit un nombre pair est de \\(1/3\\) (parce que “2” est le seul nombre pair possible dans cet ensemble de trois résultats). Par conséquent, la probabilité des deux événements liés est de \\(1/2 \\times 1/3 = 1/6\\). Vous pouvez examiner la situation dans l’autre sens : la probabilité d’obtenir un nombre pair en lançant un dé est de \\(1/2\\) (vous obtiendriez les nombres 2, 4 ou 6) et la probabilité que l’un de ces nombres soit compris entre 1 et 3 est de \\(1/3\\) (le nombre 2 parmi ces trois résultats). Par conséquent, la probabilité des deux résultats est à nouveau \\(1/2 \\times 1/3 = 1/6\\).\n\n\n\n\n\n\n\n\n\n\n\nNombre de boules noires\nNombre de boules blanches\nProbabilité\nPourcentage de cas pouvant donner ce resultat\n\n\n\n\n6\n0\n1/64\n1,56\n\n\n5\n1\n6/64\n9,38\n\n\n4\n2\n15/64\n23,44\n\n\n3\n3\n20/64\n31,25\n\n\n2\n4\n15/64\n23,44\n\n\n1\n5\n6/64\n9,38\n\n\n0\n6\n1/64\n1,56\n\n\nTotal\n\n64/64\n100\n\n\n\n\n\n\nLes nombres attendus de chaque mélange possible de couleurs lors du tirage indépendant de six perles avec remplacement à 64 occasions différentes à partir d’une grande population contenant 50 % de noires et 50 % de blanches.\n\n\nLa probabilité de n’obtenir aucune boule blanche sur 6 boules tirées est de 1,56%. On rejette l’hypothèse nulle \\(H_0\\) puisque \\(p &lt; 2,5\\%\\) (test bidirectionnel).\n\n\n1.3.2 Passage intermédiaire par une statistique\nDans la majorité des cas, on ne peut pas calculer directement la p-valeur. L’alternative est de calculer une statistique qui quantifie la différence entre les données observées et les données attendues sous \\(H_0\\). On calcule ensuite la p-valeur en comparant la valeur de la statistique à sa distribution théorique sous \\(H_0\\).\n\n1.3.2.1 Inférence à une moyenne\nOn peut par exemple être amené à comparer la moyenne d’un échantillon à la moyenne d’une population dont la variance est connue. Pour un tel test on a:\n\n\\(H_0\\): \\(\\mu = \\mu_0\\); \\(H_A\\): \\(\\mu ≠ \\mu_0\\).\n\nStatistique de test: \\(Z_{obs} = \\frac{\\bar{Y} - \\mu_0}{ESM} = \\frac{\\bar{Y} - \\mu_0}{\\frac{\\sigma}{\\sqrt{n}}} \\sim N(0, 1)\\)\n\n\n\n\n\n\n\nScore Z (Z-score)\nLe score Z est une mesure statistique qui quantifie la distance entre un point de données et la moyenne d’un ensemble de données. Il est exprimé en termes d’écarts types. Il indique le nombre d’écarts types d’un point de données par rapport à la moyenne de la distribution.\nSi un score Z est égal à 0, cela signifie que le score du point de données est identique au score moyen. Un score Z de 1,0 indique une valeur qui se situe à un écart-type de la moyenne. Les scores Z peuvent être positifs ou négatifs, une valeur positive indiquant que le score est supérieur à la moyenne et une valeur négative indiquant qu’il est inférieur à la moyenne.\n\\[ Z = \\frac{x - \\mu}{\\sigma}\\]\nErreur standard à la moyenne (ESM)\nLe terme “erreur” remplace celui de “déviation” quand on parle de la variation de moyennes plutôt que de la variation de mesures individuelles.\n\n\n\n\n\n1.3.2.2 Et si les paramètres sont inconnus ?\nSi on ne connaît pas la variance réelle de la population, il faut tenir compte des biais possibles dus à la taille de l’échantillon (n).\nOn a alors:\n\nStatistique de test (\\(S^2\\) est la variance de l’échantillon): \\(t_{obs} = \\frac{\\bar{X} - \\mu_0}{ESM} = \\frac{\\bar{X} - \\mu_0}{\\frac{S}{\\sqrt{n -1 }}} \\sim St(n-1)\\).\n\nDegrés de liberté: nombre d’observations dans l’échantillon libres de varier quand on estime la variance.\n\nPlus n est petit, plus la distribution est large car S sous-estime σ. Quand n = ∞, Student = Normale.\n\n\n\n1.3.3 Effet de la taille de l’échantillon (n)\nPlus l’échantillon est grand, plus la précision avec laquelle est connue la moyenne est importante. Intervalle de confiance à la moyenne réelle \\(\\mu\\): \\[ \\bar{Y} \\pm t_{1-\\alpha/2; n-1} . \\frac{S}{\\sqrt{n-1}}\\]\n\n\n\nL’effet de la taille de l’échantillon sur la précision et l’exactitude des valeurs de \\(\\bar{X}\\) en tant qu’estimations de \\(\\mu\\) (McKillup 2011)."
  },
  {
    "objectID": "intro1.html#on-peut-rarement-étudier-toute-la-population",
    "href": "intro1.html#on-peut-rarement-étudier-toute-la-population",
    "title": "1  Pourquoi a-t-on besoin de méthodes statistiques ?",
    "section": "1.2 On peut rarement étudier toute la population",
    "text": "1.2 On peut rarement étudier toute la population\nC’est un fait. En biologie, on peut très rarement étudier toute la population. Une population est un ensemble de tous les individus. Un individu est une unité d’observation. Par exemple l’ensemble des mille-pates d’Australie, des poissons d’un lac, des cellules d’un organe, etc.\nOn étudie donc un échantillon représentatif de la population."
  },
  {
    "objectID": "intro1.html#comment-tester-la-prédiction-à-partir-de-son-hypothèse",
    "href": "intro1.html#comment-tester-la-prédiction-à-partir-de-son-hypothèse",
    "title": "1  Pourquoi a-t-on besoin de méthodes statistiques ?",
    "section": "1.2 Comment tester la prédiction à partir de son hypothèse?",
    "text": "1.2 Comment tester la prédiction à partir de son hypothèse?\n\n1.2.1 On peut rarement étudier toute la population\nC’est un fait. En biologie, on peut très rarement étudier toute la population. Une population est un ensemble de tous les individus. Un individu est une unité d’observation. Par exemple l’ensemble des mille-pates d’Australie, des poissons d’un lac, des cellules d’un organe, etc.\nOn étudie donc un échantillon représentatif de la population.\n\n\n1.2.2 Alors comment fait-on?\nLes statistiques sont un outil d’aide à la décision pour déterminer si les différences observées (i) reflètent une réelle différence entre populations ou (ii) sont dues uniquement au hasard.\n\n\n1.2.3 Conception expérimentale\nÉtant donné qu’un chercheur ne peut généralement pas mesurer chaque individu de la population (à moins qu’il n’étudie les quelques membres restants d’une espèce en voie de disparition), il doit travailler avec un sous-ensemble soigneusement sélectionné contenant plusieurs individus, souvent appelés unités expérimentales, qu’il espère être un échantillon représentatif à partir duquel les caractéristiques de la population peuvent être déduites.\nLa meilleure façon d’obtenir un échantillon représentatif est généralement de choisir une proportion de la population au hasard - sans biais, chaque unité expérimentale possible ayant une probabilité égale d’être sélectionnée.\nLe problème de cette approche est qu’il existe souvent de grandes différences entre les unités expérimentales d’une même population:\n\nTout d’abord, même un échantillon aléatoire peut ne pas être un bon représentant de la population dont il est issu Figure 1.3.\n\n\n\n\nFigure 1.3: Même un échantillon aléatoire n’est pas nécessairement un bon représentant de la population. Deux échantillons ont été prélevés au hasard dans la même population. Par hasard, l’échantillon 1 contient un groupe de poissons relativement grands, tandis que ceux de l’échantillon 2 sont relativement petits (McKillup 2011).\n\n\n\nDeuxièmement, même si deux populations sont très différentes, les échantillons prélevés dans chacune d’elles peuvent être similaires et donner l’impression trompeuse que les populations sont également similaires Figure 1.4.\n\n\n\n\nFigure 1.4: Les échantillons sélectionnés au hasard dans des populations très différentes ne sont pas nécessairement différents. Le hasard fait que l’échantillon 1 et l’échantillon 2 sont similaires (McKillup 2011).\n\n\n\nEnfin, la variation naturelle entre les individus d’un échantillon peut masquer tout effet d’un traitement expérimental. Les variations au sein d’un échantillon (et d’une population) sont souvent si importantes qu’il peut être difficile, voire impossible, de détecter l’effet d’un traitement Figure 1.5.\n\n\n\n\nFigure 1.5: Deux échantillons de poissons ont été prélevés dans la même population et ont été délibérément appariés de manière à ce que six individus de taille égale soient initialement présents dans chaque groupe. Les poissons du groupe traité ont été nourris avec un supplément de vitamines pendant 300 jours, tandis que ceux du groupe témoin non traité ne l’ont pas été. Grâce au supplément, chaque poisson du groupe traité a grandi environ 10 % plus longtemps, mais cette différence est faible par rapport à la variation de la croissance entre les individus, ce qui peut masquer tout effet du traitement (McKillup 2011)."
  },
  {
    "objectID": "intro1.html#tester-la-prédiction-à-partir-de-son-hypothèse",
    "href": "intro1.html#tester-la-prédiction-à-partir-de-son-hypothèse",
    "title": "1  Pourquoi a-t-on besoin de méthodes statistiques ?",
    "section": "1.2 Tester la prédiction à partir de son hypothèse",
    "text": "1.2 Tester la prédiction à partir de son hypothèse\n\n1.2.1 Comment fait-on?\nLes statistiques sont un outil d’aide à la décision pour déterminer si les différences observées (i) reflètent une réelle différence entre populations ou (ii) sont dues uniquement au hasard.\n\n\n1.2.2 On peut rarement étudier toute la population\nC’est un fait. En biologie, on peut très rarement étudier toute la population. Une population est un ensemble de tous les individus. Un individu est une unité d’observation. Par exemple l’ensemble des mille-pates d’Australie, des poissons d’un lac, des cellules d’un organe, etc.\nOn étudie donc un échantillon représentatif de la population.\n\n\n1.2.3 Conception expérimentale\nÉtant donné qu’un chercheur ne peut généralement pas mesurer chaque individu de la population (à moins qu’il n’étudie les quelques membres restants d’une espèce en voie de disparition), il doit travailler avec un sous-ensemble soigneusement sélectionné contenant plusieurs individus, souvent appelés unités expérimentales, qu’il espère être un échantillon représentatif à partir duquel les caractéristiques de la population peuvent être déduites.\nLa meilleure façon d’obtenir un échantillon représentatif est généralement de choisir une proportion de la population au hasard - sans biais, chaque unité expérimentale possible ayant une probabilité égale d’être sélectionnée.\nLe problème de cette approche est qu’il existe souvent de grandes différences entre les unités expérimentales d’une même population:\n\nTout d’abord, même un échantillon aléatoire peut ne pas être un bon représentant de la population dont il est issu Figure 1.3.\n\n\n\n\nFigure 1.3: Même un échantillon aléatoire n’est pas nécessairement un bon représentant de la population. Deux échantillons ont été prélevés au hasard dans la même population. Par hasard, l’échantillon 1 contient un groupe de poissons relativement grands, tandis que ceux de l’échantillon 2 sont relativement petits (McKillup 2011).\n\n\n\nDeuxièmement, même si deux populations sont très différentes, les échantillons prélevés dans chacune d’elles peuvent être similaires et donner l’impression trompeuse que les populations sont également similaires Figure 1.4.\n\n\n\n\nFigure 1.4: Les échantillons sélectionnés au hasard dans des populations très différentes ne sont pas nécessairement différents. Le hasard fait que l’échantillon 1 et l’échantillon 2 sont similaires (McKillup 2011).\n\n\n\nEnfin, la variation naturelle entre les individus d’un échantillon peut masquer tout effet d’un traitement expérimental. Les variations au sein d’un échantillon (et d’une population) sont souvent si importantes qu’il peut être difficile, voire impossible, de détecter l’effet d’un traitement Figure 1.5.\n\n\n\n\nFigure 1.5: Deux échantillons de poissons ont été prélevés dans la même population et ont été délibérément appariés de manière à ce que six individus de taille égale soient initialement présents dans chaque groupe. Les poissons du groupe traité ont été nourris avec un supplément de vitamines pendant 300 jours, tandis que ceux du groupe témoin non traité ne l’ont pas été. Grâce au supplément, chaque poisson du groupe traité a grandi environ 10 % plus longtemps, mais cette différence est faible par rapport à la variation de la croissance entre les individus, ce qui peut masquer tout effet du traitement (McKillup 2011)."
  }
]