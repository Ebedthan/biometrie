[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Biométrie et expérimentation végétale",
    "section": "",
    "text": "Bienvenue\nCe cours présente les notions de bases en biométrie et expérimentation aux ingénieur agronomes 3e année de l’Institut National Polytechnique Félix Houphouët-Boigny.\nCe manuel est et sera toujours gratuit, sous licence CC BY-NC-ND 3.0.",
    "crumbs": [
      "Bienvenue"
    ]
  },
  {
    "objectID": "intro.html#rappels-sur-les-notions-de-base",
    "href": "intro.html#rappels-sur-les-notions-de-base",
    "title": "\n1  Importance et notions de base\n",
    "section": "\n1.1 Rappels sur les notions de base",
    "text": "1.1 Rappels sur les notions de base\n\n1.1.1 Types de statistiques\n\n\nDescriptives: le but est d’illustrer les données;\n\n\nParamétriques: on suppose que la/les variables(s) suivent une distribution particulière;\n\n\nNon paramétriques: on ne fait aucune supposition concernant la distribution de la/les variables(s).\n\n1.1.2 Variables\n\nUne variable est un attribut mesuré pour chaque individu/observation.\n\nTypes d’échelle de mesure:\n\nRatio: le 0 est clairement défini; ne peut pas être &lt; 0.\n\nIntervalle: le 0 est arbitraire; peut être &lt; 0.\n\nOrdinale: l’ordre est défini; les rangs n’indiquent pas nécessairement des différentes constantes.\n\nNominale/Catégorique: l’ordre est non défini.\n\nContinue: présente une infinité de valeurs possibles.\n\nDiscrète: nombre limité de valeurs possibles.\n\n\n\n1.1.3 Qu’est-ce qu’une distribution?\nUne fonction qui exprime la fréquence (densité de probabilité) des différentes valeurs pouvant être prise par une variable.\nRappelons ici quelques distributions usuelles.\n\n1.1.3.1 Distribution uniforme (continue)\nBien que les origines historiques de la conception de la distribution uniforme ne soient pas concluantes, on suppose que le terme “uniforme” est né du concept d’équiprobabilité dans les jeux de dés (notez que les jeux de dés auraient un espace d’échantillonnage uniforme discret et non continu).\nLes paramètres de la distribution uniforme sont:\n\nMoyenne: \\(\\frac{1}{2}(a + b)\\).\n\nVariance: \\(\\frac{1}{12}(b - a)^2\\).\n\nLa fonction de densité de la loi uniforme est:\n\\[\nf(x) = \\left\\{\\begin{array}{ll}\\frac{1}{b - a} & \\mbox{for } a \\leq x \\leq b, \\\\ 0 & \\mbox{otherwise}\\end{array}\\right.\n\\]\n\n\n\n\n\n\n1.1.3.2 Distribution binomiale\nLa distribution binomiale est fréquemment utilisée pour modéliser le nombre de succès dans un échantillon de taille \\(n\\) tiré avec remplacement d’une population de taille \\(N\\).\nLes paramètres de la distribution binomiale sont:\n\nMoyenne: \\(\\mu = np\\).\nVariance: \\(\\sigma^2 = npq\\).\n\nLa fonction de densité de la loi binomiale est:\n\\[\nf(k, n, p) = \\binom{n}{k}p^k (1-p)^{n-k}\n\\]\n\n\n\n\n\n\n1.1.3.3 Distribution de Poisson\nLa distribution de Poisson est une distribution de probabilité discrète qui exprime la probabilité qu’un nombre donné d’événements se produisent dans un intervalle de temps fixe si ces événements se produisent avec un taux moyen constant connu et indépendamment du temps écoulé depuis le dernier événement.\nLes paramètres de la distribution de Poisson sont:\n\nMoyenne: \\(\\mu = \\lambda\\)\nVariance: \\(\\sigma^2 = \\lambda\\)\n\nLa fonction de densité de probabilité de la distribution de Poisson est:\n\\[\nf(k; \\lambda) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\n\\]\n\n\n\n\n\n\n1.1.3.4 Distribution normale\nLes distributions normales sont importantes en statistique et sont souvent utilisées dans les sciences naturelles et sociales pour représenter des variables aléatoires à valeur réelle dont la distribution n’est pas connue. Leur importance est en partie due au théorème de la limite centrale. Ce théorème stipule que, sous certaines conditions, la moyenne de nombreux échantillons (observations) d’une variable aléatoire de moyenne et de variance finies est elle-même une variable aléatoire, dont la distribution converge vers une distribution normale à mesure que le nombre d’échantillons augmente. Par conséquent, les quantités physiques qui sont censées être la somme de nombreux processus indépendants, tels que les erreurs de mesure, ont souvent des distributions qui sont presque normales.\nLes paramètres de la distribution normale sont:\n\nMoyenne: \\(\\mu = \\frac{\\sum_{i=1}^{N} X_i}{N}\\).\nVariance: \\(\\sigma^2 = \\frac{\\sum (X_i - \\mu)^2}{N}\\).\n\nLa fonction de densité de la loi normale est:\n\\[ f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}\\]\n\n\n\n\n\n\n\n\n\n\n\nPoints clés à retenir\n\n\n\n\nLa distribution normale est le terme approprié pour désigner une courbe de probabilité en cloche.\nDans une distribution normale, la moyenne est égale à zéro et l’écart-type est de 1. L’asymétrie est nulle et l’aplatissement est de 3.\nLes distributions normales sont symétriques, mais toutes les distributions symétriques ne sont pas normales.\n\n\n\n\n1.1.3.5 Distribution \\(t\\) de Student\nEn probabilité et en statistique, la distribution \\(t\\) de Student (ou simplement la distribution \\(t\\)) \\(t_\\nu\\) est une distribution de probabilité continue qui généralise la distribution normale standard. Comme cette dernière, elle est symétrique autour de zéro et en forme de cloche.\nLes paramètres de la distribution \\(t\\) de Student sont:\n\nMoyenne: 0 pour \\(\\nu &gt; 1\\) et indéfini dans le cas contraire.\nVariance: \\(\\frac{\\nu}{\\nu - 2}\\) pour \\(\\nu &gt; 2\\), \\(\\infty\\) pour \\(1 &lt; \\nu \\leq 2\\), indéfini dans les cas contraires.\n\nLa fonction de densité de probabilité de la distribution de \\(t\\) est:\n\\[\nf(t) = \\frac{\\Gamma(\\frac{\\nu + 1}{2})}{\\sqrt{\\pi \\nu} \\Gamma(\\frac{\\nu}{2})} (1 + \\frac{t^2}{\\nu}) ^ {-(\\nu + 1)/2}\n\\]\nou \\(\\nu\\) est le nombre de dégrés de libertés et \\(\\Gamma\\) est la fonction Gamma.\n\n\n\n\n\nLa distribution t de Student avec \\(\\nu\\) degrés de liberté peut être définie comme la distribution de la variable aléatoire \\(T\\) avec \\[T = \\frac{Z}{\\sqrt{V/\\nu}} = Z\\sqrt{\\frac{\\nu}{V}}\\]\navec\n\n\\(Z\\) est une normale standard avec une valeur attendue de 0 et une variance de 1 ;\n\\(V\\) suit une distribution de khi-deux (\\(\\chi^2\\)) avec \\(\\nu\\) dégrés de liberté;\n\\(Z\\) et \\(V\\) sont indépendants.\n\n\n\n\n\n\n\nPoints clés à retenir\n\n\n\n\nLa distribution \\(t\\) est une distribution de probabilité continue du score z lorsque l’écart-type estimé est utilisé au dénominateur plutôt que l’écart-type réel.\nLa distribution \\(t\\), comme la distribution normale, est en forme de cloche et symétrique, mais ses queues sont plus lourdes, ce qui signifie qu’elle a tendance à produire des valeurs très éloignées de sa moyenne.\nLes tests T sont utilisés en statistique pour estimer l’importance des résultats."
  },
  {
    "objectID": "intro.html#pourquoi-a-t-on-besoin-de-méthodes-statistiques",
    "href": "intro.html#pourquoi-a-t-on-besoin-de-méthodes-statistiques",
    "title": "\n1  Importance et notions de base\n",
    "section": "\n1.2 Pourquoi a-t-on besoin de méthodes statistiques ?",
    "text": "1.2 Pourquoi a-t-on besoin de méthodes statistiques ?\nLa plupart des sciences sont comparatives. Les chercheurs ont souvent besoin de savoir si un traitement expérimental particulier a eu un effet, ou s’il existe des différences entre une variable particulière mesurée à plusieurs endroits différents. Par exemple, un nouveau médicament a-t-il un effet sur la tension artérielle, un régime riche en vitamine C réduit-il le risque de cancer du foie chez l’homme, ou existe-t-il une relation entre la couverture végétale et la densité de la population de lapins ? Mais lorsque vous faites ce genre de comparaisons, les différences entre les traitements ou entre les zones échantillonnées peuvent être réelles ou peuvent simplement être le type de variation qui se produit par hasard entre les échantillons d’une même population.\nPrenons 2 situations concrètes:\n\nDans la première, nous jouons à pile ou face avec 10 pièces. On obtient après un lancer unique de chacune des pièces 3 faces et 7 piles. Pouvons-nous dire si ce lot de pièces est truqué?\n\nDans la seconde, on échantillone une population de singes, et on observe 32 femelles et 54 mâles. Y a-t-il réellement plus de mâles dans la population?\n\nLes probabilités vous aident à prendre une décision concernant vos résultats.\n\n1.2.1 Tests statistiques et niveaux de signification\nUn test statistique est une aide à la décision concernant une hypothèse (alternative vs nulle).\nL’idée maîtresse à la base de tout test d’hypothèse statistique:\n\nJe suppose que \\(H_0\\) (hypothèse nulle) est vraie (pas de différence/relation);\n\nJe calcule la p-valeur, c’est à dire la probabilité d’obtenir une différence/relation au moins aussi forte que celle que j’ai observée dans mon échantillon (qui est un fait établi);\n\nSi cette p-valeur est faible, alors il est probable que \\(H_0\\) soit fausse: la différence mesurée est simplement une mauvaise estimation d’une différence nulle.\n\nLe statisticien Sir Ronald Fisher a proposé que, si la probabilité d’obtenir cette différence ou une différence plus extrême entre le résultat attendu et le résultat réel est inférieure à 5 %, il convient de conclure que la différence est statistiquement significative (Fisher, 1954). Le choix de 5% (qui correspond à 1/20 ou 0,05) n’a pas de raison biologique. C’est la probabilité que de nombreux chercheurs utilisent comme « niveau de signification statistique » standard.\n\n\n\n\n\n\nAttention: ce seuil n’est pas une valeur magique, les statistiques ce n’est pas blanc vs noir, vrai vs faux, significatif vs non significatif…\n\n\n\n\n1.2.2 Exemple de calcul direct de la p-valeur\nPrenons un exemple de sac contenant 1000 boules blanches et noires. On en tire 6 au hasard (McKillup 2011). On veut tester l’hypothèse qu’il y a 500 blanches et 500 noires: \\(H_0\\): \\(\\mathbb{P}(blanche) = 0,5\\) vs \\(H_A\\): \\(\\mathbb{P}(blanche) ≠ 0,5\\).\n\n\n\n\n\n\nConcepts basiques de probabilité\n\n\n\nLa probabilité d’un événement ne peut varier qu’entre 0 et 1 (qui correspondent à 0 et 100%). Si un événement est certain de se produire, il a une probabilité de 1 ; alors que s’il est certain que l’événement ne se produira pas, il a une probabilité de 0.\nLa probabilité d’un événement particulier est le nombre de résultats donnant cet événement, divisé par le nombre total de résultats possibles. Par exemple, lorsque vous jouez à pile ou face, il n’y a que deux résultats possibles : pile ou face. Ces deux événements s’excluent mutuellement : il est impossible d’obtenir les deux.\nPar conséquent, la probabilité d’obtenir un résultat positif est de 1 divisé par 2 = ½ (et donc la probabilité d’obtenir un résultat négatif est également de ½).\nLa règle de l’addition\nLa probabilité d’obtenir une tête ou une queue est de ½ + ½ = 1. Il s’agit d’un exemple de la règle de l’addition : lorsque plusieurs résultats s’excluent mutuellement, la probabilité d’obtenir l’un d’entre eux est la somme de leurs probabilités respectives. (Par conséquent, la probabilité d’obtenir un 1, un 2, un 3 ou un 4 en lançant un dé à six faces est de 4/6).\nLa règle de multiplication\nÉvénements indépendants. Pour calculer la probabilité conjointe de deux ou plusieurs événements indépendants (par exemple, un face suivi d’un autre face lors de deux lancers indépendants d’une pièce de monnaie), il suffit de multiplier les probabilités indépendantes entre elles. Par conséquent, la probabilité d’obtenir deux têtes lors de deux lancers d’une pièce est de ½ ½ = ¼. La probabilité d’obtenir un pile ou un face avec deux lancers est de ½, parce qu’il y a deux façons d’obtenir ce résultat : HT ou TH.\nÉvénements connexes. Si les événements ne sont pas indépendants (par exemple, le premier événement est un nombre compris entre 1 et 3 inclus lors du lancer d’un dé à six faces et le second événement est un nombre pair), la règle de multiplication s’applique également, mais vous devez multiplier la probabilité d’un événement par la probabilité conditionnelle du second.\nLorsqu’on lance un dé, la probabilité indépendante d’un nombre compris entre 1 et 3 est de \\(3/6 = 1/2\\), et la probabilité indépendante de tout nombre pair est également de \\(1/2\\) (les nombres pairs sont 2, 4 ou 6 divisés par les six résultats possibles).\nCependant, si vous avez déjà lancé un nombre de 1 à 3, la probabilité que cet ensemble restreint de résultats soit un nombre pair est de \\(1/3\\) (parce que “2” est le seul nombre pair possible dans cet ensemble de trois résultats). Par conséquent, la probabilité des deux événements liés est de \\(1/2 \\times 1/3 = 1/6\\). Vous pouvez examiner la situation dans l’autre sens : la probabilité d’obtenir un nombre pair en lançant un dé est de \\(1/2\\) (vous obtiendriez les nombres 2, 4 ou 6) et la probabilité que l’un de ces nombres soit compris entre 1 et 3 est de \\(1/3\\) (le nombre 2 parmi ces trois résultats). Par conséquent, la probabilité des deux résultats est à nouveau \\(1/2 \\times 1/3 = 1/6\\).\n\n\n\n\n\n\n\n\n\n\nNombre de boules noires\nNombre de boules blanches\nProbabilité\nPourcentage de cas pouvant donner ce resultat\n\n\n\n6\n0\n1/64\n1,56\n\n\n5\n1\n6/64\n9,38\n\n\n4\n2\n15/64\n23,44\n\n\n3\n3\n20/64\n31,25\n\n\n2\n4\n15/64\n23,44\n\n\n1\n5\n6/64\n9,38\n\n\n0\n6\n1/64\n1,56\n\n\nTotal\n\n64/64\n100\n\n\n\n\n\nLes nombres attendus de chaque mélange possible de couleurs lors du tirage indépendant de six perles avec remplacement à 64 occasions différentes à partir d’une grande population contenant 50 % de noires et 50 % de blanches.\n\nLa probabilité de n’obtenir aucune boule blanche sur 6 boules tirées est de 1,56%. On rejette l’hypothèse nulle \\(H_0\\) puisque \\(p &lt; 2,5\\%\\) (test bidirectionnel).\n\n1.2.3 Passage intermédiaire par une statistique\nDans la majorité des cas, on ne peut pas calculer directement la p-valeur. L’alternative est de calculer une statistique qui quantifie la différence entre les données observées et les données attendues sous \\(H_0\\). On calcule ensuite la p-valeur en comparant la valeur de la statistique à sa distribution théorique sous \\(H_0\\).\n\n1.2.3.1 Inférence à une moyenne\nOn peut par exemple être amené à comparer la moyenne d’un échantillon à la moyenne d’une population dont la variance est connue. Pour un tel test on a:\n\n\n\\(H_0\\): \\(\\mu = \\mu_0\\); \\(H_A\\): \\(\\mu ≠ \\mu_0\\).\n\nStatistique de test: \\(Z_{obs} = \\frac{\\bar{Y} - \\mu_0}{ESM} = \\frac{\\bar{Y} - \\mu_0}{\\frac{\\sigma}{\\sqrt{n}}} \\sim N(0, 1)\\)\n\n\n\n\n\n\n\n\nScore Z (Z-score)\nLe score Z est une mesure statistique qui quantifie la distance entre un point de données et la moyenne d’un ensemble de données. Il est exprimé en termes d’écarts types. Il indique le nombre d’écarts types d’un point de données par rapport à la moyenne de la distribution.\nSi un score Z est égal à 0, cela signifie que le score du point de données est identique au score moyen. Un score Z de 1,0 indique une valeur qui se situe à un écart-type de la moyenne. Les scores Z peuvent être positifs ou négatifs, une valeur positive indiquant que le score est supérieur à la moyenne et une valeur négative indiquant qu’il est inférieur à la moyenne.\n\\[ Z = \\frac{x - \\mu}{\\sigma}\\]\nErreur standard à la moyenne (ESM)\nLe terme “erreur” remplace celui de “déviation” quand on parle de la variation de moyennes plutôt que de la variation de mesures individuelles.\n\n\n\n\n1.2.3.2 Et si les paramètres sont inconnus ?\nSi on ne connaît pas la variance réelle de la population, il faut tenir compte des biais possibles dus à la taille de l’échantillon (n).\nOn a alors:\n\nStatistique de test (\\(S^2\\) est la variance de l’échantillon): \\(t_{obs} = \\frac{\\bar{X} - \\mu_0}{ESM} = \\frac{\\bar{X} - \\mu_0}{\\frac{S}{\\sqrt{n -1 }}} \\sim St(n-1)\\).\n\nDegrés de liberté: nombre d’observations dans l’échantillon libres de varier quand on estime la variance.\n\nPlus n est petit, plus la distribution est large car S sous-estime σ. Quand n = ∞, Student = Normale.\n\n1.2.4 Effet de la taille de l’échantillon (n)\nPlus l’échantillon est grand, plus la précision avec laquelle est connue la moyenne est importante. Intervalle de confiance à la moyenne réelle \\(\\mu\\): \\[ \\bar{Y} \\pm t_{1-\\alpha/2; n-1} . \\frac{S}{\\sqrt{n-1}}\\]\n\n\nL’effet de la taille de l’échantillon sur la précision et l’exactitude des valeurs de \\(\\bar{X}\\) en tant qu’estimations de \\(\\mu\\) (McKillup 2011)."
  },
  {
    "objectID": "intro.html#test-uni--vs-bidirectionnel",
    "href": "intro.html#test-uni--vs-bidirectionnel",
    "title": "\n1  Importance et notions de base\n",
    "section": "\n1.3 Test uni- vs bidirectionnel",
    "text": "1.3 Test uni- vs bidirectionnel\nL’hypothèse nulle est toujours “il n’existe pas de” différence/relation… Cela revient à dire qu’une certaine quantité est égale à 0. L’hypothèse alternative est soit:\n\nCette quantité est différente de 0 (test bidirectionnel);\n\nCette quantité est supérieure/inférieure à 0 (test unidirectionnel).\n\nAinsi on a:\n\nTest bidirectionnel:\n\n\n\\(H_0\\) : \\(\\mu = \\mu_0\\) ou \\(t = 0\\)\n\n\n\\(H_A\\) : \\(\\mu ≠ \\mu_0\\) ou \\(t ≠ 0\\)\n\n\n\nTest unidirectionnel:\n\n\n\\(H_0\\): \\(\\mu = \\mu_0\\) ou \\(t = 0\\)\n\n\n\\(H_{A1}\\): \\(\\mu &gt; \\mu_0\\) ou \\(t &gt; 0\\)\n\n\n\\(H_{A2}\\): \\(\\mu &lt; \\mu_0\\) ou \\(t &lt; 0\\)"
  },
  {
    "objectID": "intro.html#types-derreurs",
    "href": "intro.html#types-derreurs",
    "title": "\n1  Importance et notions de base\n",
    "section": "\n1.4 Types d’erreurs",
    "text": "1.4 Types d’erreurs\nQuand on prend une décision concernqnt une hypothèse sur la base d’un échantillon donné, on n’est jamais sûr de prendre la bonne décision!!.\n\n\nDécisions et erreurs statistiques lors des tests d’hypothèses nulles (“Hypothesis Testing” 2002).\n\nOn peut se tromper de 2 manières:\n\n\n\\(\\alpha\\) (probabilité d’erreur de type I: rejeter \\(H_0\\) à tort) est traditionnellement fixé à 5%. Rien n’empêche de choisir un \\(\\alpha\\) plus petit ou plus grand;\n\n\n\\(1 - \\beta\\) (probabilité d’erreur de type II: accepter \\(H_0\\) à tort) est la puissance du test. Elle dépend notamment de:\n\nLa taille de l’effet: plus l’effet est grand, plus la probabilité de le détecter est grande;\nLa variance: plus le paramètre est connu avec précision, plus la probabilité d’en détecter une différence est grande. La précision augmente avec le nombre d’observation."
  },
  {
    "objectID": "intro.html#compromis-entre-alpha-et-beta",
    "href": "intro.html#compromis-entre-alpha-et-beta",
    "title": "\n1  Importance et notions de base\n",
    "section": "\n1.5 Compromis entre \\(\\alpha\\) et \\(\\beta\\)\n",
    "text": "1.5 Compromis entre \\(\\alpha\\) et \\(\\beta\\)\n\nIl existe un compromis entre les probabilités d’erreur de type I (\\(\\alpha\\)) et de type II (\\(\\alpha\\)). Pour un même jeu de données, si on choisit de diminuer \\(\\alpha\\), on augmentera automatiquement \\(\\beta\\), et inversement.\n\n\nLe compromis entre l’erreur de type 1 et l’erreur de type 2. (a) fixé à 10 %. (b) L’abaissement à 5 % réduira le risque d’erreur de type 1, mais augmentera le risque d’erreur de type 2. (c) Une réduction à 1 % diminuera encore le risque d’erreur de type 1, mais augmentera fortement le risque d’erreur de type 2. (McKillup 2011)."
  },
  {
    "objectID": "intro.html#les-deux-grands-types-de-questions",
    "href": "intro.html#les-deux-grands-types-de-questions",
    "title": "\n1  Importance et notions de base\n",
    "section": "\n1.6 Les deux grands types de questions",
    "text": "1.6 Les deux grands types de questions\nOn peut différencier en général 3 types de jeux de données en fonction du nombre de variables mesurées sur chaque individu:\n\nUnivarié: une seule variable;\n\nBivarié: 2 variables;\n\nMultivarié: plus de 2 variables;\n\nOn peut différencier 2 grandes classes de questions:\n\nL’hypothèse porte sur l’existence de différence(s);\n\nL’hypothèse porte sur l’existence d’une relation entre variables."
  },
  {
    "objectID": "intro.html#les-grandes-classes-de-méthodes-danalyse",
    "href": "intro.html#les-grandes-classes-de-méthodes-danalyse",
    "title": "\n1  Importance et notions de base\n",
    "section": "\n1.7 Les grandes classes de méthodes d’analyse",
    "text": "1.7 Les grandes classes de méthodes d’analyse\n\n\n\n\n\n“Hypothesis Testing.” 2002. In, 32–57. Cambridge University Press. https://doi.org/10.1017/cbo9780511806384.004.\n\n\nMcKillup, Steve. 2011. “Statistics Explained,” November. https://doi.org/10.1017/cbo9781139047500."
  },
  {
    "objectID": "chapter1.html#architecture-de-von-neuman",
    "href": "chapter1.html#architecture-de-von-neuman",
    "title": "2  Partie matérielle de l’ordinateur",
    "section": "2.1 Architecture de Von Neuman",
    "text": "2.1 Architecture de Von Neuman\nL’architecture de von Neumann est un modèle structurel d’ordinateur dans lequel une unité de stockage (mémoire) unique sert à conserver à la fois les instructions et les données demandées ou produites par le calcul. Les ordinateurs actuels sont tous basés sur des versions améliorées de cette architecture.\n\n\n\nFigure 2.1: Architecture de Von Neuman\n\n\nL’architecture de von Neumann décompose l’ordinateur en 4 parties distinctes:\n- l’unité arithmétique et logique (UAL ou ALU en anglais) ou unité de traitement: son rôle est d’effectuer les opérations de base;\n- l’unité de contrôle ou de commande (control unit), chargée du « séquençage » des opérations;\n- la mémoire qui contient à la fois les données et le programme qui indiquera à l’unité de contrôle quels sont les calculs à faire sur ces données;\n- les dispositifs d’entrée-sortie, qui permettent de communiquer avec le monde extérieur."
  },
  {
    "objectID": "chapter1.html#composantes-dun-ordinateur",
    "href": "chapter1.html#composantes-dun-ordinateur",
    "title": "2  Partie matérielle de l’ordinateur",
    "section": "2.2 Composantes d’un ordinateur",
    "text": "2.2 Composantes d’un ordinateur\n\n2.2.1 L’unité centrale\nL’unité centrale, c’est l’organe principal de l’ordinateur, elle renferme plusieurs composants destinés au traitement et à la circulation de l’information. Dans l’unité centrale, on trouve:\n- le bloc d’alimentation;\n- la carte mère (microprocesseur, mémoire centrale, mémoire morte, l’horloge…);\n- les mémoires de masses (disque dur, lecteurs de CD-ROM…);\n- les cartes additionnelles (carte réseau, carte son, carte vidéo, …).\n\n2.2.1.1 Le bloc d’alimentation\nLe boîtier héberge un bloc d’alimentation électrique, chargé de fournir un courant électrique stable et continu à l’ensemble des éléments de l’ordinateur.\n\n\n\n\n\n\n\nExemple 1\n\n\n\n\n\n\n\nExemple 2\n\n\n\n\nFigure 2.2: Bloc d’alimentation\n\n\n\n\n2.2.1.2 Carte mère\nLa carte mère (motherboard en anglais) est le circuit imprimé principal de l’ordinateur. Sur cette carte, tous les composants du PC sont connectés. La carte mère contient entre autres : le socket (connecteur) pour le processeur, des supports mémoire vive, des ports pour les cartes d’extension.\n\n\n\nFigure 2.3: Carte mère\n\n\n\n\n2.2.1.3 Microprocesseur\nLe microprocesseur (CPU : Central Processing Unit ou Unité Centrale de Traitement) est le cerveau de l’ordinateur. Il permet de manipuler, de circuler les informations et d’exécuter les instructions stockées en mémoire. Toute l’activité de l’ordinateur est cadencée par une horloge unique.\n\n\n\nFigure 2.4: Microprocesseur\n\n\nLe microprocesseur est caractérisé par la cadence maximale à laquelle il est capable de travailler, par la taille et le nombre de données qu’il peut manipuler. Plus la circulation des données est rapide, plus l’ordinateur sera jugé performant.\nOn emploie généralement les termes suivants:\n- Fréquence de l’horloge: la fréquence de l’horloge de la carte mère qui cadence le microprocesseur;\n- Largeur des données: Le premier nombre indique le nombre de bits sur lequel une opération est faite. Le second nombre indique le nombre de bits transférés à la fois entre la mémoire et le microprocesseur;\n- MIPS: le nombre de millions d’instructions complétées par le microprocesseur en une seconde.\n\n\n\nDate\nProcesseur / Système\nFrquence de l’horloge\nMIPS\nSource\n\n\n\n\n1951\nUNIVAC I\n2,25 MHz\n0,002\n\n\n\n1981\nMotorola 6802\n3,58 MHz\n0,5\nsource\n\n\n1991\nIntel i860\n50 MHz\n50\nsource\n\n\n1994\nIntel DX4\n100 MHz\n70\n\n\n\n1994\nIntel Pentium\n100 MHz\n188\n\n\n\n1996\nIntel Pentium Pro\n200 MHz\n541\n\n\n\n1999\nIntel Pentium III\n600 MHz\n2054\n\n\n\n2003\nIntel Pentium 4 Extreme Edition\n3,2 GHz\n9726\n\n\n\n2008\nIntel Core i7 920 (4-core)\n2,93 GHz\n82300\n\n\n\n2011\nIntel Core i7 875K\n2,93 GHz\n92100\n\n\n\n2016\nIntel Core i7 6950X (10-core)\n3,5 GHz\n320440\n\n\n\n2021\nIntel Core i5-11600K (6-core)\n4,92 GHz\n346350\n\n\n\n\nLe microprocesseur Figure 2.4 est constitué:\n- d’une unité de commande qui est responsable de la lecture en mémoire et du décodage des instructions;\n- d’une unité de traitement (Unité Arithmétique et Logique (U.A.L.)) qui exécute les instructions.\n\n2.2.1.3.1 L’unité de commande\nL’unité de commande est constituée de plusieurs organes qui permettent la recherche en mémoire et le décodage d’une instruction. L’unité de commande est constituée des éléments suivants:\n- Le compteur ordinal: c’est un registre contenant l’adresse de l’instruction en cours;\n- Le registre d’instruction: il contient l’instruction suivante;\n- Le décodeur d’instructions: c’est un dispositif qui traduit le code de l’instruction reçu en signaux qui sont transmis au séquenceur;\n- Le séquenceur: il est chargé de synchroniser l’exécution des instructions à la cadence de l’horloge. Il est ainsi chargé de l’envoi des signaux de commande.\n\n\n2.2.1.3.2 L’unité de traitement\nCette unité utilise les données stockées en mémoire, effectue des calculs dont les résultats sont eux aussi stockées en mémoire ou acheminés vers un périphérique de sortie.\n\n\n\n2.2.1.4 La mémoire\nLa mémoire est un composant de base de l’ordinateur, son rôle est de stocker les données avant et pendant leur traitement par le processeur. Ces données sont d’apparence binaire et mémorisées sous forme d’impulsions électriques (une impulsion est égale à 1, aucune impulsion est égale à 0 ou l’inverse).\n\n2.2.1.4.1 Mémoire vive\nLa mémoire vive appelée également mémoire centrale ou RAM (Random Access Memory) permet de stocker temporairement les données et programmes en cours de traitement. Les données contenues dans la mémoire vive sont perdues lorsque le courant électrique est coupé. La mémoire vive se présente sous la forme de barrettes qu’on insère dans un connecteur de la carte mère. On peut souvent augmenter la taille mémoire en ajoutant des barrettes de RAM.\nLes caractéristiques de la mémoire vive sont:\n- sa rapidité d’accès : cette rapidité est essentielle pour fournir rapidement les données au processeur;\n- sa volatilité : cette volatilité implique que les données sont perdues dès que l’alimentation électrique est coupée.\nPour mesurer la taille mémoire, on utilise l’Octet:\n- Un octet = 8 bits;\n- Un kilo-octet (Ko) = 1024 octets ≈ 103 octets;\n- Un méga-octet (Mo) = (1024)2 octets ≈ 106 octets;\n- Un giga-octet (Go) = (1024)3 octets ≈ 109 octets;\n- Un tera-octet (To) = (1024)4 octets ≈ 1012 octets;\nOn peut aussi parler de Kbits, Mbits, Gbits. 1Kbits = 103 bits, 1Mbits= 103 kbits, 1 Gbits= 103 Mbits.\n\n\n2.2.1.4.2 Mémoire morte\nLa mémoire morte (en anglais ROM = Read Only Memory) est une mémoire en lecture seule, appelée aussi mémoire non volatile, c’est-à-dire une mémoire qui ne s’efface pas à l’extinction de l’ordinateur. Elle stocke le programme de base pour démarrer et utiliser un ordinateur (le BIOS : Basic Input Output System).\n\n\n2.2.1.4.3 Mémoire cache\nLa mémoire cache est une petite mémoire à accès rapide qui sert de tampon entre la mémoire vive et le processeur. Elle stocke les informations les plus souvent utilisées, permettant ainsi de réduire les états d’attente du microprocesseur. Lorsque le microprocesseur veut traiter des données, il accède d’abord au cache interne, s’il ne trouve pas les données, il accède au cache externe, puis à la RAM. On distingue deux types de caches:\n- Cache interne: c’est une mémoire ultra rapide intégrée au microprocesseur. Elle stocke les données les plus utilisées;\n- Cache externe: si le microprocesseur ne trouve pas les données dans la cache interne, il les cherche dans la cache externe. La cache externe est moins rapide que la cache interne mais plus rapide que la RAM.\nLe processeur est plus rapide que la mémoire RAM, celle-ci est beaucoup plus rapide que le disque dur. Une cache disque est utilisée entre le disque dur et la mémoire, lorsque l’ordinateur écrit sur le disque, les données sont placées dans la cache disque, elles sont alors écrites lentement (à la vitesse maximale du disque dur) alors que l’ordinateur peut s’occuper à faire autre chose. Lorsque l’ordinateur désire lire sur le disque, le cache disque peut avoir lu d’avance ou posséder des données lues auparavant, celles-ci sont alors tirées directement de la cache disque sans avoir à passer par le disque dur. Non seulement l’ordinateur peut-il lui même utiliser une partie de sa mémoire RAM comme cache entre lui et le disque dur (cache logicielle), mais les concepteurs de disques durs ont également ajouté une petite quantité de mémoire directement sur les contrôleurs de disques durs comme cache (cache matérielle) et c’est la norme actuellement dans la fabrication des disques dur.\n\n\n\n2.2.1.5 Les bus\nLes bus constituent le système de communication central de l’ordinateur. Ils relient le processeur à la mémoire centrale et aux cartes d’extensions, c’est par leur intermédiaire que transitent toutes les informations entre les différents composants d’un ordinateur. On distingue trois types de bus :\n- Le bus de données transférant les données entre le processeur et les autres parties. C’est un bus bidirectionnel;\n- Le bus d’adresses par lequel le processeur indique l’adresse mémoire à laquelle sont écrites ou lues les données;\n- Le bus de commande (ou contrôle) par lequel le processeur envoie des codes de commande aux différents organes.\nOn a par exemple:\n- Le bus système: appelé aussi FSB (Front Side Bus). C’est le bus qui assure le transport de données entre le processeur et la mémoire vive;\n- Le bus série : c’est le bus que tous les PC possèdent, celui qui débouche sur le port servant à brancher une souris ou un modem, ou encore certains périphériques de jeux. Ses défauts sont sa lenteur extrême car les données ne sont envoyées que bit par bit (0 ou 1); - Le bus parallèle: c’est le bus qui communique avec le port parallèle, qui sert à brancher l’imprimante, le scanner, des graveurs externes, etc. Il est 8 fois plus rapide que le port série (les informations sont transmises par tranche de 8 bits en parallèle, soit 1 octet à la fois), mais toujours lent si on le compare aux bus USB;\n- Le bus USB (Universal Serial Bus) : il est largement plus rapide que le bus parallèle et peut aller à la vitesse de 1.5 Mo par seconde pour l’USB 1.1. L’USB 2.0 peut quant à lui monter à 60 Mo par seconde et l’USB 3.0 jusqu’à 500 MB par seconde. Il est relié au port USB qui sert à brancher presque tous les périphériques du marché : webcams, modems, imprimantes, scanners, etc.\n- Le bus AGP (accelerated graphic port) : Il est apparu avec le Pentium II en 1997. Il permet de traiter 32 bits à la fois et à une fréquence de bus de 66 MHz. Ses qualités sont sa rapidité (500 Mo par seconde pour le 2 X et 1 Go pour le 4 X, et maintenant 2 Go par seconde pour le 8x). Il communique avec le port AGP;\n\n\n2.2.1.6 Connecteurs d’extension\nLes connecteurs d’extension sont des emplacements disponibles sur la carte mère destinés à recevoir des cartes d’extension, c’est-à-dire des cartes offrant de nouvelles fonctionnalités à l’ordinateur. Il existe plusieurs sortes de connecteurs:\n- Connecteur d’extension AGP : (Accelerated Graphics Port) est l’emplacement réservé à la carte graphique;\n- Connecteurs d’extension PCI : (Peripheral Component Interconnect) est l’emplacement où sont connectées les différentes cartes de votre ordinateur (carte son, carte réseau, etc.).\nParmi les cartes d’extension les plus courantes, on peut citer:\n- Carte graphique : est une carte d’extension dont le rôle est de produire une image affichable sur un moniteur d’ordinateur;\n- Carte son : est une carte d’extension permettant d’écouter de la musique et des sons sur votre ordinateur. Elle s’implante dans un connecteur PCI;\n- Carte réseau : est une carte d’extension permettant de connecter un ordinateur à un réseau.\n\n\n2.2.1.7 Ports de communication\nLes ports d’entrée-sortie sont des éléments matériels de l’ordinateur, permettant au système de communiquer avec des éléments extérieurs, c’est-à-dire d’échanger des données, d’où l’appellation d’interface d’entrée-sortie.\n\n2.2.1.7.1 Ports série\nLe port série est un port sur lequel on ne peut envoyer les données que bit par bit, les uns après les autres. Ce port peut se présenter sous la forme d’un connecteur 9 ou 25 broches (le nom du connecteur est DB-9 ou DB-25 suivant le nombre de broches). Sur un port série on peut brancher un modem, un scanner, une souris ou un appareil photo numérique.\n\n\n\nPort série\n\n\n\n\n2.2.1.7.2 Port parallèle\nLe port parallèle est basé sur un transfert de type parallèle. C’est-à-dire que les 8 bits d’un octet sont envoyés simultanément. Ce type de communication est nettement plus rapide que celui d’un port série. Un port parallèle permet de connecter une imprimante.\n\n\n\nPort parallèle\n\n\n\n\n2.2.1.7.3 Port USB\nLe port USB (Universal Serial Bus) est basé sur une architecture série pour deux raisons principales:\n- L’interface série permet d’utiliser une cadence d’horloge beaucoup plus élevée qu’une interface parallèle (dans une architecture parallèle à haut débit, les bits circulant sur chaque fil arrivent avec des décalages, provoquant des erreurs);\n- Le câble série est plus économique que le câble parallèle.\nLes ports USB supportent le Hot Plug & Play, c’est-à-dire qu’un périphérique peut être connecté et reconnu, sans redémarrage de l’ordinateur. Les périphériques qui disposent actuellement de ce type de port sont les imprimantes, scanners, Webcams, etc.\n\n\n\n\n2.2.2 Les unités de stockage\nUne mémoire de masse est une mémoire de grande capacité, non volatile. Elle conserve les données de manière permanente. Les mémoires de masse les plus utilisées sont :\n- le disque dur pour les informations qui devront être traitées ultérieurement;\n- le CD-ROM et le DVD pour les copies de sauvegarde;\n- la clé USB et disquette pour le transfert d’information entre micro-ordinateurs.\n\n2.2.2.1 Le disque dur\nLe disque dur est un support composé de disques magnétiques sur lesquels on peut stocker de très grandes quantités d’informations (20 Go, 40 Go, 80 Go, 120 Go, …). Un disque dur est formé de plusieurs plateaux circulaires superposés entre lesquels flottent des têtes de lecture et écriture et d’un moteur central permettant la rotation de tous les plateaux en même temps.\n\n\n\nDisque dur\n\n\nChaque plateau est composé de pistes concentriques. Les pistes situées à un même rayon forment un cylindre. Les pistes sont ensuite découpées en secteurs qui sont l’unité élémentaire de stockage et dont la taille est de 512 octets. Les caractéristiques principales d’un disque dur sont les suivantes:\n- Capacité: volume de données pouvant être stockées sur le disque;\n- Taux de transfert (ou débit): quantité de données pouvant être lues ou écrites sur le disque par unité de temps. Il s’exprime en bits par seconde;\n- Vitesse de rotation: vitesse à laquelle les plateaux tournent, exprimée en nombre de tours par minute. La vitesse des disques durs est de l’ordre de 7200 à 15000 rpm (rpm : Rotation Par Minute).\nCalcul de la taille (capacité) d’un disque dur:\n\\[Capacité = Nt \\times Nc \\times Ns \\times 512 o\\]\nOu:\n- Nt: nombre de têtes (ou de faces)\n- Nc: nombre de cylindres\n- Ns: nombre de secteurs\n- o: octets\n\n\n2.2.2.2 Le lecteur CD-ROM\nLe lecteur CD-ROM permet de lire les informations se trouvant sur les disques CD-ROM. Le CD-ROM (Compact Disc - Read Only Memory) est une mémoire de masse à lecture seule, les données y ont été inscrites une fois pour toute. On ne peut plus effacer leur contenu. Le CD-ROM est un disque optique de 12 cm de diamètre et de 1mm d’épaisseur, permettant de stocker des informations numériques correspondant à 650 Mo de données informatiques. Un trou circulaire en son milieu permet de le centrer sur la platine de lecture. Un lecteur CD-ROM est caractérisé par les éléments suivants:\n- Vitesse : la vitesse d’un lecteur de CD-ROM est calculée par rapport à la vitesse d’un lecteur de CD audio. Un CD audio lit 150 Ko/s par seconde (1x). Un lecteur de CD-ROM capable de lire 30000 Ko/s sera appelé un lecteur 20x. Remarque : Le X représente une vitesse de 150 Ko/s, ce qui signifie qu’un lecteur de CD 2X à un débit de 2150= 300 Ko/s alors qu’un lecteur de CD Rom 40X a un débit de 40 150 = 6 000 Ko/s.\n- Temps d’accès : est le temps moyen pour aller d’une partie du CD à une autre.\n\n\n2.2.2.3 Le graveur\nLe graveur de CD-ROM est un outil qui permet de réaliser des sauvegardes sur des CD-ROM. Il utilise deux sortes de disques : CD-R et CD-RW. Un graveur CD/DVD permet de lire ou graver des DVD, des CD audio et des CD de données.\n\n\n2.2.2.4 Clé USB\nCe sont des lecteurs amovibles. Branchés sur un port USB, elles peuvent s’ajouter à tout moment sur un ordinateur allumé. Très pratique pour transférer des informations d’un ordinateur à l’autre.\n\n\n\n2.2.3 Les périphériques d’entrées/sorties\n\n2.2.3.1 Clavier\nLe clavier est un périphérique d’entrée (figure suivante). Il vous permet d’entrer du texte, des chiffres ou des commandes dans votre ordinateur. Il peut être AZERTY, QWERTY ou autre. On désigne par ces noms les “langues” des claviers dont les français ou anglais dont les premières touches sont A,Z,E,R,T,Y et Q,W,E,R,T,Y.\n\n\n\nClavier\n\n\nUn clavier comporte 4 grandes zones:\n- Le pavé numérique, rendu actif par la touche Verr num (contrôlée par un voyant), composé des 10 chiffres et des 4 opérations, ainsi que d’une touche entrée spécifique;\n- Le bloc alphanumérique comporte toutes les lettres de l’alphabet, les 10 chiffres, les signes de ponctuation, la barre d’espace et divers autres symboles d’usage courant;\n- Le pavé de flèches qui servent à déplacer le curseur en tous sens (gauche, droite, haut, bas), à sauter de page en page, à se positionner au début ou à la fin, à insérer ou supprimer;\n- Les touches de fonction de F1 à F12 sont associées à des commandes. Ces touches spéciales permettent d’exécuter plus efficacement des tâches particulières. Les opérations réalisées par ces touches dépendent du logiciel utilisé. Par exemple, la touche F1 sert généralement à afficher l’aide sur l’utilisation du logiciel en cours.\n\n\n2.2.3.2 Souris\nLa souris (périphérique d’entrée) est un périphérique de pointage servant à déplacer un curseur sur l’écran et permettant de sélectionner, déplacer, manipuler des objets grâce à des boutons:\n\nLe bouton gauche:\n\nCliquer (clic) est l’action consistant à appuyer une seule fois sur le bouton gauche de la souris, il permet de sélectionner une icône sur le bureau, sélectionner une commande à l’intérieur d’un menu, etc.\n\nDouble cliquer est l’action de cliquer deux fois brièvement sur le bouton gauche de la souris. Cela provoque, sur une icône, l’ouverture d’une fenêtre ou le lancement d’un programme.\n\nGlisser déplacer : indique le déplacement d’un objet en maintenant le bouton gauche enfoncé et en déplaçant la souris.\n\nLe bouton droit : Permet d’ouvrir un “menu contextuel” en rapport avec la situation du pointeur ou l’objet sélectionné.\n\n\nLe bouton droit: Permet d’ouvrir un “menu contextuel” en rapport avec la situation du pointeur ou l’objet sélectionné.\n\nMolette: Elle permet de monter et de descendre rapidement dans l’affichage d’un document.\n\n\n\n2.2.3.3 L’ecran\nL’écran est un périphérique de sortie qui permet d’afficher du texte et des images traités par l’ordinateur. Il se caractérise par les paramètres suivants:\n\nLa taille de l’écran : Elle se mesure en “pouces” (1 pouce = 2,54 cm) et correspond à la mesure de la diagonale de l’écran.\n\nLa résolution de l’écran : Elle représente le nombre de points que l’écran peut afficher. Elle indique le nombre de pixels (points) affichable à l’écran. Elle est donnée en fonction du nombre de points sur la largeur, suivi de celle en hauteur. Ce nombre de points est actuellement généralement compris entre 640x480 (640 points en longueur, 480 points en largeur) et 1600x1200."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "“Hypothesis Testing.” 2002. In, 32–57. Cambridge University\nPress. https://doi.org/10.1017/cbo9780511806384.004.\n\n\nMcKillup, Steve. 2011. “Statistics Explained,” November. https://doi.org/10.1017/cbo9781139047500.\n\n\nPopper, Karl. 2005. The Logic of Scientific Discovery.\nRoutledge. https://doi.org/10.4324/9780203994627.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "intro1.html#test-uni--vs-bidirectionnel",
    "href": "intro1.html#test-uni--vs-bidirectionnel",
    "title": "1  Pourquoi a-t-on besoin de méthodes statistiques ?",
    "section": "1.4 Test uni- vs bidirectionnel",
    "text": "1.4 Test uni- vs bidirectionnel\nL’hypothèse nulle est toujours “il n’existe pas de” différence/relation… Cela revient à dire qu’une certaine quantité est égale à 0. L’hypothèse alternative est soit:\n\nCette quantité est différente de 0 (test bidirectionnel);\n\nCette quantité est supérieure/inférieure à 0 (test unidirectionnel).\n\nAinsi on a:\n\nTest bidirectionnel:\n\n\\(H_0\\) : \\(\\mu = \\mu_0\\) ou \\(t = 0\\)\n\\(H_A\\) : \\(\\mu ≠ \\mu_0\\) ou \\(t ≠ 0\\)\n\nTest unidirectionnel:\n\n\\(H_0\\): \\(\\mu = \\mu_0\\) ou \\(t = 0\\)\n\\(H_{A1}\\): \\(\\mu &gt; \\mu_0\\) ou \\(t &gt; 0\\)\n\\(H_{A2}\\): \\(\\mu &lt; \\mu_0\\) ou \\(t &lt; 0\\)"
  },
  {
    "objectID": "intro1.html#types-derreurs",
    "href": "intro1.html#types-derreurs",
    "title": "1  Pourquoi a-t-on besoin de méthodes statistiques ?",
    "section": "1.5 Types d’erreurs",
    "text": "1.5 Types d’erreurs\nQuand on prend une décision concernqnt une hypothèse sur la base d’un échantillon donné, on n’est jamais sûr de prendre la bonne décision!!.\n\n\n\nDécisions et erreurs statistiques lors des tests d’hypothèses nulles (“Hypothesis Testing” 2002).\n\n\nOn peut se tromper de 2 manières:\n\n\\(\\alpha\\) (probabilité d’erreur de type I: rejeter \\(H_0\\) à tort) est traditionnellement fixé à 5%. Rien n’empêche de choisir un \\(\\alpha\\) plus petit ou plus grand;\n\n\\(1 - \\beta\\) (probabilité d’erreur de type II: accepter \\(H_0\\) à tort) est la puissance du test. Elle dépend notamment de:\n\nLa taille de l’effet: plus l’effet est grand, plus la probabilité de le détecter est grande;\nLa variance: plus le paramètre est connu avec précision, plus la probabilité d’en détecter une différence est grande. La précision augmente avec le nombre d’observation."
  },
  {
    "objectID": "intro1.html#compromis-entre-alpha-et-beta",
    "href": "intro1.html#compromis-entre-alpha-et-beta",
    "title": "1  Pourquoi a-t-on besoin de méthodes statistiques ?",
    "section": "1.6 Compromis entre \\(\\alpha\\) et \\(\\beta\\)",
    "text": "1.6 Compromis entre \\(\\alpha\\) et \\(\\beta\\)\nIl existe un compromis entre les probabilités d’erreur de type I (\\(\\alpha\\)) et de type II (\\(\\alpha\\)). Pour un même jeu de données, si on choisit de diminuer \\(\\alpha\\), on augmentera automatiquement \\(\\beta\\), et inversement.\n\n\n\nLe compromis entre l’erreur de type 1 et l’erreur de type 2. (a) fixé à 10 %. (b) L’abaissement à 5 % réduira le risque d’erreur de type 1, mais augmentera le risque d’erreur de type 2. (c) Une réduction à 1 % diminuera encore le risque d’erreur de type 1, mais augmentera fortement le risque d’erreur de type 2. (McKillup 2011)."
  },
  {
    "objectID": "intro1.html#les-deux-grands-types-de-questions",
    "href": "intro1.html#les-deux-grands-types-de-questions",
    "title": "1  Pourquoi a-t-on besoin de méthodes statistiques ?",
    "section": "1.7 Les deux grands types de questions",
    "text": "1.7 Les deux grands types de questions\nOn peut différencier en général 3 types de jeux de données en fonction du nombre de variables mesurées sur chaque individu:\n\nUnivarié: une seule variable;\n\nBivarié: 2 variables;\n\nMultivarié: plus de 2 variables;\n\nOn peut différencier 2 grandes classes de questions:\n\nL’hypothèse porte sur l’existence de différence(s);\n\nL’hypothèse porte sur l’existence d’une relation entre variables."
  },
  {
    "objectID": "intro1.html#les-grandes-classes-de-méthodes-danalyse",
    "href": "intro1.html#les-grandes-classes-de-méthodes-danalyse",
    "title": "1  Pourquoi a-t-on besoin de méthodes statistiques ?",
    "section": "1.8 Les grandes classes de méthodes d’analyse",
    "text": "1.8 Les grandes classes de méthodes d’analyse\n\n\n\n\n\n“Hypothesis Testing.” 2002. In, 32–57. Cambridge University Press. https://doi.org/10.1017/cbo9780511806384.004.\n\n\nMcKillup, Steve. 2011. “Statistics Explained,” November. https://doi.org/10.1017/cbo9781139047500.\n\n\nPopper, Karl. 2005. The Logic of Scientific Discovery. Routledge. https://doi.org/10.4324/9780203994627."
  },
  {
    "objectID": "intro2.html#rappels-sur-les-notions-de-base",
    "href": "intro2.html#rappels-sur-les-notions-de-base",
    "title": "\n2  Importance et notions de base\n",
    "section": "\n2.1 Rappels sur les notions de base",
    "text": "2.1 Rappels sur les notions de base\n\n2.1.1 Types de statistiques\n\n\nDescriptives: le but est d’illustrer les données;\n\n\nParamétriques: on suppose que la/les variables(s) suivent une distribution particulière;\n\n\nNon paramétriques: on ne fait aucune supposition concernant la distribution de la/les variables(s).\n\n2.1.2 Variables\n\nUne variable est un attribut mesuré pour chaque individu/observation.\n\nTypes d’échelle de mesure:\n\nRatio: le 0 est clairement défini; ne peut pas être &lt; 0.\n\nIntervalle: le 0 est arbitraire; peut être &lt; 0.\n\nOrdinale: l’ordre est défini; les rangs n’indiquent pas nécessairement des différentes constantes.\n\nNominale/Catégorique: l’ordre est non défini.\n\nContinue: présente une infinité de valeurs possibles.\n\nDiscrète: nombre limité de valeurs possibles.\n\n\n\n2.1.3 Qu’est-ce qu’une distribution?\nUne fonction qui exprime la fréquence (densité de probabilité) des différentes valeurs pouvant être prise par une variable.\nRappelons ici quelques distributions usuelles.\n\n2.1.3.1 Distribution uniforme (continue)\nBien que les origines historiques de la conception de la distribution uniforme ne soient pas concluantes, on suppose que le terme “uniforme” est né du concept d’équiprobabilité dans les jeux de dés (notez que les jeux de dés auraient un espace d’échantillonnage uniforme discret et non continu).\nLes paramètres de la distribution uniforme sont:\n\nMoyenne: \\(\\frac{1}{2}(a + b)\\).\n\nVariance: \\(\\frac{1}{12}(b - a)^2\\).\n\nLa fonction de densité de la loi uniforme est:\n\\[\nf(x) = \\left\\{\\begin{array}{ll}\\frac{1}{b - a} & \\mbox{for } a \\leq x \\leq b, \\\\ 0 & \\mbox{otherwise}\\end{array}\\right.\n\\]\n\n\n\n\n\n\n2.1.3.2 Distribution binomiale\nLa distribution binomiale est fréquemment utilisée pour modéliser le nombre de succès dans un échantillon de taille \\(n\\) tiré avec remplacement d’une population de taille \\(N\\).\nLes paramètres de la distribution binomiale sont:\n\nMoyenne: \\(\\mu = np\\).\nVariance: \\(\\sigma^2 = npq\\).\n\nLa fonction de densité de la loi binomiale est:\n\\[\nf(k, n, p) = \\binom{n}{k}p^k (1-p)^{n-k}\n\\]\n\n\n\n\n\n\n2.1.3.3 Distribution de Poisson\nLa distribution de Poisson est une distribution de probabilité discrète qui exprime la probabilité qu’un nombre donné d’événements se produisent dans un intervalle de temps fixe si ces événements se produisent avec un taux moyen constant connu et indépendamment du temps écoulé depuis le dernier événement.\nLes paramètres de la distribution de Poisson sont:\n\nMoyenne: \\(\\mu = \\lambda\\)\nVariance: \\(\\sigma^2 = \\lambda\\)\n\nLa fonction de densité de probabilité de la distribution de Poisson est:\n\\[\nf(k; \\lambda) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\n\\]\n\n\n\n\n\n\n2.1.3.4 Distribution normale\nLes distributions normales sont importantes en statistique et sont souvent utilisées dans les sciences naturelles et sociales pour représenter des variables aléatoires à valeur réelle dont la distribution n’est pas connue. Leur importance est en partie due au théorème de la limite centrale. Ce théorème stipule que, sous certaines conditions, la moyenne de nombreux échantillons (observations) d’une variable aléatoire de moyenne et de variance finies est elle-même une variable aléatoire, dont la distribution converge vers une distribution normale à mesure que le nombre d’échantillons augmente. Par conséquent, les quantités physiques qui sont censées être la somme de nombreux processus indépendants, tels que les erreurs de mesure, ont souvent des distributions qui sont presque normales.\nLes paramètres de la distribution normale sont:\n\nMoyenne: \\(\\mu = \\frac{\\sum_{i=1}^{N} X_i}{N}\\).\nVariance: \\(\\sigma^2 = \\frac{\\sum (X_i - \\mu)^2}{N}\\).\n\nLa fonction de densité de la loi normale est:\n\\[ f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}\\]\n\n\n\n\n\n\n\n\n\n\n\nPoints clés à retenir\n\n\n\n\nLa distribution normale est le terme approprié pour désigner une courbe de probabilité en cloche.\nDans une distribution normale, la moyenne est égale à zéro et l’écart-type est de 1. L’asymétrie est nulle et l’aplatissement est de 3.\nLes distributions normales sont symétriques, mais toutes les distributions symétriques ne sont pas normales.\n\n\n\n\n2.1.3.5 Distribution \\(t\\) de Student\nEn probabilité et en statistique, la distribution \\(t\\) de Student (ou simplement la distribution \\(t\\)) \\(t_\\nu\\) est une distribution de probabilité continue qui généralise la distribution normale standard. Comme cette dernière, elle est symétrique autour de zéro et en forme de cloche.\nLes paramètres de la distribution \\(t\\) de Student sont:\n\nMoyenne: 0 pour \\(\\nu &gt; 1\\) et indéfini dans le cas contraire.\nVariance: \\(\\frac{\\nu}{\\nu - 2}\\) pour \\(\\nu &gt; 2\\), \\(\\infty\\) pour \\(1 &lt; \\nu \\leq 2\\), indéfini dans les cas contraires.\n\nLa fonction de densité de probabilité de la distribution de \\(t\\) est:\n\\[\nf(t) = \\frac{\\Gamma(\\frac{\\nu + 1}{2})}{\\sqrt{\\pi \\nu} \\Gamma(\\frac{\\nu}{2})} (1 + \\frac{t^2}{\\nu}) ^ {-(\\nu + 1)/2}\n\\]\nou \\(\\nu\\) est le nombre de dégrés de libertés et \\(\\Gamma\\) est la fonction Gamma.\n\n\n\n\n\nLa distribution t de Student avec \\(\\nu\\) degrés de liberté peut être définie comme la distribution de la variable aléatoire \\(T\\) avec \\[T = \\frac{Z}{\\sqrt{V/\\nu}} = Z\\sqrt{\\frac{\\nu}{V}}\\]\navec\n\n\\(Z\\) est une normale standard avec une valeur attendue de 0 et une variance de 1 ;\n\\(V\\) suit une distribution de khi-deux (\\(\\chi^2\\)) avec \\(\\nu\\) dégrés de liberté;\n\\(Z\\) et \\(V\\) sont indépendants.\n\n\n\n\n\n\n\nPoints clés à retenir\n\n\n\n\nLa distribution \\(t\\) est une distribution de probabilité continue du score z lorsque l’écart-type estimé est utilisé au dénominateur plutôt que l’écart-type réel.\nLa distribution \\(t\\), comme la distribution normale, est en forme de cloche et symétrique, mais ses queues sont plus lourdes, ce qui signifie qu’elle a tendance à produire des valeurs très éloignées de sa moyenne.\nLes tests T sont utilisés en statistique pour estimer l’importance des résultats."
  },
  {
    "objectID": "intro2.html#pourquoi-a-t-on-besoin-de-méthodes-statistiques",
    "href": "intro2.html#pourquoi-a-t-on-besoin-de-méthodes-statistiques",
    "title": "\n2  Importance et notions de base\n",
    "section": "\n2.2 Pourquoi a-t-on besoin de méthodes statistiques ?",
    "text": "2.2 Pourquoi a-t-on besoin de méthodes statistiques ?\nLa plupart des sciences sont comparatives. Les chercheurs ont souvent besoin de savoir si un traitement expérimental particulier a eu un effet, ou s’il existe des différences entre une variable particulière mesurée à plusieurs endroits différents. Par exemple, un nouveau médicament a-t-il un effet sur la tension artérielle, un régime riche en vitamine C réduit-il le risque de cancer du foie chez l’homme, ou existe-t-il une relation entre la couverture végétale et la densité de la population de lapins ? Mais lorsque vous faites ce genre de comparaisons, les différences entre les traitements ou entre les zones échantillonnées peuvent être réelles ou peuvent simplement être le type de variation qui se produit par hasard entre les échantillons d’une même population.\nPrenons 2 situations concrètes:\n\nDans la première, nous jouons à pile ou face avec 10 pièces. On obtient après un lancer unique de chacune des pièces 3 faces et 7 piles. Pouvons-nous dire si ce lot de pièces est truqué?\n\nDans la seconde, on échantillone une population de singes, et on observe 32 femelles et 54 mâles. Y a-t-il réellement plus de mâles dans la population?\n\nLes probabilités vous aident à prendre une décision concernant vos résultats.\n\n2.2.1 Tests statistiques et niveaux de signification\nUn test statistique est une aide à la décision concernant une hypothèse (alternative vs nulle).\nL’idée maîtresse à la base de tout test d’hypothèse statistique:\n\nJe suppose que \\(H_0\\) (hypothèse nulle) est vraie (pas de différence/relation);\n\nJe calcule la p-valeur, c’est à dire la probabilité d’obtenir une différence/relation au moins aussi forte que celle que j’ai observée dans mon échantillon (qui est un fait établi);\n\nSi cette p-valeur est faible, alors il est probable que \\(H_0\\) soit fausse: la différence mesurée est simplement une mauvaise estimation d’une différence nulle.\n\nLe statisticien Sir Ronald Fisher a proposé que, si la probabilité d’obtenir cette différence ou une différence plus extrême entre le résultat attendu et le résultat réel est inférieure à 5 %, il convient de conclure que la différence est statistiquement significative (Fisher, 1954). Le choix de 5% (qui correspond à 1/20 ou 0,05) n’a pas de raison biologique. C’est la probabilité que de nombreux chercheurs utilisent comme « niveau de signification statistique » standard.\n\n\n\n\n\n\nAttention: ce seuil n’est pas une valeur magique, les statistiques ce n’est pas blanc vs noir, vrai vs faux, significatif vs non significatif…\n\n\n\n\n2.2.2 Exemple de calcul direct de la p-valeur\nPrenons un exemple de sac contenant 1000 boules blanches et noires. On en tire 6 au hasard (McKillup 2011). On veut tester l’hypothèse qu’il y a 500 blanches et 500 noires: \\(H_0\\): \\(\\mathbb{P}(blanche) = 0,5\\) vs \\(H_A\\): \\(\\mathbb{P}(blanche) ≠ 0,5\\).\n\n\n\n\n\n\nConcepts basiques de probabilité\n\n\n\nLa probabilité d’un événement ne peut varier qu’entre 0 et 1 (qui correspondent à 0 et 100%). Si un événement est certain de se produire, il a une probabilité de 1 ; alors que s’il est certain que l’événement ne se produira pas, il a une probabilité de 0.\nLa probabilité d’un événement particulier est le nombre de résultats donnant cet événement, divisé par le nombre total de résultats possibles. Par exemple, lorsque vous jouez à pile ou face, il n’y a que deux résultats possibles : pile ou face. Ces deux événements s’excluent mutuellement : il est impossible d’obtenir les deux.\nPar conséquent, la probabilité d’obtenir un résultat positif est de 1 divisé par 2 = ½ (et donc la probabilité d’obtenir un résultat négatif est également de ½).\nLa règle de l’addition\nLa probabilité d’obtenir une tête ou une queue est de ½ + ½ = 1. Il s’agit d’un exemple de la règle de l’addition : lorsque plusieurs résultats s’excluent mutuellement, la probabilité d’obtenir l’un d’entre eux est la somme de leurs probabilités respectives. (Par conséquent, la probabilité d’obtenir un 1, un 2, un 3 ou un 4 en lançant un dé à six faces est de 4/6).\nLa règle de multiplication\nÉvénements indépendants. Pour calculer la probabilité conjointe de deux ou plusieurs événements indépendants (par exemple, un face suivi d’un autre face lors de deux lancers indépendants d’une pièce de monnaie), il suffit de multiplier les probabilités indépendantes entre elles. Par conséquent, la probabilité d’obtenir deux têtes lors de deux lancers d’une pièce est de ½ ½ = ¼. La probabilité d’obtenir un pile ou un face avec deux lancers est de ½, parce qu’il y a deux façons d’obtenir ce résultat : HT ou TH.\nÉvénements connexes. Si les événements ne sont pas indépendants (par exemple, le premier événement est un nombre compris entre 1 et 3 inclus lors du lancer d’un dé à six faces et le second événement est un nombre pair), la règle de multiplication s’applique également, mais vous devez multiplier la probabilité d’un événement par la probabilité conditionnelle du second.\nLorsqu’on lance un dé, la probabilité indépendante d’un nombre compris entre 1 et 3 est de \\(3/6 = 1/2\\), et la probabilité indépendante de tout nombre pair est également de \\(1/2\\) (les nombres pairs sont 2, 4 ou 6 divisés par les six résultats possibles).\nCependant, si vous avez déjà lancé un nombre de 1 à 3, la probabilité que cet ensemble restreint de résultats soit un nombre pair est de \\(1/3\\) (parce que “2” est le seul nombre pair possible dans cet ensemble de trois résultats). Par conséquent, la probabilité des deux événements liés est de \\(1/2 \\times 1/3 = 1/6\\). Vous pouvez examiner la situation dans l’autre sens : la probabilité d’obtenir un nombre pair en lançant un dé est de \\(1/2\\) (vous obtiendriez les nombres 2, 4 ou 6) et la probabilité que l’un de ces nombres soit compris entre 1 et 3 est de \\(1/3\\) (le nombre 2 parmi ces trois résultats). Par conséquent, la probabilité des deux résultats est à nouveau \\(1/2 \\times 1/3 = 1/6\\).\n\n\n\n\n\n\n\n\n\n\nNombre de boules noires\nNombre de boules blanches\nProbabilité\nPourcentage de cas pouvant donner ce resultat\n\n\n\n6\n0\n1/64\n1,56\n\n\n5\n1\n6/64\n9,38\n\n\n4\n2\n15/64\n23,44\n\n\n3\n3\n20/64\n31,25\n\n\n2\n4\n15/64\n23,44\n\n\n1\n5\n6/64\n9,38\n\n\n0\n6\n1/64\n1,56\n\n\nTotal\n\n64/64\n100\n\n\n\n\n\nLes nombres attendus de chaque mélange possible de couleurs lors du tirage indépendant de six perles avec remplacement à 64 occasions différentes à partir d’une grande population contenant 50 % de noires et 50 % de blanches.\n\nLa probabilité de n’obtenir aucune boule blanche sur 6 boules tirées est de 1,56%. On rejette l’hypothèse nulle \\(H_0\\) puisque \\(p &lt; 2,5\\%\\) (test bidirectionnel).\n\n2.2.3 Passage intermédiaire par une statistique\nDans la majorité des cas, on ne peut pas calculer directement la p-valeur. L’alternative est de calculer une statistique qui quantifie la différence entre les données observées et les données attendues sous \\(H_0\\). On calcule ensuite la p-valeur en comparant la valeur de la statistique à sa distribution théorique sous \\(H_0\\).\n\n2.2.3.1 Inférence à une moyenne\nOn peut par exemple être amené à comparer la moyenne d’un échantillon à la moyenne d’une population dont la variance est connue. Pour un tel test on a:\n\n\n\\(H_0\\): \\(\\mu = \\mu_0\\); \\(H_A\\): \\(\\mu ≠ \\mu_0\\).\n\nStatistique de test: \\(Z_{obs} = \\frac{\\bar{Y} - \\mu_0}{ESM} = \\frac{\\bar{Y} - \\mu_0}{\\frac{\\sigma}{\\sqrt{n}}} \\sim N(0, 1)\\)\n\n\n\n\n\n\n\n\nScore Z (Z-score)\nLe score Z est une mesure statistique qui quantifie la distance entre un point de données et la moyenne d’un ensemble de données. Il est exprimé en termes d’écarts types. Il indique le nombre d’écarts types d’un point de données par rapport à la moyenne de la distribution.\nSi un score Z est égal à 0, cela signifie que le score du point de données est identique au score moyen. Un score Z de 1,0 indique une valeur qui se situe à un écart-type de la moyenne. Les scores Z peuvent être positifs ou négatifs, une valeur positive indiquant que le score est supérieur à la moyenne et une valeur négative indiquant qu’il est inférieur à la moyenne.\n\\[ Z = \\frac{x - \\mu}{\\sigma}\\]\nErreur standard à la moyenne (ESM)\nLe terme “erreur” remplace celui de “déviation” quand on parle de la variation de moyennes plutôt que de la variation de mesures individuelles.\n\n\n\n\n2.2.3.2 Et si les paramètres sont inconnus ?\nSi on ne connaît pas la variance réelle de la population, il faut tenir compte des biais possibles dus à la taille de l’échantillon (n).\nOn a alors:\n\nStatistique de test (\\(S^2\\) est la variance de l’échantillon): \\(t_{obs} = \\frac{\\bar{X} - \\mu_0}{ESM} = \\frac{\\bar{X} - \\mu_0}{\\frac{S}{\\sqrt{n -1 }}} \\sim St(n-1)\\).\n\nDegrés de liberté: nombre d’observations dans l’échantillon libres de varier quand on estime la variance.\n\nPlus n est petit, plus la distribution est large car S sous-estime σ. Quand n = ∞, Student = Normale.\n\n2.2.4 Effet de la taille de l’échantillon (n)\nPlus l’échantillon est grand, plus la précision avec laquelle est connue la moyenne est importante. Intervalle de confiance à la moyenne réelle \\(\\mu\\): \\[ \\bar{Y} \\pm t_{1-\\alpha/2; n-1} . \\frac{S}{\\sqrt{n-1}}\\]\n\n\nL’effet de la taille de l’échantillon sur la précision et l’exactitude des valeurs de \\(\\bar{X}\\) en tant qu’estimations de \\(\\mu\\) (McKillup 2011)."
  },
  {
    "objectID": "intro2.html#test-uni--vs-bidirectionnel",
    "href": "intro2.html#test-uni--vs-bidirectionnel",
    "title": "\n2  Rappel des notions de base\n",
    "section": "\n2.5 Test uni- vs bidirectionnel",
    "text": "2.5 Test uni- vs bidirectionnel\nL’hypothèse nulle est toujours “il n’existe pas de” différence/relation… Cela revient à dire qu’une certaine quantité est égale à 0. L’hypothèse alternative est soit:\n\nCette quantité est différente de 0 (test bidirectionnel);\n\nCette quantité est supérieure/inférieure à 0 (test unidirectionnel).\n\nAinsi on a:\n\nTest bidirectionnel:\n\n\n\\(H_0\\) : \\(\\mu = \\mu_0\\) ou \\(t = 0\\)\n\n\n\\(H_A\\) : \\(\\mu ≠ \\mu_0\\) ou \\(t ≠ 0\\)\n\n\n\nTest unidirectionnel:\n\n\n\\(H_0\\): \\(\\mu = \\mu_0\\) ou \\(t = 0\\)\n\n\n\\(H_{A1}\\): \\(\\mu &gt; \\mu_0\\) ou \\(t &gt; 0\\)\n\n\n\\(H_{A2}\\): \\(\\mu &lt; \\mu_0\\) ou \\(t &lt; 0\\)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rappel des notions de base</span>"
    ]
  },
  {
    "objectID": "intro2.html#types-derreurs",
    "href": "intro2.html#types-derreurs",
    "title": "\n2  Rappel des notions de base\n",
    "section": "\n2.6 Types d’erreurs",
    "text": "2.6 Types d’erreurs\nQuand on prend une décision concernqnt une hypothèse sur la base d’un échantillon donné, on n’est jamais sûr de prendre la bonne décision!!.\n\n\nDécisions et erreurs statistiques lors des tests d’hypothèses nulles (“Hypothesis Testing” 2002).\n\nOn peut se tromper de 2 manières:\n\n\n\\(\\alpha\\) (probabilité d’erreur de type I: rejeter \\(H_0\\) à tort) est traditionnellement fixé à 5%. Rien n’empêche de choisir un \\(\\alpha\\) plus petit ou plus grand;\n\n\n\\(1 - \\beta\\) (probabilité d’erreur de type II: accepter \\(H_0\\) à tort) est la puissance du test. Elle dépend notamment de:\n\nLa taille de l’effet: plus l’effet est grand, plus la probabilité de le détecter est grande;\nLa variance: plus le paramètre est connu avec précision, plus la probabilité d’en détecter une différence est grande. La précision augmente avec le nombre d’observation.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rappel des notions de base</span>"
    ]
  },
  {
    "objectID": "intro2.html#compromis-entre-alpha-et-beta",
    "href": "intro2.html#compromis-entre-alpha-et-beta",
    "title": "\n2  Rappel des notions de base\n",
    "section": "\n2.7 Compromis entre \\(\\alpha\\) et \\(\\beta\\)\n",
    "text": "2.7 Compromis entre \\(\\alpha\\) et \\(\\beta\\)\n\nIl existe un compromis entre les probabilités d’erreur de type I (\\(\\alpha\\)) et de type II (\\(\\alpha\\)). Pour un même jeu de données, si on choisit de diminuer \\(\\alpha\\), on augmentera automatiquement \\(\\beta\\), et inversement.\n\n\nLe compromis entre l’erreur de type 1 et l’erreur de type 2. (a) fixé à 10 %. (b) L’abaissement à 5 % réduira le risque d’erreur de type 1, mais augmentera le risque d’erreur de type 2. (c) Une réduction à 1 % diminuera encore le risque d’erreur de type 1, mais augmentera fortement le risque d’erreur de type 2. (McKillup 2011).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rappel des notions de base</span>"
    ]
  },
  {
    "objectID": "intro2.html#les-deux-grands-types-de-questions",
    "href": "intro2.html#les-deux-grands-types-de-questions",
    "title": "\n2  Rappel des notions de base\n",
    "section": "\n2.8 Les deux grands types de questions",
    "text": "2.8 Les deux grands types de questions\nOn peut différencier en général 3 types de jeux de données en fonction du nombre de variables mesurées sur chaque individu:\n\nUnivarié: une seule variable;\n\nBivarié: 2 variables;\n\nMultivarié: plus de 2 variables;\n\nOn peut différencier 2 grandes classes de questions:\n\nL’hypothèse porte sur l’existence de différence(s);\n\nL’hypothèse porte sur l’existence d’une relation entre variables.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rappel des notions de base</span>"
    ]
  },
  {
    "objectID": "intro2.html#les-grandes-classes-de-méthodes-danalyse",
    "href": "intro2.html#les-grandes-classes-de-méthodes-danalyse",
    "title": "\n2  Rappel des notions de base\n",
    "section": "\n2.9 Les grandes classes de méthodes d’analyse",
    "text": "2.9 Les grandes classes de méthodes d’analyse\n\n\n\n\n\n“Hypothesis Testing.” 2002. In, 32–57. Cambridge University Press. https://doi.org/10.1017/cbo9780511806384.004.\n\n\nMcKillup, Steve. 2011. “Statistics Explained,” November. https://doi.org/10.1017/cbo9781139047500.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rappel des notions de base</span>"
    ]
  },
  {
    "objectID": "intro1.html#la-méthode-scientifique",
    "href": "intro1.html#la-méthode-scientifique",
    "title": "1  Pourquoi a-t-on besoin de méthodes statistiques ?",
    "section": "",
    "text": "1.1.1 Approche hypothético-déductive\nLes caractéristiques essentielles de la vision “hypothético-déductive” de la méthode scientifique (Popper 2005) sont les suivantes : une personne observe ou prélève des échantillons du monde naturel et utilise toutes les informations disponibles pour faire une supposition intuitive et logique, appelée hypothèse, sur la manière dont le système fonctionne. La personne n’a aucun moyen de savoir si son hypothèse est correcte - elle peut s’appliquer ou non. Les prédictions faites à partir de l’hypothèse sont testées, soit par un échantillonnage supplémentaire, soit par des expériences. Si les résultats sont cohérents avec les prédictions, l’hypothèse est retenue. Dans le cas contraire, elle est rejetée et une nouvelle hypothèse est formulée Figure 1.1.\n\n\n\n\n\n\nFigure 1.1: Le processus de formulation et de vérification des hypothèses (McKillup 2011).\n\n\n\n\n\n1.1.2 Exemple d’application\nLe mille-pattes portugais Ommatioulus moreleti Figure 1.2 a été introduit accidentellement dans le sud de l’Australie depuis le Portugal dans les années 1950.\n\n\n\n\n\n\nFigure 1.2: Ommatoiulus moreleti\n\n\n\nCe mille-pattes vit dans la litière de feuilles et atteint environ quatre centimètres de long. En l’absence d’ennemis naturels dans son pays d’origine (en particulier les hérissons européens, qui mangent beaucoup de mille-pattes), son nombre a rapidement augmenté pour atteindre les proportions d’un fléau en Australie-Méridionale. Bien qu’il ne cause que très peu de dégâts aux cultures agricoles, O. moreleti est un ravageur “nuisible” sérieux car il envahit les maisons.\nEn travaillant sur les moyens de réduire les nuisances causées par le mille-pattes portugais, McKillup (McKillup 2011) a remarqué que les propriétaires de maisons qui signalaient de graves problèmes avaient des maisons bien éclairées avec de grandes fenêtres sans rideaux. En revanche, les voisins dont les maisons n’étaient pas aussi bien éclairées et qui fermaient leurs rideaux la nuit signalaient beaucoup moins de mille-pattes à l’intérieur. Le nombre d’O. moreleti par mètre carré était similaire dans la litière de feuilles autour des deux types de maisons.\n\n1.1.2.1 De l’observation à l’hypothèse\nA partir de l’exemple précédent, on peut donc en suivant l’approche hypothético-déductive les éléments suivants:\n\nEtape 1: Observation: Cette espèce peste envahit les maisons, particulièrement celles fort éclairées.\nEtape 2: Hypothèse: Les millepates sont attirés par la lumière. Hypothèse alternative (\\(H_A\\)): Les mille-pates sont attirés par la lumière. Hypothèse nulle (\\(H_0\\)): Les mille-pates ne sont pas attirés par la lumière.\nEtape 3: Prédiction à partir de l’hypothèse: Il devrait y avoir plus de millepattes sur des plaques éclairées que sur des plaques non éclairées.\n\n\n\n1.1.2.2 Prendre une décision à propos d’une hypothèse\nUne fois que l’on dispose du résultat du test expérimental d’une hypothèse, deux choses peuvent se produire :\n\nsoit les résultats de l’expérience sont cohérents avec l’hypothèse, donc l’hypothèse est retenu;\nou les résultats ne sont pas cohérents avec l’hypothèse, on peut donc rejeter l’hypothèse.\n\nSi l’hypothèse est rejetée, il est probable qu’elle soit erronée et qu’il faille en proposer une autre.\nSi l’hypothèse est retenue, qu’elle résiste à d’autres tests et qu’elle présente une très grande généralité, elle peut devenir une théorie. Mais une théorie n’est jamais qu’une hypothèse très générale qui a résisté à des tests répétés. Il est toujours possible qu’elle soit réfutée à l’avenir.\n\n\n1.1.2.3 Pourquoi une hypothèse ou une théorie ne peut-elle jamais être prouvée ?\nAucune hypothèse ou théorie ne peut jamais être prouvée - un jour, il peut y avoir des preuves qui la rejettent et conduisent à une explication différente (qui peut inclure toutes les prédictions réussies de l’hypothèse précédente). Par conséquent, nous ne pouvons que falsifier ou réfuter des hypothèses et des théories - nous ne pouvons jamais les prouver.\nLes cas de réfutation suivie d’un changement de pensée sont fréquents. En voici deux exemples.\nLes chercheurs en médecine pensaient que l’excès d’acidité de l’estomac était responsable de la majorité des ulcères gastriques chez l’homme. Un changement radical s’est opéré lorsque de nombreux ulcères ont guéri à la suite d’une antibiothérapie visant à réduire le nombre de bactéries Helicobacter pylori dans la paroi de l’estomac.\nIl existe au moins trois théories sur la manière dont le rein humain produit une solution concentrée d’urine, et la dernière en date n’est pas nécessairement correcte.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Pourquoi a-t-on besoin de méthodes statistiques ?</span>"
    ]
  },
  {
    "objectID": "intro1.html#tests-statistiques-et-niveaux-de-signification",
    "href": "intro1.html#tests-statistiques-et-niveaux-de-signification",
    "title": "1  Pourquoi a-t-on besoin de méthodes statistiques ?",
    "section": "1.3 Tests statistiques et niveaux de signification",
    "text": "1.3 Tests statistiques et niveaux de signification\nUn test statistique est une aide à la décision concernant une hypothèse (alternative vs nulle).\nL’idée maîtresse à la base de tout test d’hypothèse statistique:\n\nJe suppose que \\(H_0\\) (hypothèse nulle) est vraie (pas de différence/relation);\n\nJe calcule la p-valeur, c’est à dire la probabilité d’obtenir une différence/relation au moins aussi forte que celle que j’ai observée dans mon échantillon (qui est un fait établi);\n\nSi cette p-valeur est faible, alors il est probable que \\(H_0\\) soit fausse: la différence mesurée est simplement une mauvaise estimation d’une différence nulle.\n\nLe statisticien Sir Ronald Fisher a proposé que, si la probabilité d’obtenir cette différence ou une différence plus extrême entre le résultat attendu et le résultat réel est inférieure à 5 %, il convient de conclure que la différence est statistiquement significative (Fisher, 1954). Le choix de 5% (qui correspond à 1/20 ou 0,05) n’a pas de raison biologique. C’est la probabilité que de nombreux chercheurs utilisent comme « niveau de signification statistique » standard.\n\n\n\n\n\n\nAttention: ce seuil n’est pas une valeur magique, les statistiques ce n’est pas blanc vs noir, vrai vs faux, significatif vs non significatif…\n\n\n\n\n1.3.1 Exemple de calcul direct de la p-valeur\nPrenons un exemple de sac contenant 1000 boules blanches et noires. On en tire 6 au hasard (McKillup 2011). On veut tester l’hypothèse qu’il y a 500 blanches et 500 noires: \\(H_0\\): \\(\\mathbb{P}(blanche) = 0,5\\) vs \\(H_A\\): \\(\\mathbb{P}(blanche) ≠ 0,5\\).\n\n\n\n\n\n\nConcepts basiques de probabilité\n\n\n\nLa probabilité d’un événement ne peut varier qu’entre 0 et 1 (qui correspondent à 0 et 100%). Si un événement est certain de se produire, il a une probabilité de 1 ; alors que s’il est certain que l’événement ne se produira pas, il a une probabilité de 0.\nLa probabilité d’un événement particulier est le nombre de résultats donnant cet événement, divisé par le nombre total de résultats possibles. Par exemple, lorsque vous jouez à pile ou face, il n’y a que deux résultats possibles : pile ou face. Ces deux événements s’excluent mutuellement : il est impossible d’obtenir les deux.\nPar conséquent, la probabilité d’obtenir un résultat positif est de 1 divisé par 2 = ½ (et donc la probabilité d’obtenir un résultat négatif est également de ½).\nLa règle de l’addition\nLa probabilité d’obtenir une tête ou une queue est de ½ + ½ = 1. Il s’agit d’un exemple de la règle de l’addition : lorsque plusieurs résultats s’excluent mutuellement, la probabilité d’obtenir l’un d’entre eux est la somme de leurs probabilités respectives. (Par conséquent, la probabilité d’obtenir un 1, un 2, un 3 ou un 4 en lançant un dé à six faces est de 4/6).\nLa règle de multiplication\nÉvénements indépendants. Pour calculer la probabilité conjointe de deux ou plusieurs événements indépendants (par exemple, un face suivi d’un autre face lors de deux lancers indépendants d’une pièce de monnaie), il suffit de multiplier les probabilités indépendantes entre elles. Par conséquent, la probabilité d’obtenir deux têtes lors de deux lancers d’une pièce est de ½ ½ = ¼. La probabilité d’obtenir un pile ou un face avec deux lancers est de ½, parce qu’il y a deux façons d’obtenir ce résultat : HT ou TH.\nÉvénements connexes. Si les événements ne sont pas indépendants (par exemple, le premier événement est un nombre compris entre 1 et 3 inclus lors du lancer d’un dé à six faces et le second événement est un nombre pair), la règle de multiplication s’applique également, mais vous devez multiplier la probabilité d’un événement par la probabilité conditionnelle du second.\nLorsqu’on lance un dé, la probabilité indépendante d’un nombre compris entre 1 et 3 est de \\(3/6 = 1/2\\), et la probabilité indépendante de tout nombre pair est également de \\(1/2\\) (les nombres pairs sont 2, 4 ou 6 divisés par les six résultats possibles).\nCependant, si vous avez déjà lancé un nombre de 1 à 3, la probabilité que cet ensemble restreint de résultats soit un nombre pair est de \\(1/3\\) (parce que “2” est le seul nombre pair possible dans cet ensemble de trois résultats). Par conséquent, la probabilité des deux événements liés est de \\(1/2 \\times 1/3 = 1/6\\). Vous pouvez examiner la situation dans l’autre sens : la probabilité d’obtenir un nombre pair en lançant un dé est de \\(1/2\\) (vous obtiendriez les nombres 2, 4 ou 6) et la probabilité que l’un de ces nombres soit compris entre 1 et 3 est de \\(1/3\\) (le nombre 2 parmi ces trois résultats). Par conséquent, la probabilité des deux résultats est à nouveau \\(1/2 \\times 1/3 = 1/6\\).\n\n\n\n\n\n\n\n\n\n\n\nNombre de boules noires\nNombre de boules blanches\nProbabilité\nPourcentage de cas pouvant donner ce resultat\n\n\n\n\n6\n0\n1/64\n1,56\n\n\n5\n1\n6/64\n9,38\n\n\n4\n2\n15/64\n23,44\n\n\n3\n3\n20/64\n31,25\n\n\n2\n4\n15/64\n23,44\n\n\n1\n5\n6/64\n9,38\n\n\n0\n6\n1/64\n1,56\n\n\nTotal\n\n64/64\n100\n\n\n\n\n\n\nLes nombres attendus de chaque mélange possible de couleurs lors du tirage indépendant de six perles avec remplacement à 64 occasions différentes à partir d’une grande population contenant 50 % de noires et 50 % de blanches.\n\n\nLa probabilité de n’obtenir aucune boule blanche sur 6 boules tirées est de 1,56%. On rejette l’hypothèse nulle \\(H_0\\) puisque \\(p &lt; 2,5\\%\\) (test bidirectionnel).\n\n\n1.3.2 Passage intermédiaire par une statistique\nDans la majorité des cas, on ne peut pas calculer directement la p-valeur. L’alternative est de calculer une statistique qui quantifie la différence entre les données observées et les données attendues sous \\(H_0\\). On calcule ensuite la p-valeur en comparant la valeur de la statistique à sa distribution théorique sous \\(H_0\\).\n\n1.3.2.1 Inférence à une moyenne\nOn peut par exemple être amené à comparer la moyenne d’un échantillon à la moyenne d’une population dont la variance est connue. Pour un tel test on a:\n\n\\(H_0\\): \\(\\mu = \\mu_0\\); \\(H_A\\): \\(\\mu ≠ \\mu_0\\).\n\nStatistique de test: \\(Z_{obs} = \\frac{\\bar{Y} - \\mu_0}{ESM} = \\frac{\\bar{Y} - \\mu_0}{\\frac{\\sigma}{\\sqrt{n}}} \\sim N(0, 1)\\)\n\n\n\n\n\n\n\nScore Z (Z-score)\nLe score Z est une mesure statistique qui quantifie la distance entre un point de données et la moyenne d’un ensemble de données. Il est exprimé en termes d’écarts types. Il indique le nombre d’écarts types d’un point de données par rapport à la moyenne de la distribution.\nSi un score Z est égal à 0, cela signifie que le score du point de données est identique au score moyen. Un score Z de 1,0 indique une valeur qui se situe à un écart-type de la moyenne. Les scores Z peuvent être positifs ou négatifs, une valeur positive indiquant que le score est supérieur à la moyenne et une valeur négative indiquant qu’il est inférieur à la moyenne.\n\\[ Z = \\frac{x - \\mu}{\\sigma}\\]\nErreur standard à la moyenne (ESM)\nLe terme “erreur” remplace celui de “déviation” quand on parle de la variation de moyennes plutôt que de la variation de mesures individuelles.\n\n\n\n\n\n1.3.2.2 Et si les paramètres sont inconnus ?\nSi on ne connaît pas la variance réelle de la population, il faut tenir compte des biais possibles dus à la taille de l’échantillon (n).\nOn a alors:\n\nStatistique de test (\\(S^2\\) est la variance de l’échantillon): \\(t_{obs} = \\frac{\\bar{X} - \\mu_0}{ESM} = \\frac{\\bar{X} - \\mu_0}{\\frac{S}{\\sqrt{n -1 }}} \\sim St(n-1)\\).\n\nDegrés de liberté: nombre d’observations dans l’échantillon libres de varier quand on estime la variance.\n\nPlus n est petit, plus la distribution est large car S sous-estime σ. Quand n = ∞, Student = Normale.\n\n\n\n1.3.3 Effet de la taille de l’échantillon (n)\nPlus l’échantillon est grand, plus la précision avec laquelle est connue la moyenne est importante. Intervalle de confiance à la moyenne réelle \\(\\mu\\): \\[ \\bar{Y} \\pm t_{1-\\alpha/2; n-1} . \\frac{S}{\\sqrt{n-1}}\\]\n\n\n\nL’effet de la taille de l’échantillon sur la précision et l’exactitude des valeurs de \\(\\bar{X}\\) en tant qu’estimations de \\(\\mu\\) (McKillup 2011)."
  },
  {
    "objectID": "intro1.html#on-peut-rarement-étudier-toute-la-population",
    "href": "intro1.html#on-peut-rarement-étudier-toute-la-population",
    "title": "1  Pourquoi a-t-on besoin de méthodes statistiques ?",
    "section": "1.2 On peut rarement étudier toute la population",
    "text": "1.2 On peut rarement étudier toute la population\nC’est un fait. En biologie, on peut très rarement étudier toute la population. Une population est un ensemble de tous les individus. Un individu est une unité d’observation. Par exemple l’ensemble des mille-pates d’Australie, des poissons d’un lac, des cellules d’un organe, etc.\nOn étudie donc un échantillon représentatif de la population."
  },
  {
    "objectID": "intro1.html#comment-tester-la-prédiction-à-partir-de-son-hypothèse",
    "href": "intro1.html#comment-tester-la-prédiction-à-partir-de-son-hypothèse",
    "title": "1  Pourquoi a-t-on besoin de méthodes statistiques ?",
    "section": "1.2 Comment tester la prédiction à partir de son hypothèse?",
    "text": "1.2 Comment tester la prédiction à partir de son hypothèse?\n\n1.2.1 On peut rarement étudier toute la population\nC’est un fait. En biologie, on peut très rarement étudier toute la population. Une population est un ensemble de tous les individus. Un individu est une unité d’observation. Par exemple l’ensemble des mille-pates d’Australie, des poissons d’un lac, des cellules d’un organe, etc.\nOn étudie donc un échantillon représentatif de la population.\n\n\n1.2.2 Alors comment fait-on?\nLes statistiques sont un outil d’aide à la décision pour déterminer si les différences observées (i) reflètent une réelle différence entre populations ou (ii) sont dues uniquement au hasard.\n\n\n1.2.3 Conception expérimentale\nÉtant donné qu’un chercheur ne peut généralement pas mesurer chaque individu de la population (à moins qu’il n’étudie les quelques membres restants d’une espèce en voie de disparition), il doit travailler avec un sous-ensemble soigneusement sélectionné contenant plusieurs individus, souvent appelés unités expérimentales, qu’il espère être un échantillon représentatif à partir duquel les caractéristiques de la population peuvent être déduites.\nLa meilleure façon d’obtenir un échantillon représentatif est généralement de choisir une proportion de la population au hasard - sans biais, chaque unité expérimentale possible ayant une probabilité égale d’être sélectionnée.\nLe problème de cette approche est qu’il existe souvent de grandes différences entre les unités expérimentales d’une même population:\n\nTout d’abord, même un échantillon aléatoire peut ne pas être un bon représentant de la population dont il est issu Figure 1.3.\n\n\n\n\nFigure 1.3: Même un échantillon aléatoire n’est pas nécessairement un bon représentant de la population. Deux échantillons ont été prélevés au hasard dans la même population. Par hasard, l’échantillon 1 contient un groupe de poissons relativement grands, tandis que ceux de l’échantillon 2 sont relativement petits (McKillup 2011).\n\n\n\nDeuxièmement, même si deux populations sont très différentes, les échantillons prélevés dans chacune d’elles peuvent être similaires et donner l’impression trompeuse que les populations sont également similaires Figure 1.4.\n\n\n\n\nFigure 1.4: Les échantillons sélectionnés au hasard dans des populations très différentes ne sont pas nécessairement différents. Le hasard fait que l’échantillon 1 et l’échantillon 2 sont similaires (McKillup 2011).\n\n\n\nEnfin, la variation naturelle entre les individus d’un échantillon peut masquer tout effet d’un traitement expérimental. Les variations au sein d’un échantillon (et d’une population) sont souvent si importantes qu’il peut être difficile, voire impossible, de détecter l’effet d’un traitement Figure 1.5.\n\n\n\n\nFigure 1.5: Deux échantillons de poissons ont été prélevés dans la même population et ont été délibérément appariés de manière à ce que six individus de taille égale soient initialement présents dans chaque groupe. Les poissons du groupe traité ont été nourris avec un supplément de vitamines pendant 300 jours, tandis que ceux du groupe témoin non traité ne l’ont pas été. Grâce au supplément, chaque poisson du groupe traité a grandi environ 10 % plus longtemps, mais cette différence est faible par rapport à la variation de la croissance entre les individus, ce qui peut masquer tout effet du traitement (McKillup 2011)."
  },
  {
    "objectID": "intro1.html#tester-la-prédiction-à-partir-de-son-hypothèse",
    "href": "intro1.html#tester-la-prédiction-à-partir-de-son-hypothèse",
    "title": "1  Pourquoi a-t-on besoin de méthodes statistiques ?",
    "section": "1.2 Tester la prédiction à partir de son hypothèse",
    "text": "1.2 Tester la prédiction à partir de son hypothèse\n\n1.2.1 Comment fait-on?\nLes statistiques sont un outil d’aide à la décision pour déterminer si les différences observées (i) reflètent une réelle différence entre populations ou (ii) sont dues uniquement au hasard.\n\n\n1.2.2 On peut rarement étudier toute la population\nC’est un fait. En biologie, on peut très rarement étudier toute la population. Une population est un ensemble de tous les individus. Un individu est une unité d’observation. Par exemple l’ensemble des mille-pates d’Australie, des poissons d’un lac, des cellules d’un organe, etc.\nOn étudie donc un échantillon représentatif de la population.\n\n\n1.2.3 Choix d’un échantillon représentatif\nÉtant donné qu’un chercheur ne peut généralement pas mesurer chaque individu de la population (à moins qu’il n’étudie les quelques membres restants d’une espèce en voie de disparition), il doit travailler avec un sous-ensemble soigneusement sélectionné contenant plusieurs individus, souvent appelés unités expérimentales, qu’il espère être un échantillon représentatif à partir duquel les caractéristiques de la population peuvent être déduites.\nLa meilleure façon d’obtenir un échantillon représentatif est généralement de choisir une proportion de la population au hasard - sans biais, chaque unité expérimentale possible ayant une probabilité égale d’être sélectionnée.\nLe problème de cette approche est qu’il existe souvent de grandes différences entre les unités expérimentales d’une même population:\n\nTout d’abord, même un échantillon aléatoire peut ne pas être un bon représentant de la population dont il est issu Figure 1.3.\n\n\n\n\n\n\n\nFigure 1.3: Même un échantillon aléatoire n’est pas nécessairement un bon représentant de la population. Deux échantillons ont été prélevés au hasard dans la même population. Par hasard, l’échantillon 1 contient un groupe de poissons relativement grands, tandis que ceux de l’échantillon 2 sont relativement petits (McKillup 2011).\n\n\n\n\nDeuxièmement, même si deux populations sont très différentes, les échantillons prélevés dans chacune d’elles peuvent être similaires et donner l’impression trompeuse que les populations sont également similaires Figure 1.4.\n\n\n\n\n\n\n\nFigure 1.4: Les échantillons sélectionnés au hasard dans des populations très différentes ne sont pas nécessairement différents. Le hasard fait que l’échantillon 1 et l’échantillon 2 sont similaires (McKillup 2011).\n\n\n\n\nEnfin, la variation naturelle entre les individus d’un échantillon peut masquer tout effet d’un traitement expérimental. Les variations au sein d’un échantillon (et d’une population) sont souvent si importantes qu’il peut être difficile, voire impossible, de détecter l’effet d’un traitement Figure 1.5.\n\n\n\n\n\n\n\nFigure 1.5: Deux échantillons de poissons ont été prélevés dans la même population et ont été délibérément appariés de manière à ce que six individus de taille égale soient initialement présents dans chaque groupe. Les poissons du groupe traité ont été nourris avec un supplément de vitamines pendant 300 jours, tandis que ceux du groupe témoin non traité ne l’ont pas été. Grâce au supplément, chaque poisson du groupe traité a grandi environ 10 % plus longtemps, mais cette différence est faible par rapport à la variation de la croissance entre les individus, ce qui peut masquer tout effet du traitement (McKillup 2011).\n\n\n\n\n\n1.2.4 Caractéristiques recherchées pour les mesures/données\nL’objectif est d’obtenir des mesures avec la plus grande précision et sans biais.\n\nLa précision est déterminée la variabilité des mesures répétées de la même quantité.\nLes biais proviennent d’une inadéquation systématique entre la mesure et la valeur réelle.\n\n\n1.2.4.1 La différence entre mesurer et manipuler\nIl existe deux grandes classes d’expériences:\n\nMesure seule: on mesure les variables d’un système dans son état existant;\nMesure avec manipulation: on modifie/manipule l’état d’un système et on mesure les changements qui en résultent.\n\n\n\n1.2.4.2 Les différences entre corrélation et cause\nSeule une expérience avec manipulation peut démontrer un lien de cause à effet.\nIl faut se méfier des relations observées dans une expérience sans manipulation.\nPar exemple, l’humidité du sol peut déterminer à la fois le nombre de souris et le poids du blé. Par conséquent, bien qu’il existe une relation de cause à effet entre l’humidité du sol et chacune des deux variables, celles-ci ne sont pas elles-mêmes liées de manière causale.\n\n\n1.2.4.3 L’importance de la réplication\nSeule la réplication/répétition (prise de plusieurs mesures de la même variable sur des individus indépendants) permet de déterminer la variation due au hasard/\nC’est donc un élément vital de toute expérience.\nPrenons l’exemple de l’échantillonnage du lac Dark, dans le Wisconsin, pour étudier la densité de la population de crevettes d’eau douce en fonction de la profondeur (McKillup 2011).\nSi vous n’échantillonnez qu’à un seul endroit Figure 1.6 (a), les résultats ne donneront pas une bonne indication de l’évolution de la densité de la population de crevettes en fonction de la profondeur du lac. L’échantillonnage doit être répété, mais il est peu utile d’échantillonner de façon répétée une petite zone (par exemple en prenant plusieurs échantillons sous ’’ dans la Figure 1.6 (b)) car cela ne donnera toujours pas une indication précise des changements de la densité de la population en fonction de la profondeur dans l’ensemble du lac (bien qu’il puisse donner une indication très précise des conditions dans cette partie particulière du lac). Ce type d’échantillonnage est un aspect de ce que Hurlbert (1984) a appelé pseudoréplication. Seul le cas numéro de la Figure 1.6 (c) est correcte.\n\n\n\n\n\n\nFigure 1.6: Variation du nombre de crevettes d’eau douce par mètre cube d’eau à deux profondeurs différentes (10 m et 20 m) dans le lac Dark, Wisconsin (McKillup 2011).\n\n\n\n\n\n1.2.4.4 La pseudoréplication, un piège à éviter\nL’un des pièges les plus redoutables consiste à faire croire que l’on dispose d’un plan expérimental de manipulation reproduit, alors qu’il ne l’est pas du tout.\nPrésentons ici 4 cas de replication apparentes:\n\nMême si vous disposez de plusieurs réplicats distincts pour chaque traitement (par exemple cinq aquariums de traitement et cinq aquariums de contrôle), la disposition de ces réplicats peut entraîner un manque d’indépendance.\n\n\n\nCas de réplication apparente. Le regroupement des réplicats signifie qu’il n’y a pas d’indépendance entre les contrôles ou les traitements.\n\n\nRéplicats placées en alternance. Si vous avez décidé de contourner le problème du regroupement en plaçant les traitements et les contrôles en alternance (c’est-à-dire en plaçant, de gauche à droite, le traitement 1, le contrôle 1 ; le traitement 2, le contrôle 2 ; le traitement 3, etc…), des problèmes peuvent subsister. ), il peut encore y avoir des problèmes. Par hasard, tous les traitement (ou tous les contrôles) peuvent être soumis à d’autres caractéristiques régulières dont vous n’êtes même pas conscient.\n\n\n\nUne disposition régulière des traitements et des contrôles peut, par hasard, correspondre à une caractéristique de l’environnement (ici les très évidents plafonniers) susceptible d’affecter les résultats.\n\n\nSouvent, en raison d’un manque d’équipement, il se peut que vous deviez placer toutes les réplicats d’un traitement à une température donnée dans une seule armoire à température contrôlée, et toutes les répliques d’un traitement à une autre température dans une seule autre armoire. Malheureusement, s’il y a quelque chose de particulier à une armoire, en plus de la température, alors le traitement expérimental ou le traitement de contrôle peut être affecté. Ce schéma est appelé “ségrégation isolante”. \n\n\n\n1.2.4.5 Exercice\nIdentifiez tous les potentiels problèmes qui découle de l’expérimentation ci-dessous.\n\n\n\n\n1.2.5 La conception d’une expérience est une affaire de compromis\nLa conception d’une expérience bien contrôlée, correctement reproduite et réaliste a été décrite par certains chercheurs comme un “art”. Ce n’est pas le cas, mais il y a souvent plusieurs façons de tester la même hypothèse, et donc plusieurs expériences différentes qui pourraient être réalisées.\nOn a souvent dit qu’il n’y avait pas d’expérience parfaite. L’un des problèmes inhérents est qu’au fur et à mesure qu’une conception s’améliore, le coût en temps et en équipement augmente également, mais la capacité à réaliser réellement l’expérience diminue (figure 4.6). Un modèle absolument parfait peut être impossible à réaliser. Par conséquent, chaque chercheur doit choisir un modèle qui soit “suffisamment bon” tout en restant pratique. Il n’y a pas de règles en la matière - la décision relative à la conception est entre les mains du chercheur et sera finalement jugée par ses collègues qui examineront tout rapport de travail.\n\n\n\nExemple de compromis entre le coût et la capacité de réaliser une expérience. Plus la qualité du plan d’expérience augmente, plus le coût de l’expérience augmente (ligne continue), tandis que la capacité à réaliser l’expérience diminue (ligne en pointillés). Votre plan d’expérience doit généralement être un compromis entre ce qui est faisable, ce qui est abordable et ce qui est suffisamment rigoureux (McKillup 2011).\n\n\n\n\n\n\nMcKillup, Steve. 2011. “Statistics Explained,” November. https://doi.org/10.1017/cbo9781139047500.\n\n\nPopper, Karl. 2005. The Logic of Scientific Discovery. Routledge. https://doi.org/10.4324/9780203994627.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Pourquoi a-t-on besoin de méthodes statistiques ?</span>"
    ]
  },
  {
    "objectID": "intro2.html#types-de-statistiques",
    "href": "intro2.html#types-de-statistiques",
    "title": "\n2  Rappel des notions de base\n",
    "section": "",
    "text": "Descriptives: le but est d’illustrer les données;\n\n\nParamétriques: on suppose que la/les variables(s) suivent une distribution particulière;\n\n\nNon paramétriques: on ne fait aucune supposition concernant la distribution de la/les variables(s).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rappel des notions de base</span>"
    ]
  },
  {
    "objectID": "intro2.html#variables",
    "href": "intro2.html#variables",
    "title": "\n2  Rappel des notions de base\n",
    "section": "\n2.2 Variables",
    "text": "2.2 Variables\n\nUne variable est un attribut mesuré pour chaque individu/observation.\n\nTypes d’échelle de mesure:\n\nRatio: le 0 est clairement défini; ne peut pas être &lt; 0.\n\nIntervalle: le 0 est arbitraire; peut être &lt; 0.\n\nOrdinale: l’ordre est défini; les rangs n’indiquent pas nécessairement des différentes constantes.\n\nNominale/Catégorique: l’ordre est non défini.\n\nContinue: présente une infinité de valeurs possibles.\n\nDiscrète: nombre limité de valeurs possibles.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rappel des notions de base</span>"
    ]
  },
  {
    "objectID": "intro2.html#quest-ce-quune-distribution",
    "href": "intro2.html#quest-ce-quune-distribution",
    "title": "\n2  Rappel des notions de base\n",
    "section": "\n2.3 Qu’est-ce qu’une distribution?",
    "text": "2.3 Qu’est-ce qu’une distribution?\nUne fonction qui exprime la fréquence (densité de probabilité) des différentes valeurs pouvant être prise par une variable.\nRappelons ici quelques distributions usuelles.\n\n2.3.1 Distribution uniforme (continue)\nBien que les origines historiques de la conception de la distribution uniforme ne soient pas concluantes, on suppose que le terme “uniforme” est né du concept d’équiprobabilité dans les jeux de dés (notez que les jeux de dés auraient un espace d’échantillonnage uniforme discret et non continu).\nLes paramètres de la distribution uniforme sont:\n\nMoyenne: \\(\\frac{1}{2}(a + b)\\).\n\nVariance: \\(\\frac{1}{12}(b - a)^2\\).\n\nLa fonction de densité de la loi uniforme est:\n\\[\nf(x) = \\left\\{\\begin{array}{ll}\\frac{1}{b - a} & \\mbox{for } a \\leq x \\leq b, \\\\ 0 & \\mbox{otherwise}\\end{array}\\right.\n\\]\n\n\n\n\n\n\n\n\n\n2.3.2 Distribution binomiale\nLa distribution binomiale est fréquemment utilisée pour modéliser le nombre de succès dans un échantillon de taille \\(n\\) tiré avec remplacement d’une population de taille \\(N\\).\nLes paramètres de la distribution binomiale sont:\n\nMoyenne: \\(\\mu = np\\).\nVariance: \\(\\sigma^2 = npq\\).\n\nLa fonction de densité de la loi binomiale est:\n\\[\nf(k, n, p) = \\binom{n}{k}p^k (1-p)^{n-k}\n\\]\n\n\n\n\n\n\n\n\n\n2.3.3 Distribution de Poisson\nLa distribution de Poisson est une distribution de probabilité discrète qui exprime la probabilité qu’un nombre donné d’événements se produisent dans un intervalle de temps fixe si ces événements se produisent avec un taux moyen constant connu et indépendamment du temps écoulé depuis le dernier événement.\nLes paramètres de la distribution de Poisson sont:\n\nMoyenne: \\(\\mu = \\lambda\\)\nVariance: \\(\\sigma^2 = \\lambda\\)\n\nLa fonction de densité de probabilité de la distribution de Poisson est:\n\\[\nf(k; \\lambda) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\n\\]\n\n\n\n\n\n\n\n\n\n2.3.4 Distribution normale\nLes distributions normales sont importantes en statistique et sont souvent utilisées dans les sciences naturelles et sociales pour représenter des variables aléatoires à valeur réelle dont la distribution n’est pas connue. Leur importance est en partie due au théorème de la limite centrale. Ce théorème stipule que, sous certaines conditions, la moyenne de nombreux échantillons (observations) d’une variable aléatoire de moyenne et de variance finies est elle-même une variable aléatoire, dont la distribution converge vers une distribution normale à mesure que le nombre d’échantillons augmente. Par conséquent, les quantités physiques qui sont censées être la somme de nombreux processus indépendants, tels que les erreurs de mesure, ont souvent des distributions qui sont presque normales.\nLes paramètres de la distribution normale sont:\n\nMoyenne: \\(\\mu = \\frac{\\sum_{i=1}^{N} X_i}{N}\\).\nVariance: \\(\\sigma^2 = \\frac{\\sum (X_i - \\mu)^2}{N}\\).\n\nLa fonction de densité de la loi normale est:\n\\[ f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoints clés à retenir\n\n\n\n\nLa distribution normale est le terme approprié pour désigner une courbe de probabilité en cloche.\nDans une distribution normale, la moyenne est égale à zéro et l’écart-type est de 1. L’asymétrie est nulle et l’aplatissement est de 3.\nLes distributions normales sont symétriques, mais toutes les distributions symétriques ne sont pas normales.\n\n\n\n\n2.3.5 Distribution \\(t\\) de Student\nEn probabilité et en statistique, la distribution \\(t\\) de Student (ou simplement la distribution \\(t\\)) \\(t_\\nu\\) est une distribution de probabilité continue qui généralise la distribution normale standard. Comme cette dernière, elle est symétrique autour de zéro et en forme de cloche.\nLes paramètres de la distribution \\(t\\) de Student sont:\n\nMoyenne: 0 pour \\(\\nu &gt; 1\\) et indéfini dans le cas contraire.\nVariance: \\(\\frac{\\nu}{\\nu - 2}\\) pour \\(\\nu &gt; 2\\), \\(\\infty\\) pour \\(1 &lt; \\nu \\leq 2\\), indéfini dans les cas contraires.\n\nLa fonction de densité de probabilité de la distribution de \\(t\\) est:\n\\[\nf(t) = \\frac{\\Gamma(\\frac{\\nu + 1}{2})}{\\sqrt{\\pi \\nu} \\Gamma(\\frac{\\nu}{2})} (1 + \\frac{t^2}{\\nu}) ^ {-(\\nu + 1)/2}\n\\]\nou \\(\\nu\\) est le nombre de dégrés de libertés et \\(\\Gamma\\) est la fonction Gamma.\n\n\n\n\n\n\n\n\nLa distribution t de Student avec \\(\\nu\\) degrés de liberté peut être définie comme la distribution de la variable aléatoire \\(T\\) avec \\[T = \\frac{Z}{\\sqrt{V/\\nu}} = Z\\sqrt{\\frac{\\nu}{V}}\\]\navec\n\n\\(Z\\) est une normale standard avec une valeur attendue de 0 et une variance de 1 ;\n\\(V\\) suit une distribution de khi-deux (\\(\\chi^2\\)) avec \\(\\nu\\) dégrés de liberté;\n\\(Z\\) et \\(V\\) sont indépendants.\n\n\n\n\n\n\n\nPoints clés à retenir\n\n\n\n\nLa distribution \\(t\\) est une distribution de probabilité continue du score z lorsque l’écart-type estimé est utilisé au dénominateur plutôt que l’écart-type réel.\nLa distribution \\(t\\), comme la distribution normale, est en forme de cloche et symétrique, mais ses queues sont plus lourdes, ce qui signifie qu’elle a tendance à produire des valeurs très éloignées de sa moyenne.\nLes tests T sont utilisés en statistique pour estimer l’importance des résultats.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rappel des notions de base</span>"
    ]
  },
  {
    "objectID": "intro2.html#tests-statistiques-et-niveaux-de-signification",
    "href": "intro2.html#tests-statistiques-et-niveaux-de-signification",
    "title": "\n2  Rappel des notions de base\n",
    "section": "\n2.4 Tests statistiques et niveaux de signification",
    "text": "2.4 Tests statistiques et niveaux de signification\nUn test statistique est une aide à la décision concernant une hypothèse (alternative vs nulle).\nL’idée maîtresse à la base de tout test d’hypothèse statistique:\n\nJe suppose que \\(H_0\\) (hypothèse nulle) est vraie (pas de différence/relation);\n\nJe calcule la p-valeur, c’est à dire la probabilité d’obtenir une différence/relation au moins aussi forte que celle que j’ai observée dans mon échantillon (qui est un fait établi);\n\nSi cette p-valeur est faible, alors il est probable que \\(H_0\\) soit fausse: la différence mesurée est simplement une mauvaise estimation d’une différence nulle.\n\nLe statisticien Sir Ronald Fisher a proposé que, si la probabilité d’obtenir cette différence ou une différence plus extrême entre le résultat attendu et le résultat réel est inférieure à 5 %, il convient de conclure que la différence est statistiquement significative (Fisher, 1954). Le choix de 5% (qui correspond à 1/20 ou 0,05) n’a pas de raison biologique. C’est la probabilité que de nombreux chercheurs utilisent comme « niveau de signification statistique » standard.\n\n\n\n\n\n\nAttention: ce seuil n’est pas une valeur magique, les statistiques ce n’est pas blanc vs noir, vrai vs faux, significatif vs non significatif…\n\n\n\n\n2.4.1 Exemple de calcul direct de la p-valeur\nPrenons un exemple de sac contenant 1000 boules blanches et noires. On en tire 6 au hasard (McKillup 2011). On veut tester l’hypothèse qu’il y a 500 blanches et 500 noires: \\(H_0\\): \\(\\mathbb{P}(blanche) = 0,5\\) vs \\(H_A\\): \\(\\mathbb{P}(blanche) ≠ 0,5\\).\n\n\n\n\n\n\nConcepts basiques de probabilité\n\n\n\nLa probabilité d’un événement ne peut varier qu’entre 0 et 1 (qui correspondent à 0 et 100%). Si un événement est certain de se produire, il a une probabilité de 1 ; alors que s’il est certain que l’événement ne se produira pas, il a une probabilité de 0.\nLa probabilité d’un événement particulier est le nombre de résultats donnant cet événement, divisé par le nombre total de résultats possibles. Par exemple, lorsque vous jouez à pile ou face, il n’y a que deux résultats possibles : pile ou face. Ces deux événements s’excluent mutuellement : il est impossible d’obtenir les deux.\nPar conséquent, la probabilité d’obtenir un résultat positif est de 1 divisé par 2 = ½ (et donc la probabilité d’obtenir un résultat négatif est également de ½).\nLa règle de l’addition\nLa probabilité d’obtenir une tête ou une queue est de ½ + ½ = 1. Il s’agit d’un exemple de la règle de l’addition : lorsque plusieurs résultats s’excluent mutuellement, la probabilité d’obtenir l’un d’entre eux est la somme de leurs probabilités respectives. (Par conséquent, la probabilité d’obtenir un 1, un 2, un 3 ou un 4 en lançant un dé à six faces est de 4/6).\nLa règle de multiplication\nÉvénements indépendants. Pour calculer la probabilité conjointe de deux ou plusieurs événements indépendants (par exemple, un face suivi d’un autre face lors de deux lancers indépendants d’une pièce de monnaie), il suffit de multiplier les probabilités indépendantes entre elles. Par conséquent, la probabilité d’obtenir deux têtes lors de deux lancers d’une pièce est de ½ ½ = ¼. La probabilité d’obtenir un pile ou un face avec deux lancers est de ½, parce qu’il y a deux façons d’obtenir ce résultat : HT ou TH.\nÉvénements connexes. Si les événements ne sont pas indépendants (par exemple, le premier événement est un nombre compris entre 1 et 3 inclus lors du lancer d’un dé à six faces et le second événement est un nombre pair), la règle de multiplication s’applique également, mais vous devez multiplier la probabilité d’un événement par la probabilité conditionnelle du second.\nLorsqu’on lance un dé, la probabilité indépendante d’un nombre compris entre 1 et 3 est de \\(3/6 = 1/2\\), et la probabilité indépendante de tout nombre pair est également de \\(1/2\\) (les nombres pairs sont 2, 4 ou 6 divisés par les six résultats possibles).\nCependant, si vous avez déjà lancé un nombre de 1 à 3, la probabilité que cet ensemble restreint de résultats soit un nombre pair est de \\(1/3\\) (parce que “2” est le seul nombre pair possible dans cet ensemble de trois résultats). Par conséquent, la probabilité des deux événements liés est de \\(1/2 \\times 1/3 = 1/6\\). Vous pouvez examiner la situation dans l’autre sens : la probabilité d’obtenir un nombre pair en lançant un dé est de \\(1/2\\) (vous obtiendriez les nombres 2, 4 ou 6) et la probabilité que l’un de ces nombres soit compris entre 1 et 3 est de \\(1/3\\) (le nombre 2 parmi ces trois résultats). Par conséquent, la probabilité des deux résultats est à nouveau \\(1/2 \\times 1/3 = 1/6\\).\n\n\n\n\n\n\n\n\n\n\nNombre de boules noires\nNombre de boules blanches\nProbabilité\nPourcentage de cas pouvant donner ce resultat\n\n\n\n6\n0\n1/64\n1,56\n\n\n5\n1\n6/64\n9,38\n\n\n4\n2\n15/64\n23,44\n\n\n3\n3\n20/64\n31,25\n\n\n2\n4\n15/64\n23,44\n\n\n1\n5\n6/64\n9,38\n\n\n0\n6\n1/64\n1,56\n\n\nTotal\n\n64/64\n100\n\n\n\n\n\nLes nombres attendus de chaque mélange possible de couleurs lors du tirage indépendant de six perles avec remplacement à 64 occasions différentes à partir d’une grande population contenant 50 % de noires et 50 % de blanches.\n\nLa probabilité de n’obtenir aucune boule blanche sur 6 boules tirées est de 1,56%. On rejette l’hypothèse nulle \\(H_0\\) puisque \\(p &lt; 2,5\\%\\) (test bidirectionnel).\n\n2.4.2 Passage intermédiaire par une statistique\nDans la majorité des cas, on ne peut pas calculer directement la p-valeur. L’alternative est de calculer une statistique qui quantifie la différence entre les données observées et les données attendues sous \\(H_0\\). On calcule ensuite la p-valeur en comparant la valeur de la statistique à sa distribution théorique sous \\(H_0\\).\n\n2.4.2.1 Inférence à une moyenne\nOn peut par exemple être amené à comparer la moyenne d’un échantillon à la moyenne d’une population dont la variance est connue. Pour un tel test on a:\n\n\n\\(H_0\\): \\(\\mu = \\mu_0\\); \\(H_A\\): \\(\\mu ≠ \\mu_0\\).\n\nStatistique de test: \\(Z_{obs} = \\frac{\\bar{Y} - \\mu_0}{ESM} = \\frac{\\bar{Y} - \\mu_0}{\\frac{\\sigma}{\\sqrt{n}}} \\sim N(0, 1)\\)\n\n\n\n\n\n\n\n\nScore Z (Z-score)\nLe score Z est une mesure statistique qui quantifie la distance entre un point de données et la moyenne d’un ensemble de données. Il est exprimé en termes d’écarts types. Il indique le nombre d’écarts types d’un point de données par rapport à la moyenne de la distribution.\nSi un score Z est égal à 0, cela signifie que le score du point de données est identique au score moyen. Un score Z de 1,0 indique une valeur qui se situe à un écart-type de la moyenne. Les scores Z peuvent être positifs ou négatifs, une valeur positive indiquant que le score est supérieur à la moyenne et une valeur négative indiquant qu’il est inférieur à la moyenne.\n\\[ Z = \\frac{x - \\mu}{\\sigma}\\]\nErreur standard à la moyenne (ESM)\nLe terme “erreur” remplace celui de “déviation” quand on parle de la variation de moyennes plutôt que de la variation de mesures individuelles.\n\n\n\n\n2.4.2.2 Et si les paramètres sont inconnus ?\nSi on ne connaît pas la variance réelle de la population, il faut tenir compte des biais possibles dus à la taille de l’échantillon (n).\nOn a alors:\n\nStatistique de test (\\(S^2\\) est la variance de l’échantillon): \\(t_{obs} = \\frac{\\bar{X} - \\mu_0}{ESM} = \\frac{\\bar{X} - \\mu_0}{\\frac{S}{\\sqrt{n -1 }}} \\sim St(n-1)\\).\n\nDegrés de liberté: nombre d’observations dans l’échantillon libres de varier quand on estime la variance.\n\nPlus n est petit, plus la distribution est large car S sous-estime σ. Quand n = ∞, Student = Normale.\n\n2.4.3 Effet de la taille de l’échantillon (n)\nPlus l’échantillon est grand, plus la précision avec laquelle est connue la moyenne est importante. Intervalle de confiance à la moyenne réelle \\(\\mu\\): \\[ \\bar{Y} \\pm t_{1-\\alpha/2; n-1} . \\frac{S}{\\sqrt{n-1}}\\]\n\n\nL’effet de la taille de l’échantillon sur la précision et l’exactitude des valeurs de \\(\\bar{X}\\) en tant qu’estimations de \\(\\mu\\) (McKillup 2011).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rappel des notions de base</span>"
    ]
  },
  {
    "objectID": "chapter1.html#préambule",
    "href": "chapter1.html#préambule",
    "title": "\n3  Comparaison de moyennes\n",
    "section": "",
    "text": "3.1.1 Nomenclature\nDans ce chapitre, nous supposons que:\n\nLa réponse \\(Y\\) est une variable quantitative continue qui suit une distribution normale;\nL’hypothèse de test porte sur l’existence de différence(s) de la moyenne de \\(Y\\) entre plusieurs groupes;\nLes groupes sont des niveaux du facteur/critère \\(X\\);\n\\(X\\) est une variable discrète, souvent qualitative nominale;\n\n\\(X\\) peut être fixe ou aléatoire:\n\nfixe: on ne s’intéresse qu’aux niveaux étudiés, choisis spécifiquement (p. ex. mâle vs femelle);\naléatoire: on s’intéresse à tous les niveaux possibles, parmi lesquels on en a étudié certains choisis aléatoirement (p. ex. Espagne, Finlande et Pologne pour représenter l’UE).\n\n\n\n3.1.2 Techniques de comparaison de moyennes\nDans le cas ou le jeu de données contient 2 niveaux pour \\(X\\) (c.à.d. 2 groupes) alors on effectue un test de \\(t\\). S’il y a plus de 2 niveaux pour \\(X\\) alors une analyse de variance à un critère de classification (ANOVA 1) est choisi. S’il y a plus d’un critère de classification pour \\(X\\) alors on aura un ANOVA2, ANOVA3, …",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Comparaison de moyennes</span>"
    ]
  },
  {
    "objectID": "chapter1.html#comparaison-de-2-moyennes",
    "href": "chapter1.html#comparaison-de-2-moyennes",
    "title": "\n3  Comparaison de moyennes\n",
    "section": "\n3.2 Comparaison de 2 moyennes",
    "text": "3.2 Comparaison de 2 moyennes\nOn distingue 2 cas pour les expériences où une variable continue \\(Y\\) est mesurée sur les individus appartenant à 2 groupes (A et B):\n\nSoit une mesure du groupe A est associé avec 1 et 1 seule mesure du groupe B (et inversement): les données sont dites “pairées”;\nSoit les mesures du groupe A ne sont pas associées aux mesures du groupe B: les données sont dites “indépendantes”.\n\n\n\n\n\n\n\nLire les valeurs critiques (fractiles) de la loi de t avec R\n\n\n\nPour trouver la valeur critique T dans R, vous pouvez utiliser la fonction qt(), qui utilise la syntaxe suivante :\n\nqt(p, df, lower.tail=TRUE)\n\noù :\n\np: le niveau de signification à utiliser;\ndf: Les degrés de liberté;\nlower.tail: Si TRUE, la probabilité à gauche de p dans la distribution t est renvoyée. Si FALSE, la probabilité à droite est renvoyée. La valeur par défaut est TRUE.\n\nTest unilatéral à gauche\nSupposons que nous voulions trouver la valeur critique de \\(t\\) pour un test unilatéral gauche avec un niveau de signification de 0,05 et un degrés de liberté = 18.\n\nqt(p = 0.05, df = 18, lower.tail = TRUE)\n\n[1] -1.734064\n\n\nLa valeur critique \\(t\\) est de -1,734. Ainsi, si la statistique du test est inférieure à cette valeur, les résultats du test sont statistiquement significatifs.\nTest unilatéral à droite\nSupposons que nous voulions trouver la valeur critique de \\(t\\) pour un test unilatéral à droite avec un niveau de signification de 0,05 et un degrés de liberté = 18.\n\nqt(p = 0.05, df = 18, lower.tail = FALSE)\n\n[1] 1.734064\n\n\nLa valeur critique \\(t\\) est de 1,734. Ainsi, si la statistique du test est supérieur à cette valeur, les résultats du test sont statistiquement significatifs.\nTest bilatéral\nSupposons que nous voulions trouver la valeur critique de \\(t\\) pour un test bilatéral avec un niveau de signification de 0,05 et un degrés de liberté = 18.\n\nqt(p = 0.05/2, df = 18, lower.tail = FALSE)\n\n[1] 2.100922\n\n\nChaque fois que vous effectuez un test bilatéral, il y a deux valeurs critiques. Dans le cas présent, les valeurs critiques de T sont 2,1 et -2,1.\nPar conséquent, si la statistique du test est inférieure à -2,1 ou supérieure à 2,1, les résultats du test sont statistiquement significatifs.\n\n\n\n3.2.1 Données pairées: test de \\(t\\) pairé\nPar exemple, on mesure le temps mis par des sprinteurs pour couvrir le 100m lors de 2 jours de course consécutifs, pour vérifier l’existence d’un effet d’adaptation à un environnement non familier. On a alors les hypothèses suivantes:\n\n\\(H_0\\): il n’y a pas de différence entre les 2 jours;\n\\(H_A\\): il y a une différence entre les 2 jours.\n\nPour un test de \\(t\\) pairé on a \\(t_{obs} = \\frac{\\bar{Y_D} - \\mu_D}{SEM} = \\frac{\\bar{Y_D} - \\mu_D}{\\frac{S_D}{\\sqrt{n - 1}}} \\sim St(n-1)\\).\nEn partant de l’exemple précédent dont les données onst présentées ici:\n\n\n\n\n\n\n\n\nNuméro\nTemps de course (Jour 1)\nTemps de course (Jour 2)\nDifférence \n\n\n\n1\n13,5\n13,6\n +0,1\n\n\n2\n14,6\n14,6\n0,0\n\n\n3\n12,7\n12,6\n-0,1\n\n\n4\n15,5\n15,7\n+0,2\n\n\n5\n11,1\n11,1\n0,0\n\n\n6\n16,4\n16,6\n+0,2\n\n\n7\n13,2\n13,2\n0,0\n\n\n8\n19,3\n19,5\n+0,2\n\n\n9\n16,7\n16,8\n+0,1\n\n\n10\n18,4\n18,7\n+0,3\n\n\n\nPour rappel, le test de \\(t\\) n’est rien d’autre qu’un test d’hypothèse sur une moyenne:\n\n\\(H_0\\) :\\(\\mu = \\mu_0\\) , en d’autre termes la moyenne de la différence est égale à 0;\n\\(H_A\\): \\(\\mu \\neq \\mu_0\\), en d’autres termes, la moyenne de la différence est différente de 0.\n\nA partir des données ci-dessus présentées on a:\n\nDégré de libertés (ddl) = \\(n-1\\) = 10 - 1 = 9;\n\\(\\bar{X} = 0,100\\), \\(s = 0,1247\\), \\(n = 10\\);\n\\(SEM = \\frac{S_D}{\\sqrt{n - 1}}\\) = 0,0394.\n\nPour un dégré de liberté de 9 on a \\(t_9 = \\frac{0,10 - 0}{0,03944} = 2,5355\\).\nEn utilisant la table ou R (voir ci-dessous) la valeur critique de \\(t_9\\) pour \\(\\alpha = 0,05\\) est de \\(2,262\\) (\\(t_{obs} = 2,5355 &gt; t_{lu} = 2,263\\)).\n\nqt(p=0.05/2, df=9, lower.tail=FALSE)\n\n[1] 2.262157\n\n\nPar conséquent, la valeur de \\(t\\) se situe en dehors de l’intervalle dans lequel on s’attendrait à ce que \\(95 \\%\\) des statistiques \\(t\\) générées par des échantillons de \\(n = 9\\) à partir d’une population où \\(\\mu = 0\\). Il a donc été conclu que la moyenne de la population des différences de temps de course était significativement différente (\\(P &lt; 0,05\\)) d’une moyenne attendue de zéro.\n\n3.2.2 Données indépendantes: test de \\(t\\) indépendant\nUn écologiste a échantillonné la longueur de la coquille de 15 palourdes d’eau douce dans chacun de deux lacs afin de déterminer si ces échantillons étaient susceptibles de provenir de populations ayant la même longueur moyenne de coquille.\n\n\nLac A\nLac B\n\n\n\n25\n45\n\n\n40\n37\n\n\n34\n36\n\n\n37\n38\n\n\n38\n49\n\n\n35\n47\n\n\n29\n32\n\n\n32\n41\n\n\n35\n38\n\n\n44\n45\n\n\n27\n33\n\n\n33\n39\n\n\n37\n46\n\n\n38\n47\n\n\n36\n40\n\n\n\nPour cette étude on a les hypothèses suivantes:\n\n\\(H_0: \\mu_A = \\mu_B\\): il n’y a pas de différence de taille moyenne entre les 2 lacs;\n\\(H_1: \\mu_A \\neq \\mu_B\\): il y a une différence de taille moyenne entre les 2 lacs.\n\nPour tester les hypothèses, il faut tenir compte de la taille des deux populations desquelles dépend le \\(t_{obs}\\) :\n\nSi \\(n_A = n_B\\): \\(t_{obs} = \\frac{(\\bar{Y_A} - \\bar{Y_B}) - (\\mu_A - \\mu_B)}{\\sqrt{\\frac{S^2_A}{n_A} + \\frac{S^2_B}{n_B}}} \\sim St(n_A + n_B - 2)\\)\n\nSi \\(n_A \\neq n_B\\): \\(t_{obs} = \\frac{(\\bar{Y_A} - \\bar{Y_B}) - (\\mu_A - \\mu_B)}{\\sqrt{(\\frac{(n_A - 1) \\times S^2_A + (n_B - 1) \\times S^2_B}{n_A + n_B - 2})(\\frac{1}{n_A} + \\frac{1}{n_B})}} \\sim St(n_A + n_B - 2)\\).\n\nNotre étude se situant dans le premier cas, on a alors:\n\\(t_{obs} = \\frac{(34,67 - 40,87) - (0)}{\\sqrt{\\frac{24,67}{15} + \\frac{28,69}{15}}} = -3,287\\).\nAvec le dégré de liberté \\(df = n_A + n_B - 2 = 15 + 15 - 2 = 28\\), on a :\n\nqt(p=0.05/2, df=28, lower.tail=FALSE)\n\n[1] 2.048407\n\n\nLa valeur critique de \\(t_{28}\\) pour une valeur de 0,05 est de 2,048, de sorte que les deux moyennes de l’échantillon ont une probabilité inférieure à 5 % d’être issues de la même population.\n\n3.2.3 Test de \\(t\\) pairé vs test de \\(t\\) indépendant\nEt si on avait analysé l'exemple des sprinteurs comme si les observations des 2 jours étaient indépendantes? A ce moment on obtiendrait \\(t_{obs} = -0.084\\), \\(df = 18\\), \\(t_{lu} = -2,1\\).\nLa différence entre les 2 jours n'apparaît plus du tout comme significative!!\nPourquoi?\nDans un test de t indépendant, on intègre la différence entre sprinteurs dans la variation due au hasard. De ce fait, la différence entre moyennes des 2 jours paraît faible comparée aux différences entre sprinteurs.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Comparaison de moyennes</span>"
    ]
  },
  {
    "objectID": "intro1.html",
    "href": "intro1.html",
    "title": "1  Pourquoi a-t-on besoin de méthodes statistiques ?",
    "section": "",
    "text": "1.1 La méthode scientifique",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Pourquoi a-t-on besoin de méthodes statistiques ?</span>"
    ]
  },
  {
    "objectID": "intro2.html",
    "href": "intro2.html",
    "title": "\n2  Rappel des notions de base\n",
    "section": "",
    "text": "2.1 Types de statistiques",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rappel des notions de base</span>"
    ]
  },
  {
    "objectID": "chapter1.html",
    "href": "chapter1.html",
    "title": "\n3  Comparaison de moyennes\n",
    "section": "",
    "text": "3.1 Préambule",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Comparaison de moyennes</span>"
    ]
  },
  {
    "objectID": "chapter1.html#comparaison-de-plus-de-2-moyennes",
    "href": "chapter1.html#comparaison-de-plus-de-2-moyennes",
    "title": "\n3  Comparaison de moyennes\n",
    "section": "\n3.3 Comparaison de plus de 2 moyennes",
    "text": "3.3 Comparaison de plus de 2 moyennes\nDans beaucoup d'expériences biologiques, on veut comparer les moyennes de plus de 2 groupes.\n\n3.3.1 Et pourquoi pas une série de tests de \\(t\\) ?\nTout simplement parce que la probabilité d’une erreur de type 1 augmente lorsque vous effectuez plusieurs comparaisons par paire.\nChaque fois que vous effectuez un test statistique où l’hypothèse nulle s’applique, le risque d’une erreur de type 1 est la valeur de \\(\\alpha\\). Si est \\(\\alpha = 0,05\\), la probabilité de ne pas commettre d’erreur de type 1 est 1 - \\(\\alpha\\) ou 0,95.\nSi vous disposez de trois moyennes de traitement et que vous effectuez donc trois comparaisons par paire (1 contre 2, 2 contre 3 et 1 contre 3), la probabilité de ne pas commettre d’erreur de type 1 est de \\((0,95)^3 = 0,86\\). La probabilité d’au moins une erreur de type 1 est de 0,14 ou 14 %.\nPour quatre moyennes de traitement, il y a six comparaisons possibles, de sorte que la probabilité d’absence d’erreur de type 1 est de \\((0,95)^6 = 0,74\\). La probabilité d’au moins une erreur de type 1 est de 0,26 ou 26%.\nPour cinq moyens de traitement, il y a dix comparaisons possibles, la probabilité qu’il n’y ait pas d’erreur de type 1 est donc de \\((0,95)^10  = 0,60\\). La probabilité d’au moins une erreur de type 1 est de 0,40 ou 40 %.\nCes risques sont inacceptables. Vous avez besoin d’un test qui compare plus de deux moyennes de traitement avec une erreur de type 1 égale à \\(\\alpha\\).\n\n3.3.2 Analyse de variance à un facteur\nL’analyse de la variance a été développée par le statisticien Sir Ronald A. Fisher à partir de 1918. Il s’agit d’une technique très élégante qui peut être appliquée à de nombreux plans d’expérience très complexes.\n\n3.3.2.1 Présentation de l’exemple\nImaginez que vous souhaitiez évaluer les effets de deux médicaments expérimentaux sur la croissance des tumeurs cérébrales chez l’homme. Un grand nombre de ces tumeurs ne peuvent pas être enlevées car le cerveau serait gravement endommagé. Une tumeur en croissance comprimera et remplacera le tissu neural, causant souvent des dommages mortels, c’est pourquoi il y a un grand intérêt médical pour les médicaments qui affectent la croissance des tumeurs.\nOn vous a assigné 12 sujets expérimentaux consentants, chacun ayant une tumeur cérébrale de la même taille et du même type. Quatre d’entre eux sont répartis au hasard dans un groupe de contrôle non traité, quatre sont traités avec le médicament «Tumostat» et quatre autres avec le médicament «Inhibin 4». Après deux mois de traitement, leurs tumeurs sont mesurées à nouveau.\nVotre hypothèse nulle est la suivante : «Il n’y a pas de différence dans le diamètre moyen des tumeurs entre les populations sur lesquelles ces trois échantillons ont été prélevés». L’hypothèse alternative est la suivante : «Il existe une différence dans le diamètre moyen des tumeurs parmi les populations sur lesquelles ces échantillons ont été prélevés».\nLes résultats de cette expérience sont illustrés à la Figure 3.1, le diamètre de la tumeur (en millimètres) augmentant sur l’axe Y et les trois catégories de traitement sur l’axe X.\n\n\n\n\n\nFigure 3.1: Représentation graphique du diamètre des tumeurs cérébrales humaines chez des volontaires cliniques non traités (contrôle) ou traités avec les médicaments expérimentaux Tumostat ou Inhibin 4. Le diamètre des tumeurs augmente vers le haut de la page. La ligne horizontale épaisse représente la moyenne générale, tandis que les lignes plus courtes et plus claires représentent les moyennes de traitement. Le diamètre de chaque tumeur répliquée est représenté par un carré plein (McKillup 2011).\n\n\nLes moyennes de l’échantillon de chaque groupe de quatre patients ont été calculées à partir des résultats de l’expérience. Les moyennes des échantillons de chaque groupe de quatre sont indiquées, ainsi que la grande moyenne, qui est le diamètre moyen des 12 tumeurs.\nRéfléchissez maintenant au diamètre de chaque tumeur. Il existe deux sources possibles de variation qui contribueront à l’éloigner de la moyenne générale Figure 3.2.\n\n\n\n\n\nFigure 3.2: Les flèches indiquent l’écart de chaque réplicat par rapport à la moyenne de son traitement respectif. Il s’agit uniquement de la variation due à l’erreur (McKillup 2011).\n\n\nTout d’abord, il y a l’effet du traitement qu’il a subi (Contrôle ou Tumostat ou Inhibine 4). Deuxièmement, il est probable qu’il y ait des variations entre les individus qui ne peuvent pas être contrôlées, telles que de légères différences dans la taille initiale de la tumeur, des différences dans l’état de santé général, le génotype, l’état nutritionnel et les réponses immunitaires de chaque personne, ainsi que d’autres aspects involontaires de l’expérience. Cette variation incontrôlable est appelée « erreur ». Par conséquent, le déplacement de chaque point de l’axe Y par rapport à la moyenne générale sera déterminé par la formule suivante :\n\\[ \\mbox{Diametre de la tumeur} = traitement + erreur\\]\nDans l’exemple de la Figure 3.1, le Tumostat et l’Inhibine 4 semblent avoir un effet inhibiteur sur la croissance par rapport au contrôle (dans lequel les tumeurs ont grossi), mais l’effet est-il significatif ou s’agit-il simplement du type de différence qui peut se produire par hasard parmi des échantillons prélevés dans des populations ayant la même moyenne ?\nUne ANOVA à facteur unique calcule cette probabilité de manière très simple. Pour comprendre comment l’ANOVA procède, il faut examiner les raisons pour lesquelles les valeurs de chaque tumeur et les moyennes de traitement sont là où elles sont: * Tout d’abord, le diamètre de chaque tumeur s’écarte de la moyenne de son traitement uniquement en raison de l’erreur. C’est ce qu’on appelle l’erreur ou la variation à l’intérieur du groupe;\n* Deuxièmement, la moyenne de chaque traitement sera décalée de la grande moyenne par tout effet de ce traitement plus l’erreur. Ici, puisqu’il s’agit de moyennes de traitement, la distance entre la moyenne d’un traitement particulier et la grande moyenne est l’effet moyen de toutes les répétitions de ce traitement. Pour obtenir l’effet total, il faut considérer que ce déplacement se produit pour chacune des répétitions. C’est ce qu’on appelle la variation entre les groupes;\n* Troisièmement, le diamètre de chaque tumeur sera décalé de la moyenne générale par les deux sources de variation - la variation au sein du groupe (Figure 3.2) et la variation entre les groupes (Figure 3.3) décrites ci-dessus. C’est ce qu’on appelle la variation totale de l’expérience.\n\n\n\n\n\nFigure 3.3: Les flèches indiquent le déplacement de la moyenne de chaque traitement par rapport à la moyenne générale et représentent l’effet moyen du traitement plus l’erreur pour les répétitions de ce traitement.\n\n\nLa figure Figure 3.4 montre la distance déplacée pour les quatre tumeurs de chaque traitement.\n\n\n\n\n\nFigure 3.4: Les flèches indiquent l’écart de chaque réplicat par rapport à la moyenne générale. La longueur de chaque flèche représente la variation totale affectant chaque réplicat.\n\n\nChacune des figures Figure 3.1 - Figure 3.4 montre la dispersion des points autour des moyennes. Il est donc possible de calculer une variance distincte pour chaque figure:\n\nLa variance intra-groupe, qui n’est due qu’à l’erreur (Figure 3.2), peut être calculée à partir de la dispersion des points autour de la moyenne de chaque traitement.\n\nLa variance entre les groupes, qui est due au traitement et à l’erreur (Figure 3.3), peut être calculée à partir de la dispersion des moyennes de traitement autour de la grande moyenne. La distance entre la moyenne de chaque traitement et la moyenne générale représente l’effet moyen pour le nombre de répétitions dans ce traitement.\n\nLa variance totale (Figure 3.4) est l’effet combiné de la variance intra-groupe et de la variance inter-groupe. Elle peut être calculée à partir de la dispersion de tous les points autour de la grande moyenne.\n\nCes estimations permettent d’évaluer très facilement si les moyennes des trois traitements proviennent de populations ayant la même moyenne \\(\\mu\\). Premièrement, si aucun traitement n’a d’effet, la variance entre les groupes (due au traitement plus à l’erreur) sera un petit nombre, car toutes les moyennes du traitement ne seront éloignées de la grande moyenne que par l’effet de l’erreur (Figure 3.5 (a)). Deuxièmement, si l’effet du traitement est relativement important, certaines ou toutes les moyennes du traitement seront très différentes les unes des autres et plus éloignées de la grande moyenne. Par conséquent, la variance entre les groupes (due au traitement et à l’erreur) sera importante par rapport à la variance à l’intérieur du groupe (due à l’erreur uniquement) (Figure 3.5 (b)). Au fur et à mesure que les différences entre les traitements s’accroissent, la variance entre les groupes s’accroît également.\n\n\n\n\n\nFigure 3.5: (a) Aucun effet du traitement. Les moyennes des trois traitements ne s’écartent de la moyenne générale qu’en raison de l’erreur, de sorte que la variance entre les groupes sera relativement faible. (b) Un effet du traitement. Il existe des différences relativement importantes entre les moyennes du traitement, de sorte qu’elles sont plus éloignées de la moyenne générale, ce qui rend la variance entre les groupes relativement importante.\n\n\nPar conséquent, pour obtenir une statistique montrant l’effet relatif des traitements par rapport à l’erreur, il suffit de calculer la variance entre les groupes (due aux traitements plus l’erreur) et de la diviser par la variance à l’intérieur du groupe (due à l’erreur):\n\\[\\frac{\\mbox{Variance inter-groupe (traitement + erreur)}}{\\mbox{Variance intra-groupe (erreur)}}\\]\nS’il n’y a pas d’effet de traitement, le numérateur et le dénominateur de l’équation ne feront qu’estimer l’erreur, de sorte que la valeur de cette statistique sera d’environ 1,0 (Figure 3.5 (a)). Cependant, à mesure que l’effet du traitement augmente (Figure 3.5 (b)), le numérateur de l’équation devient de plus en plus grand, de sorte que la valeur de la statistique augmente également. Au fur et à mesure qu’elle augmente, la probabilité que les traitements aient été effectués sur des populations ayant la même moyenne diminue et finit par être inférieure à 0,05.\nLa statistique obtenue en divisant une variance par une autre s’appelle la statistique F ou le ratio F. Une fois le F calculé, sa signification peut être évaluée en recherchant la distribution attendue de F sous l’hypothèse nulle d’absence de différence entre les moyennes de traitements. Lorsque les groupes de traitements sont issus de populations ayant la même moyenne (c’est-à-dire qu’aucun des traitements n’a d’effet), la valeur de la statistique sera, seulement supérieure à une valeur particulière dans 5 % des cas et sera considérée comme statistiquement significative.\n\n3.3.2.2 Calcul du F\n\nPour réaliser une ANOVA à un seul facteur, il suffit de calculer la variance entre les groupes (inter groupe) (traitement) et de la diviser par la variance à l’intérieur du groupe (intra groupe) (erreur) pour obtenir le ratio F.\nLes données de l’exemple ci-dessus sont:\n\n\nContrôle\nTumostat\nInhibin 4\n\n\n\n7\n4\n1\n\n\n8\n5\n2\n\n\n10\n7\n4\n\n\n11\n8\n5\n\n\n\nOn peut les représenter graphiquement à l’aide de cette illustration Figure 3.6:\n\n\n\n\n\nFigure 3.6: Représentation graphique du diamètre des tumeurs cérébrales humaines chez des volontaires cliniques non traités (contrôle) ou traités avec les médicaments expérimentaux Tumostat ou Inhibin 4.\n\n\n\n3.3.2.2.1 Calcul de la variation intra-groupe (erreur)\nCommençons par calculer la variance à l’intérieur du groupe (intra-groupe) (erreur) Figure 3.7:\n\n\n\n\n\nFigure 3.7: Calcul de la variance intra-groupe.\n\n\nLa somme des carrés intra-groupe (erreur) est \\[ SCR = \\sum^n_{i=1}(x_i - \\bar{x})^2\\]. On a donc:\n\\(SCR = ((7 - 9)^2 + (8 - 9)^2 + (10 - 9)^2 + (11 - 9)^2) + ((4 - 6)^2 + (5 - 6)^2 + (7 - 6)^2 + (8 - 6)^2) + ((1 - 3)^2 + (2 - 3)^2 + (4 - 3)^2 + (5 - 3)^2)\\)\n\\[ SCR = (4 + 1 + 1 + 4) + (4 + 1 + 1 + 4) + (4 + 1 + 1 + 4) = 30 \\]\nD’où on obtient la variance intra-groupe (erreur) est \\[ \\frac{SCR}{n} = 30 \\div 9 = 3,33 \\].\n\n3.3.2.2.2 Calcul de la variance inter-groupe (traitement)\nEnsuite on peut calculer la variance entre groupe (inter-groupe) (traitement). Cela se fait en deux étapes. Tout d’abord, le déplacement de la moyenne de chaque traitement par rapport à la moyenne générale est élevé au carré. Cette valeur doit être multipliée par la taille de l’échantillon pour chaque traitement afin d’obtenir l’effet total pour les répétitions de ce traitement, car le déplacement est la moyenne pour le traitement. Ces trois valeurs sont ensuite additionnées pour obtenir la somme des carrés. Ensuite, la somme des carrés sont divisés par le nombre de degrés de liberté pour obtenir la valeur carrée moyenne, qui est la variance entre les groupes (traitement) Figure 3.8.\n\n\n\n\n\nFigure 3.8: Calcul de la variance inter-groupe.\n\n\nOn a donc la somme des carrés inter-groupe (traitement) \\(= (9 - 6)^2 \\times 4 + (6 - 6)^2 \\times 4 + (3 - 6)^2 \\times 4 = 72\\).\nLa variance intra-groupe (traitement) est donc \\(72 \\div 2 = 36\\).\n\n3.3.2.2.3 Calcul de la variance totale\nTout d’abord, il faut calculer la somme des carrés pour la variation totale en prenant le déplacement de chaque point par rapport à la moyenne générale, en l’élevant au carré et en l’additionnant pour toutes les répétitions. On obtient ainsi la somme totale des carrés. En divisant la somme totale des carrés par le nombre total de degrés de liberté (il y a \\(n -1\\) degrés de liberté, et dans ce cas \\(n = 12\\)), on obtient le carré moyen Figure 3.9.\n\n\n\n\n\nFigure 3.9: Calcul de la somme totale des carrés et de la variation totale.\n\n\nOn a donc la somme des carrés totaux :\\[(25 + 16 + 4 + 1) + (4 + 1 + 1 + 4) + (25 + 16 + 4 + 1) = 102\\]\nEt la variance totale est: \\(102 \\div 11 = 9,273\\).\n\n3.3.2.2.4 Calcul du F\n\nEnfin, pour obtenir le rapport F, qui compare l’effet du traitement à l’effet de l’erreur, il suffit de diviser la variance entre les groupes (traitement) par la variance à l’intérieur des groupes (erreur). Étant donné que la variance du traitement est de 36 (Figure 3.8) et que la variance de l’erreur est de 3,33 (Figure 3.7), le rapport F de la variance du traitement / variance de l’erreur est de \\(36 \\div 3,33 = 10,8\\).\nLa table suivante donne les résultats de cette analyse dans un format similaire à celui fourni par la plupart des logiciels statistiques.\n\n\n\n\n\n\n\n\n\n\nSource de variation\nSomme des carrés\nddl\nSomme des carrés moyens\nF\nProbabilité\n\n\n\nInter-groupe (traitement)\n72\n2\n36,0\n10,8\n0,004\n\n\nIntra-groupe (erreur)\n30\n9\n3,3\n\n\n\n\nTotale\n102\n11\n\n\n\n\n\n\nVous vous demanderez peut-être pourquoi la somme totale des carrés et la variance totale de l’expérience ont été calculées, puisqu’elles ne sont pas nécessaires pour le rapport F donné ci-dessus. Le calcul a été inclus pour illustrer l’additivité des sommes des carrés et des degrés de liberté. Le tableau 9.2 montre que la somme totale des carrés (102) est la somme des sommes des carrés du traitement (72) et de l’erreur (30). Notez également que le total des degrés de liberté (11) est la somme du traitement (2) et de l’erreur (9) degrés de liberté. Cette additivité des sommes des carrés et des degrés de liberté sera utilisée lors de l’examen de modèles ANOVA plus complexes.\nIl ne vous reste plus qu’à trouver la valeur critique du rapport F. Cette procédure était autrefois fastidieuse car il y avait deux valeurs de degrés de liberté à prendre en compte - celle associée au carré moyen du traitement et celle associée au carré moyen de l’erreur - et vous deviez rechercher la valeur critique dans un grand nombre de tableaux. Ici, cependant, vous pouvez utiliser un programme de statistiques pour effectuer cette analyse, générer le rapport F et obtenir la probabilité.\nLa valeur de probabilité (p-value) présentée dans ce tableau peut être obtenue dans R par la commande:\n\npf(10.8, 2, 9, lower.tail = FALSE)\n\n[1] 0.004058307\n\n\nCette analyse peut être effectuée de la même manière dans R avec les commandes suivantes:\n\n# Chargement des données\ncancer.data &lt;- read.csv(\"data/cancer.csv\", header=T)\n\n# Lancement de l'analyse de variance\nres.aov &lt;- aov(diameter ~ drugs, data = cancer.data)\n\n# Affichage du résultat\nsummary(res.aov)\n\n            Df Sum Sq Mean Sq F value  Pr(&gt;F)   \ndrugs        2     72   36.00    10.8 0.00406 **\nResiduals    9     30    3.33                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nOn obtient alors un tableau similaire à celui présenté plus haut.\nEn conclusion \\(p = 0,04 &lt; 0,05\\), donc on peut rejeter \\(H_0\\), ce qui nous permet de parier avec une probabilité \\(p\\) de nous tromper qu’il existe au moins un groupe qui a une moyenne réelle \\(\\mu\\) différente des autres.\n\n3.3.2.3 ANOVA à un facteur vs test de t indépendant\nS’il n’y a que 2 groupes dont les observations sont indépendantes, test de t indépendant et ANOVA 1 sont équivalents.\n\\(F_{obs} = (t_{obs})^2\\), les \\(p\\) sont identiques.\nLes deux tests ont la même \\(H_0\\): \\(\\mu_1 = \\mu_2\\) mais seul le test de t permet une \\(H_A\\) du type &lt; ou &gt;. Si on veut une telle \\(H_A\\) unidirectionnelle ou tester une différence entre moyennes autre que 0 alors seul le test de t convient.\n\n3.3.2.4 Comment savoir quels groupes ont des moyennes différentes?\nLorsque vous utilisez une ANOVA à facteur unique pour examiner les résultats d’une expérience comportant trois traitements ou plus, un résultat significatif indique seulement qu’un ou plusieurs traitements semblent provenir de populations ayant des moyennes différentes. Il n’identifie pas les moyennes des traitements particuliers qui semblent provenir de la même population ou de populations différentes.\nPar exemple, une différence significative entre les moyennes des trois traitements A, B et C peut se produire de plusieurs façons. La moyenne A peut être supérieure (ou inférieure) à B et C ; la moyenne B peut être supérieure (ou inférieure) à A et C ; la moyenne C peut être supérieure (ou inférieure) à A et B ; et, enfin, les moyennes A, B et C peuvent toutes être différentes l’une de l’autre.\nDeux stratégies sont alors possibles:\n\nLes tests de comparaison multiples a posteriori ou encore tests posthoc;\n\nLes comparaison a priori ou encore contrastes a priori.\n\n\n3.3.2.4.1 Tests de comparaison multiples a posteriori\n\nLes tests de comparaisons multiples sont utilisés pour comparer un ensemble de moyennes et les affecter à des groupes qui semblent provenir de la même population. Ces tests sont généralement effectués après qu’une ANOVA I a montré une différence significative entre les traitements. Ils sont appelés tests a posteriori ou post hoc, qui signifient tous deux «après l’événement», où l’«événement» est un résultat significatif de l’ANOVA.\nDe nombreux tests de comparaison multiple ont été mis au point, mais tous fonctionnent essentiellement de la même manière.\nLa statistique t est calculée en divisant la différence entre deux moyennes par l’erreur standard de cette différence. La statistique de Tukey, \\(q\\), est calculée en divisant la différence entre deux moyennes par l’erreur standard de la moyenne. La plus petite moyenne est toujours retranchée de la plus grande, ce qui donne un nombre positif : \\[ q = \\frac{\\bar{X_A} - \\bar{X_B}}{SEM} \\]\nCette procédure est d’abord utilisée pour comparer la plus grande moyenne à la plus petite. Si la différence est significative, le test se poursuit en comparant la plus grande à la plus petite suivante et ainsi de suite. Si une différence non significative est trouvée, toutes les moyennes comprises dans l’intervalle entre cette paire sont affectées à la même population. La procédure est ensuite répétée, en commençant par la deuxième plus grande et la plus petite moyenne ; elle est répétée à nouveau en commençant par la troisième plus grande et la plus petite moyenne, et ainsi de suite. Finalement, les moyennes seront affectées à un ou plusieurs groupes, chacun contenant celles qui semblent provenir de la même population.\nPour la statistique de Tukey, vous avez besoin de la SEM (Standard Error Mean, Erreur standard moyenne) et la meilleure façon de l’obtenir est d’utiliser l’erreur quadratique moyenne de l’ANOVA, car il s’agit d’une estimation de la variance de la population, \\(\\sigma^2\\), calculée à partir du déplacement de tous les réplicats de l’expérience par rapport à leurs moyennes de traitement respectives. Par conséquent, étant donné que l’erreur standard d’une moyenne est : \\[ SEM = \\frac{\\sigma}{\\sqrt{n}} = \\sqrt{\\frac{\\sigma^2}{n}}\\].\nL’erreur standard de la moyenne estimée à partir d’une ANOVA est: \\[ SEM = \\sqrt{\\frac{MS error}{n}} \\].\nLa valeur calculée de q sera nulle lorsqu’il n’y a pas de différence entre les moyennes des deux échantillons et augmentera au fur et à mesure que la différence entre les moyennes s’accroît. Si q dépasse la valeur critique, l’hypothèse selon laquelle les moyennes proviennent de la même population est rejetée. La valeur critique de q dépend de la valeur de \\(\\alpha\\), du nombre de degrés de liberté pour l’erreur de MS et du nombre de moyennes testées.\nTest de Tukey avec R\n\n# Chargement des données\ncancer.data &lt;- read.csv(\"data/cancer.csv\", header=T)\n\n# Lancement de l'analyse de variance\nres.aov &lt;- aov(diameter ~ drugs, data = cancer.data)\n\n# Affichage du résultat\nsummary(res.aov)\n\n            Df Sum Sq Mean Sq F value  Pr(&gt;F)   \ndrugs        2     72   36.00    10.8 0.00406 **\nResiduals    9     30    3.33                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Test de Tukey\ntukey &lt;- TukeyHSD(res.aov, 'drugs', conf.level = 0.95)\n\n# Resumé du test de Tukey\ntukey\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = diameter ~ drugs, data = cancer.data)\n\n$drugs\n                   diff        lwr        upr     p adj\ninhibin 4-control    -6 -9.6044637 -2.3955363 0.0030996\ntumostat-control     -3 -6.6044637  0.6044637 0.1032324\ntumostat-inhibin 4    3 -0.6044637  6.6044637 0.1032324\n\n# Graphique du test de Tukey\nplot(tukey)\n\n\n\n\n\n\n\nAutres tests\nIl existe de nombreux autres tests de comparaison multiple. Il s’agit notamment des tests LSD, Bonferroni, Scheffé et Student-Newman-Keuls. Les plus couramment utilisés sont les tests de Tukey et de Student-Newman-Keuls (Zar, 1999). La plupart des progiciels statistiques offrent un large choix de ces tests, dont les mérites relatifs sont décrits dans des textes plus avancés.\n\n3.3.2.4.2 Tests a priori\n\nNous avons précédemment discuté sur le danger d’une probabilité accrue d’erreur de type 1 lorsque l’on effectue de nombreuses comparaisons par paire entre trois moyennes ou plus. Ici, cependant, la méthode a posteriori permettant d’identifier les moyennes de traitement qui semblent provenir de la même population utilise de nombreuses comparaisons par paires. Vous pouvez donc être amenés à penser que cette procédure présente également un risque accru d’erreur de type 1. Cependant, celà n’est pas le cas. Tout d’abord, les comparaisons a-posteriori non planifiées ne sont généralement effectuées entre tous les groupes que si l’ANOVA a détecté une différence significative entre les moyennes des traitements. Deuxièmement, les tests a posteriori sont spécifiquement conçus pour prendre en compte le nombre de moyennes comparées et présentent un risque d’erreur de type 1 beaucoup plus faible que le même nombre de tests t. Malheureusement, cela rend les tests de comparaison multiple relativement peu puissants.\nPar exemple, il arrive parfois qu’une ANOVA détecte une différence significative entre les traitements, mais que les tests a posteriori ultérieurs ne parviennent pas à détecter une différence significative entre les moyennes. Au lieu d’effectuer un grand nombre de comparaisons a posteriori non planifiées et sans discernement, une meilleure approche peut consister à effectuer un petit nombre de comparaisons planifiées (a-priori, c’est-à-dire « avant l’événement »). Par exemple, votre hypothèse pourrait être que chacun des deux médicaments expérimentaux utilisés dans l’exemple ci-dessus réduira la croissance des tumeurs cérébrales par rapport au contrôle. Une ANOVA permettra de tester les différences entre les traitements avec un coefficient de 0,05 et donnera également une bonne estimation de la variance de l’échantillon à partir de l’erreur systémique, puisque celle-ci a été calculée à partir de tous les individus utilisés dans l’expérience. Toutefois, au lieu d’effectuer un grand nombre de comparaisons imprévues, vous pourriez effectuer deux tests t (unilatéraux) comparant la croissance moyenne des tumeurs dans chaque traitement médicamenteux et dans le contrôle.\nSi vous ne faites qu’une seule comparaison planifiée, la probabilité d’une erreur de type 1 est de 0,05, ce qui est acceptable. Si vous effectuez plusieurs comparaisons a priori qui ont réellement été planifiées pour des raisons particulières avant l’expérience (par exemple, pour tester les hypothèses «Inhibin 4 réduit la croissance de la tumeur par rapport au contrôle non traité» et «Tumostat réduit la croissance de la tumeur par rapport au contrôle non traité»), chacune est une hypothèse distincte et différente, de sorte que le risque d’une erreur de type 1 est encore acceptable à 0,05. Ce n’est que lorsque vous effectuez des comparaisons sans discernement que le risque d’erreur de type 1 augmente et que vous devez envisager d’utiliser l’un des tests a posteriori décrits précédemment, qui maintient un taux d’erreur de 0,05.\n\n3.3.2.4.2.1 Test de t pour deux moyennes\nLe test a priori le plus simple est une comparaison entre deux moyennes. Dans notre exemple, supposons qu’avant de réaliser l’expérience, nous ayons émis l’hypothèse a priori qu’il existe une différence dans le diamètre moyen du test entre les traitement de Inhibin 4 et de contrôle. Cela conduit à comparer les moyennes \\(\\bar{X_A} = 9\\) et \\(\\bar{X_B} = 3\\). Pour effectuer une comparaison planifiée après une ANOVA à un facteur, vous utilisez la formule pour un test t, sauf que vous utilisez l’erreur quadratique moyenne (MS error) comme meilleure estimation de \\(s^2\\): \\[ t_{n_A + n_B - 2} = \\frac{\\bar{X_A} - \\bar{X_B}}{\\sqrt{\\frac{2 \\times MS error}{n}}} \\].\nLe dégré de liberté de cette statistique est le dégré de liberté de l’erreur quadratique moyenne. Dans notre exemple cela donne: \\[ t_6 = \\frac{9 - 3}{\\sqrt{\\frac{2 \\times 3,33}{4}}} = 4,649\\].\nEtant donné que la valeur critique unilatérale de 5 % pour t est de 2,446 (p = 0,001), on peut conclure que ces deux moyennes semblent également provenir de populations différentes.\n\n3.3.2.4.2.2 Contrates pour deux moyennes.\nUne autre façon d’envisager la comparaison que nous venons de faire entre les moyennes des Inhibin 4 et de contrôle est de considérer le numérateur de notre test t comme une «combinaison linéaire» de moyennes. Une combinaison linéaire est simplement une somme de valeurs pondérées. Pour cette comparaison, nous attribuons un poids de 1 au traitement Inhibin 4 et un poids de -1 au contrôle. Toutes les autres moyennes ont un poids nul. Nous utilisons la notation psi (\\(\\psi\\)) qui indique la somme pondérée des moyennes, avec des pondérations \\(\\alpha_i\\) pour chaque moyenne, \\(\\bar{X_i}\\). Pour notre exemple précédent on a :\n\\[ \\psi = (1) \\times 9 + (-1) \\times 3 = 6 \\].\nLe test d’hypothèse pour les contrastes peut être effectué sous la forme d’un test t ou d’un test F puisque lorsque \\(ddl = 1, \\mbox{on a} F = t^2\\). Nous utiliserons le test F. Le numérateur du test F est calculé avec les sommes des erreurs quadratiques suivantes : \\[ SC_{contraste} = \\frac{\\psi^2}{\\sum (\\alpha_i^2/n_i)} \\]. Ce qui équivaut, lorsque la taille des échantillons est la même à: \\[ SC_{contraste} = \\frac{\\psi^2}{(\\sum \\alpha_i^2)/n} \\].\nOn a donc: \\[ SC_{contraste} =  \\frac{6^2}{(1^2 + (-1)^2)/4} = 72\\].\nL’erreur quadratique moyenne est toujours la somme des erreurs quadratiques divisée par les degrés de liberté. Le dégré de liberté pour les contrastes a priori est toujours égal à 1, de sorte que le numérateur du test F est le suivant: \\[ MS_{contraste} = \\frac{SC_{contraste}}{1} = SC_{contraste} \\].\nLe dénominateur du test F pour les contrastes a priori est le même que celui du test F. Notre valeur F est donc la suivante: \\[ F(1, ddl_{erreur} = \\frac{MS_{contraste}}{MS_{erreur}}) \\].\nCe qui correspond dans notre exemple à: \\[ F(1, 9) = \\frac{72}{3,33} = 21,62\\].\nLa valeur de p pour cette valeur de F est 0,001, qui est la même que celle obtenue pour le test de t ci-dessus. Ceci s’explique par le fait que la statistique de F est égale à \\(t^2\\) (\\(21,62 = 2,44^2\\)).\n\n3.3.2.4.2.3 Contrastes orthogonaux et indépendance\nContrastes pour groupes de moyennes\nLes contrastes nous permettent également de comparer des groupes de moyennes avec d’autres groupes de moyennes. Dans notre exemple, supposons que nous ayons l’hypothèse préalable que les traitements en général ont un effet différents de celui des contrôles sur les résultats des tests. En d’autres termes, nous voulons comparer la moyenne des deux conditions (tumostat et inhibin 4) avec le contrôle.\nNos poids seront alors de 1 pour le contrôle, et de -.5 pour le traitement tumostat et -.5 pour le traitement inhibin 4, et de zéro pour les conditions restantes (s’il y en avait). La combinaison linéaire de moyennes correspondante est la suivante:\n\\[ \\psi = (1) \\times 9 + (-0,5) \\times 6 + (-0,5) \\times 3 = 4,5\\].\nVous devez vous convaincre que cette valeur, \\(\\psi\\), est la différence entre le contrôle et la moyenne des deux traitements. Elle doit avoir une valeur attendue de zéro pour l’hypothèse nulle. Si la somme de tous les poids est égale à zéro, la valeur attendue du contraste sera égale à zéro sous l’hypothèse nulle.\nL’erreur quadratique moyenne pour ce contraste est: \\[ SS_{contraste} = \\frac{\\psi^2}{(\\sum \\alpha_i^2)/2} = \\frac{4,5^2}{\\frac{(1)^2 + (-0,5)^2 + (-0,5)^2}{4}} =  54\\].\nOn a donc \\[ F(1,9) = \\frac{54}{3,33} = 16,21\\]. La valeur de p pour cette valeur est 0,002.\nConstrates orthogonaux et indépendance\nNous avons maintenant établi deux contrastes. Nous venons de comparer les effets de l’inhibin 4 et du tumostat à la moyenne des effets du contrôle sur les résultats des tests. Auparavant, nous avons comparé le contrôle et l’inhibin 4. Vous devez comprendre que ces deux contrastes sont dépendants simplement parce qu’ils possèdent des groupes en commun.\nCependant, les contrastes peuvent être indépendants s’ils ne partagent aucun groupe en commun. Et même s’ils partagent des groupes, formellement, deux contrastes sont indépendants si la somme des produits de leurs poids est égale à zéro. Dans ce cas, les deux contrastes sont dits orthogonaux. Dans notre exemple: \\(c_1 = [1, 0, -1] \\mbox{et} c_2 = [1, -0.5, -0.5]\\). La somme des produits est donc: \\((1)(1) + (0)(-0.5) + (-1)(-0.5) = 1.5 \\neq 0\\)\nCependant le contraste \\(c_3=[0.5, -1, 0.5]\\) est bel et bien orthogonal au contraste \\(c_1\\).\nSi deux contrastes sont orthogonaux, les deux tests sont «indépendants». Si deux tests sont indépendants, la probabilité de rejeter un test ne dépend pas de la probabilité de rejeter l’autre.\nTester des contrastes orthogonaux sur le même ensemble de données revient à mener des expériences complètement distinctes. Comme les contrastes orthogonaux sont indépendants, nous pouvons facilement calculer le taux d’erreur par famille : \\[ FW = 1 - (1 - \\alpha)^n \\] où \\(n\\) est le nombre de contrastes orthogonaux.\n\n3.3.3 Analyse de variance à deux facteurs\nUne ANOVA à facteur unique donne la probabilité que deux échantillons ou plus proviennent de populations ayant la même moyenne. L’ANOVA à facteur unique est utilisée pour analyser des données univariées provenant d’échantillons exposés à différents niveaux ou aspects d’un seul facteur. Par exemple, elle pourrait être utilisée pour comparer la consommation d’oxygène d’une espèce de crabe intertidal (la variable) à deux températures ou plus (le facteur), la croissance de tumeurs cérébrales (la variable) exposées à une série de médicaments (le facteur), ou la résistance aux insecticides d’un papillon de nuit (la variable) provenant de plusieurs endroits différents (le facteur). Cependant, les scientifiques du vivant obtiennent souvent des données univariées en relation avec plus d’un facteur. Des exemples d’expériences à deux facteurs sont la consommation d’oxygène d’un crabe intertidal à plusieurs combinaisons de température et d’humidité, la croissance de tumeurs cérébrales exposées à une série de médicaments et à différents niveaux de radiothérapie, ou la résistance aux insecticides d’un ravageur agricole provenant de différents endroits et de différentes plantes hôtes. Il serait très utile de disposer d’une analyse donnant des rapports F distincts (et la probabilité que les moyennes des traitements proviennent de populations ayant la même moyenne) pour chacun des deux facteurs. C’est ce que fait l’ANOVA à deux facteurs.\n\n3.3.3.1 Présentation de l’exemple\nLes blattes représentent un risque sérieux pour la santé publique, en particulier dans les villes tropicales et subtropicales où l’assainissement est insuffisant. Ces insectes vivent souvent dans les égouts et les canalisations, mais ils se nourrissent beaucoup et infestent fréquemment les zones de stockage et de préparation des aliments. Les blattes urbaines ont un régime alimentaire varié, qui comprend souvent des excréments et d’autres déchets, de sorte qu’elles peuvent contaminer les aliments et, partant, provoquer des maladies chez l’homme.\nUn entomologiste urbain étudiant les moyens de lutte contre les blattes s’est intéressé aux effets de la température et de l’humidité sur l’activité de la blatte Periplaneta americana. L’entomologiste a conçu une méthode pour mesurer l’activité des blattes en plaçant ces insectes individuellement dans des bocaux de verre cylindriques à couvercle ouvert. En les filmant par le haut et en analysant les enregistrements par ordinateur, l’entomologiste a obtenu des données sur la quantité de mouvement de chaque blatte par heure.\nL’entomologiste a mis en place une expérience pour la croissance des blattes à trois températures et trois niveaux d’humidité. Le tableau suivant récapitule la longueur en mm de 27 blattes nourries ad libitum et maintenues dans neuf combinaisons différentes de température et d’humidité.\n\n\nHumidité (%)\nTemperature (°C)\nTaille de la blatte (mm)\n\n\n\n33\n20\n1\n\n\n33\n20\n2\n\n\n33\n20\n3\n\n\n33\n30\n5\n\n\n33\n30\n6\n\n\n33\n30\n7\n\n\n33\n40\n9\n\n\n33\n40\n10\n\n\n33\n40\n11\n\n\n66\n20\n9\n\n\n66\n20\n10\n\n\n66\n20\n11\n\n\n66\n30\n13\n\n\n66\n30\n14\n\n\n66\n30\n15\n\n\n66\n40\n17\n\n\n66\n40\n18\n\n\n66\n40\n19\n\n\n99\n20\n17\n\n\n99\n20\n18\n\n\n99\n20\n19\n\n\n99\n30\n21\n\n\n99\n30\n22\n\n\n99\n30\n23\n\n\n99\n60\n25\n\n\n99\n60\n26\n\n\n99\n60\n27\n\n\n\n\n3.3.3.1.1 Notion d’interaction\nLes expériences qui incluent simultanément les effets de plus d’un facteur sur une variable particulière peuvent être beaucoup plus révélatrices que l’examen de chaque facteur séparément, car vous pouvez détecter certaines combinaisons de facteurs qui ont un effet synergique encore appelé interaction. En outre, l’examen de plusieurs facteurs à la fois peut permettre de réaliser d’importantes économies de temps et de ressources par rapport à la réalisation d’une série d’expériences et d’analyses distinctes.\n\n\n\n\nMcKillup, Steve. 2011. “Statistics Explained,” November. https://doi.org/10.1017/cbo9781139047500.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Comparaison de moyennes</span>"
    ]
  },
  {
    "objectID": "chapter1.html#présentation-de-lexemple",
    "href": "chapter1.html#présentation-de-lexemple",
    "title": "\n3  Comparaison de moyennes\n",
    "section": "\n3.4 Présentation de l’exemple",
    "text": "3.4 Présentation de l’exemple\nImaginez que vous souhaitiez évaluer les effets de deux médicaments expérimentaux sur la croissance des tumeurs cérébrales chez l’homme. Un grand nombre de ces tumeurs ne peuvent pas être enlevées car le cerveau serait gravement endommagé. Une tumeur en croissance comprimera et remplacera le tissu neural, causant souvent des dommages mortels, c’est pourquoi il y a un grand intérêt médical pour les médicaments qui affectent la croissance des tumeurs.\nOn vous a assigné 12 sujets expérimentaux consentants, chacun ayant une tumeur cérébrale de la même taille et du même type. Quatre d’entre eux sont répartis au hasard dans un groupe de contrôle non traité, quatre sont traités avec le médicament «Tumostat» et quatre autres avec le médicament «Inhibin 4». Après deux mois de traitement, leurs tumeurs sont mesurées à nouveau.\nVotre hypothèse nulle est la suivante : «Il n’y a pas de différence dans le diamètre moyen des tumeurs entre les populations sur lesquelles ces trois échantillons ont été prélevés». L’hypothèse alternative est la suivante : «Il existe une différence dans le diamètre moyen des tumeurs parmi les populations sur lesquelles ces échantillons ont été prélevés».\nLes résultats de cette expérience sont illustrés à la Figure 3.1, le diamètre de la tumeur (en millimètres) augmentant sur l’axe Y et les trois catégories de traitement sur l’axe X.\n\n\n\n\n\nFigure 3.1: Représentation graphique du diamètre des tumeurs cérébrales humaines chez des volontaires cliniques non traités (contrôle) ou traités avec les médicaments expérimentaux Tumostat ou Inhibin 4. Le diamètre des tumeurs augmente vers le haut de la page. La ligne horizontale épaisse représente la moyenne générale, tandis que les lignes plus courtes et plus claires représentent les moyennes de traitement. Le diamètre de chaque tumeur répliquée est représenté par un carré plein (McKillup 2011).\n\n\nLes moyennes de l’échantillon de chaque groupe de quatre patients ont été calculées à partir des résultats de l’expérience. Les moyennes des échantillons de chaque groupe de quatre sont indiquées, ainsi que la grande moyenne, qui est le diamètre moyen des 12 tumeurs.\nRéfléchissez maintenant au diamètre de chaque tumeur. Il existe deux sources possibles de variation qui contribueront à l’éloigner de la moyenne générale.\n\n\n\n\n\nFigure 3.2: Les flèches indiquent l’écart de chaque réplicat par rapport à la moyenne de son traitement respectif. Il s’agit uniquement de la variation due à l’erreur (McKillup 2011).\n\n\nTout d’abord, il y a l’effet du traitement qu’il a subi (Contrôle ou Tumostat ou Inhibine 4). Deuxièmement, il est probable qu’il y ait des variations entre les individus qui ne peuvent pas être contrôlées, telles que de légères différences dans la taille initiale de la tumeur, des différences dans l’état de santé général, le génotype, l’état nutritionnel et les réponses immunitaires de chaque personne, ainsi que d’autres aspects involontaires de l’expérience. Cette variation incontrôlable est appelée « erreur ». Par conséquent, le déplacement de chaque point de l’axe Y par rapport à la moyenne générale sera déterminé par la formule suivante :\n\\[ \\mbox{Diametre de la tumeur} = traitement + erreur\\]\nDans l’exemple de la Figure 3.1, le Tumostat et l’Inhibine 4 semblent avoir un effet inhibiteur sur la croissance par rapport au contrôle (dans lequel les tumeurs ont grossi), mais l’effet est-il significatif ou s’agit-il simplement du type de différence qui peut se produire par hasard parmi des échantillons prélevés dans des populations ayant la même moyenne ? Une ANOVA à facteur unique calcule cette probabilité de manière très simple. Pour comprendre comment l’ANOVA procède, il faut examiner les raisons pour lesquelles les valeurs de chaque tumeur et les moyennes de traitement sont là où elles sont.\n\n\n\n\nMcKillup, Steve. 2011. “Statistics Explained,” November. https://doi.org/10.1017/cbo9781139047500.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Comparaison de moyennes</span>"
    ]
  }
]